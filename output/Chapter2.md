第2章 共同演化计算概述  
**2.1 共同演化系统：概要**  

共同演化计算（Coevolutionary Computation）通常指采用进化计算（Evolutionary Computation）核心原理的一大类计算系统。这些共同演化系统以种群为基础，并使用变异和选择的进化操作来进行搜索过程。作为问题求解的搜索方法，这两种方法可以在“生成-测试”（generate-and-test）的框架内实现迭代的算法实现。事实上，早期的共同演化计算发展共享了与EAs（进化算法，Evolutionary Algorithms）相同的设计原则，并采用了前者已经引入的进化操作。但它们的区别在于用于评估种群中每个候选解或个体质量的适应度评价方法的具体设计。  

一方面，进化算法（EAs）用一个绝对性能测量来评估每个候选解的目标适应度。在优化问题的情境下，通常已知并以闭形式构造适应度函数$f$，这样可以通过直接查询$f$来获得一个实值输出，从而确定候选解的适应度（质量）。另一方面，共同演化系统则通过测试案例来评估每个候选解的主观适应度，而这些测试案例在搜索过程中是可以变化的。此外，在共同演化中，适应度评价需要一个显式过程（例如，通过计算程序执行），以确定候选解相对于这些测试案例的质量。  

总而言之，非常重要的是将共同演化计算看作一种通用问题求解框架，并应用它的特定区别特征，使其能够在多种问题设置中表现出效果，而这些问题通常对其进化计算的对应方法是具有挑战性的。在下一节2.2中，我们将给出共同演化系统关键发展的分类性综述，并简要总结现代自然演化综合理论，以提供一个背景来研究共同演化系统与自然演化之间的关系。在此之后，我们将在接下来的两节中更详细地描述和讨论共同演化的主要原理和概念。  

第2.3节将聚焦于共同演化的主要原理，即包含主观适应度评价过程的“生成—测试”框架。我们将讨论这种适应度评价的性质，并提出描述成功共同演化搜索所需条件的论点。在第2.4节，将讨论监管共同演化操作、具有特定问题求解能力的两个主要概念。这包括种群结构以及共同演化中代理之间的两种类型的交互。  
**2.2 协同进化计算的发展**

我们将从第2.2.1节开始回顾协同进化系统的一些关键历史发展。这是为了提供一个背景，使得后续章节能够对协同进化搜索的过程以及支配协同进化系统机制与主要组件设计的核心概念进行更详细的讨论。我们对这些发展性研究的回顾不是按时间顺序进行的，而是采用更具类别性的回顾方式，重点关注这些研究试图解决的动机。这些动机可能包括验证关于自然协同进化过程中的机制的假设，也可能涉及设计原理或概念框架，这些框架被实施为用于解决现实问题的计算系统。实际上，演化计算与协同进化计算研究的两大基本动机是：理解自然演化与协同进化过程中的机制，从而为设计用于问题求解的计算系统提供指导。在第2.2.1节中，我们将简要介绍现代生物学中对自然演化的综合现代化理论，该理论通常包含种群遗传学理论以及对物种内部变异的解释。这样可以以一种更新且更现代的进化生物学视角作为讨论自然演化与协同进化系统之间关系的基础。

**2.2.1 关键发展的分类视角**

不出所料，涉及战略决策的问题领域在协同进化系统的研究与开发中得到了早期且显著的关注。首先，以博弈论的形式提出解决这些问题的正式方法，自其在文献[84]中首次引入以来，便不断得到发展。接着，我们可以注意到各种形式的计算机技术已经普遍可用，包括从高性能计算集群到移动设备，以及从公共部门到私人部门的覆盖，这些都在现代世界中相互联网。基础研究与应用技术的发展已经促成了解决战略决策问题的能力与广泛应用，而这正是许多重要人类活动的标志[58]。

在人工智能的背景下，游戏提供了开发和评估智能行为的手段。具体而言，游戏是某种由主体进行的行为活动的模型，在这些活动中，主体通过某些资源的消耗获得奖励。
从人工智能领域较为正式的方法转向，早期协同进化计算的重点在于理解自然演化如何使得一群代理能够在与其他代理交互过程中，基于各自作决策和执行决策的能力，涌现出具有智能的决策行为，而这种行为仅依赖极少的预编程知识【12】。一个更加重要的挑战是研究代理是否能够仅通过策略交互来学习有效的决策行为，而这些策略交互可以被建模为博弈过程。考虑一种简单的场景，即在两个玩家之间进行的一类具有竞争性质的零和博弈。在该环境中，任何合法动作序列下给某一玩家分配的收益必然会从另一玩家处扣除。由于收益分配方式引发的游戏竞争性意味着最终总会有胜者和败者（虽然平局可能出现，但也可以设计规则在最终累积收益中打破平局）。一个关键点是，关于博弈结果的信息是直接可得的。相比于需要进一步信息收集和计算以处理如累积收益损失等特定博弈属性的情况，这里无需额外的复杂计算。在这样的背景下，可以设计协同进化过程，使得该群体中的游戏代理优先选择那些获得较多胜利次数的个体。

在任意博弈过程中，一个代理仅具备能力来接收游戏状态描述作为输入，并输出对应于游戏设计规定的资源分配决策，以完成动作。这种输入输出响应形式的行为可以用适当的、可能是非线性的参数表示方法建模，例如人工神经网络(Artificial Neural Networks, ANNs)。这种建模方法限制了可以融入代理决策能力的博弈知识量，而仅保留完成合法动作所需的知识。代理依赖其策略表示中的参数来唯一地标识自身。通过在协同进化过程中应用变异算子改变策略参数，以及通过选择算子捕捉其繁殖机会，代理能够适应自己的博弈行为。然而，问题在于，仅通过代理间策略交互或博弈过程的整体结果指导的协同进化，是否足以生成能够实施有效决策的代理。此外，每一个结果本质上是代理所作决策序列对应的收益之和。并不存在明确的机制来赋予那些在问题领域知识背景中被视为重要的特定决策模式更高的优先权。

事实上，早在【6, 68】中就已记录了尝试协同进化具有智能决策能力的代理的研究。然而，历经四十年，通过进一步的研究及更高速计算机的出现，才得以实现协同进化学习，使得代理能够玩起点几乎不依赖专家知识的有竞争性的零和棋类游戏【13, 41】。不仅这些协同进化的代理能够学习以高度竞争的水准玩这些棋类游戏【38】，它们还能够进行战略性博弈操作，展现出类似于人类专家玩家的风格【16】。
基于竞争性共进化的框架用于学习战略行为，这一方法已被应用于其他类别的游戏。例如，在非合作游戏的范畴内，非零和游戏形式的迭代囚徒困境（Iterated Prisoner’s Dilemma, IPD）已受到广泛关注。标准的IPD涉及两名玩家在一系列行动中同时选择合作或背叛。两名玩家所有四种可能联合作出的行动对应的收益可用一个规范形式的矩阵表示，该矩阵反映了合作的群体理性与背叛的个体理性之间的对立动机 [$2, 3$]。尽管结构简单，IPD却能够在迭代行动序列中生成复杂的代理行为，尤其当代理可以根据过去的游戏记录进行决策时 [$4$]。这进一步催生了一大批固定响应的纯策略。在不同游戏配置（例如游戏中允许多于两种选择和噪声）下，包含各种IPD策略集合的种群的共进化动态可能表现出复杂性 [$14, 22$]。

这一IPD共进化框架进一步被扩展以纳入更复杂的机制，例如间接交互（例如基于声誉） [$15, 90$] 和联合体形成（例如多于两名玩家同时参与交互） [$73, 74, 88, 89$]，这些机制与现实世界中的交互相关联。尽管共进化过程能够生成复杂的代理行为，支配其交互的游戏规范实际上是定义良好的。游戏作为某些现实世界交互（例如经济学和社会系统中的交互）的抽象建模，从而更便于分析和识别某些使战略行为有效的显著特征。当需要以假设性方式探索或评估在放宽代理交互限制后可能出现的战略行为，便可以将共进化系统设计为模拟工具。在这里，软人工生命（Soft Artificial Life, ALife）提供了一个框架，结合了数学和计算的建模与模拟方面，用以开发类似生命行为 [$46$]。

例如，元胞自动机（Cellular Automata, CA）通常用来建模空间或其他形式的局部交互，通过定义代理在一个共进化有限种群中的特定网格状邻域结构进行交互 [$29$]。与共进化中的大多数选择机制不同，元胞自动机仅以某种随机抽样形式实现从种群中选择与代理交互。然而，早期的开创性工作 [$76$] 已考虑了模拟现实复杂生命行为的其他方面。交互仍然涉及两名玩家，因此可从种群中抽取任意代理进行资源竞争，旨在生存和繁殖。然而，这些交互的环境设定真实地复杂化。

首先，代理活动的环境是一个三维世界，其模拟物理学包括诸如重力、摩擦和碰撞等多种效应。接下来，这些代理本质上是虚拟生物，其构造高度复杂，具有由不同固定功能的神经节点组成的决策能力，以及用于检测环境的输入传感器和用于实现运动与执行任务的输出效应器。这些生物的实际操作涉及物理运动，其由构成其身体结构（部件）之间的形态学关系（morphology）所支配。构成身体的形态结构和控制身体运动的神经架构的拓扑均通过有向图来合并和描述。这种表示方式允许构造特定变异操作，以物理上改变虚拟生物，从而使代理能够仅通过交互共进化其身体的形态结构和操作行为。
协同进化计算与机器学习研究之间存在着强大的协作效应。许多研究利用机器学习中的原理与机制来开发和改进用于解决学习问题的协同进化系统【17, 19, 21】。另外一些早期研究则使用协同进化方法解决各种学习问题。此前，我们介绍了关于博弈策略协同进化学习的研究，这一类问题难以单纯使用机器学习方法解决，除非利用大量领域知识并依赖高性能计算资源。而对于较为经典的学习问题，以一个案例为例，早期有研究【51, 63, 65】尝试协同进化元胞自动机（Cellular Automata，简称$CA$）规则以完成二进制密度分类任务。这涉及一个一维的晶格或数组$N$（两个相对端点单元连接形成一个环），其中的每个单元都取二进制状态中的一个，即$\{0,1\}$。该任务的目标是对描述数组中$0$和$1$排列的初始配置进行判断，高密度即数组中$1$的数量多于$0$的数量，否则为低密度。

对于配备有充足内存的计算机，它可以直接统计$1$和$0$的数量然后进行比较，因此该任务相对简单。然而，真正的挑战在于仅允许本地化计算且内存极为有限。$CA$规则按照某些时间步长，通过改变单元的当前状态并基于其邻域内的单元状态来执行状态变换，直到得到一个固定的配置【57】。如果这种状态变换的结果配置为全$1$，则$CA$规则被认为将初始配置分类为高密度；反之，则为低密度。即便如此，协同进化学习已经被证明能够产生高性能的$CA$规则，这些规则对应于先前已被鉴别出效果优异的策略【85】。这一成果是通过两种种群、一种捕食者-猎物协同进化框架实现的，其中候选解决方案的种群由$CA$规则组成，测试案例的种群由数组的初始配置组成。

$CA$规则的适应度是它能够正确分类或解决的初始配置数量之和。初始配置的适应度则是未被正确分类或解决的$CA$规则数量之和。为了保证协同进化搜索的持续进展，可以进一步通过多样性维护技术增强两种种群的协同进化设置【18】。在【85】中使用了一种竞争性适应度分享机制，该机制通过重新分配与解决特定测试案例相关联的贡献或权重，而不是假设权重均为统一值。例如，相对适应度计算中，对于$CA$规则，解决初始配置的规则数量较少时，该初始配置被赋予较高权重。同样的原则也适用于进化初始配置的共享适应度计算。
这种双种群协同进化学习方法还有其他应用，包括语法归纳、基因调控推断和演化机器人学。具体而言，所有这些应用都在系统辨识的框架下进行，其主要学习目标是构建一个模型，该模型能够代表目标系统的基础或内部过程，而目标系统的外部输出行为可在输入数据呈现后观察到 [8]。与大多数数据驱动机器学习方法的情况不同，针对系统辨识任务，数据通常有限。例如，数据的获取可能成本高昂，或者即使数据可用，也可能存在偏差，从而难以获得具有代表性的数据集。因此，系统辨识的主要挑战在于模型学习必须通过有限且谨慎设计的一系列实验来完成。这一挑战可以通过一种类似于主动学习方法的双种群协同进化框架来解决 [8]。具体而言，单独的测试案例种群不仅可以规避数据集可用性受限的问题，还可以生成可有效区分目标模型的新测试案例。

协同进化原理长期以来被用于解决复杂的优化问题。协同进化框架的一个早期经典例子是在文献 [48] 中报道的研究。该研究关注的是寻找一种最小化排序算法，该算法能够将一个未排序元素列表转换成一个已经排序的列表。这种算法被称为排序网络，因为它具有描述性的图形化操作表示形式。排序网络由$n$根平行的水平线组成，每条水平线对应列表中的一个元素。水平线的左端是未排序的列表，而右端是排序后的列表。算法的操作通过有向的竖线表示，每根竖线的两端用箭头连接位置$i$和$j$的两条水平线，其中 $i, j \in \{1, \ldots, n\}$。每根有向竖线代表一个比较与交换（即置换）的操作，该操作针对对应位于第$i$和第$j$水平线上的元素进行。箭头的方向表示交换的方向，使得较小的元素总会出现在箭头的尾部（详见文献 [48] 的图1和图2）。研究表明，与使用固定测试案例的标准演化优化方法相比，双种群协同进化框架能够显著改进优化效果。

最后，协同进化逐渐发展成一种高层次的通用问题求解框架。这里的总体动机与其他框架（例如超启发式方法）类似，其核心在于自动搜索针对目标问题的低层次问题求解方法。该框架通过协同进化原理在算法或启发式的空间中进行竞争性搜索，以及解决问题的其他方面，例如问题分解。实际上，在这种背景下，合作协同进化方法早期就已被开发出来，用于解决复杂问题，这些问题的解决方案表示形式允许分解结构作为组件 [67]。然而，据了解，并非所有现实世界中的问题都能被分解为独立的组件。组件之间可能存在复杂的相互依赖。因此，该框架被设计成适应性地协同调整这些组件。对于每个组件，从一个遗传隔离的种群中（即没有与其他种群候选者的交叉或迁移）获取候选解。而所有组件的候选解一起合作以形成问题的完整解决方案。剩余的步骤包括适应度评估，以及对各个种群内部的候选者应用适当的选择压力。这可以被定义为一个“信用分配问题”，即通过来自其他种群的固定代表帮助评估当前隔离种群中的候选解的适应度。
对这种协作共演化框架的受控实证研究表明，其在训练用于模式分类任务的人工神经网络（ANNs）方面具有可行性。事实上，可以将各种其他扩展融入到协作共演化中，这突显了该框架的通用性特性。在文献[45]中，该研究将此框架扩展用于ANN训练，以协作共演化构建集成模型。具体来说，组件现在表现为单个ANN的形式，它们可以通过机器学习中常用于集成方法的柔性方式进行组合。在处理性能评估和共演化解决方案选择的问题上，该框架采用了多目标优化方法，这些目标包括分类性能与单个ANN输出及构建集成之间的模糊度或相关性度量。

这种协作共演化框架在解决实际问题方面的其他应用还包括优化和设计问题。在文献[91]中，该框架被用于解决一个特定实例的二次分配问题（Quadratic Assignment Problem，QAP），即在算法的调度执行过程中涉及多功能模块的节点（多处理器）映射，该算法具有某些典型于信号处理和多媒体应用的底层数据流依赖。在文献[55]中，协作共演化框架的并行实现被应用于直接解决关于复杂工程设计问题的整个生命周期问题，这些问题可以被分解并允许在较小的分解问题上执行并发优化任务。

这种高级的、通用的问题解决共演化框架不仅限于协作环境。事实上，该框架还扩展到之前提到的竞争性共演化环境。例如，游戏策略的集成可以采用单种群的竞争性框架进行共演化，该框架带有多样性维护机制[21]。经过严格的定量分析验证表明，与集成内单个策略相比，由于覆盖效应（即每个个体击败不同子集的对手策略），所构建的集成模型具有更高的泛化性能[17,18]。

此共演化原则被用来开发自动化并行投资组合优化器。在文献[54,80]中，双种群竞争性框架被用于共演化一种由优化器构成的种群和另一种由组合优化问题实例构成的种群。这要求对优化器和问题实例进行某种形式的参数化。大多数启发式优化器设计时都带有参数设置，这些参数可以结合转化操作来构造其配置或参数空间。诸如旅行商问题（Travelling Salesman Problems, TSPs）这样的组合优化问题，通常具有与问题大小相关联的度量，该度量可以作为扰动过程的固定设置，以生成问题实例。两种群以竞争方式共同演化，且此框架已证明了其能通过并行实现生成优化器种群，这些优化器能够以接近专家设计的优化器的性能水平，集体解决新生成的问题实例。
### 2.2.2 演化生物学及其与协同演化计算的关系

在1997年的演化计算回顾论文[5]中，简要提及了结合达尔文进化理论[23]和孟德尔遗传学理论的自然进化新达尔文综合理论（或模型）[49]，以介绍遗传算法（EAs）的基本结构。具体来说，标准的遗传算法中包含一个个体群体，经历变异和选择的过程。有许多现代遗传算法采用的进化搜索过程方法论远比早期定义的基本遗传算法复杂和深入。然而，大多数演化计算领域的研究通常采用简化版本的新达尔文综合理论在其文章中进行介绍（包括回顾论文[5]）。与演化生物学研究中的原始形式和常规介绍相比，新达尔文综合理论涉及的内容更为复杂和丰富，涵盖了遗传学、生态学和古生物学等多个领域的概念和发现[49]。事实上，生物进化的现代综合理论自身也在不断演化，领域内专家对该理论是否需要更新仍在展开讨论[52]。尽管如此，我们按照演化生物学的著作[44]提供对现代综合理论的简要但更深入的介绍。我们的动机是既提供对这一进化模型更全面的阐释，同时探讨它如何与演化计算中设计的一些复杂系统（例如协同演化系统）相关联。

现代综合理论有几个核心概念对此进行了支持[44]：

第一，生物进化过程发生的层级是**种群**而非**个体**。这意味着生物进化过程被概念化为种群中遗传变异频率的变化，而不是个体的变化。

第二，遗传通过基因实现，现在通常被接受为DNA或RNA。特别是，拉马克学派中关于个体经验传递到后代的观点仅被考虑为一种**文化遗传**形式，它在某种程度上介导了自然选择。例如，在有性繁殖中，通过配子传递给真核生物后代的DNA序列不会受到双亲经历的影响。

第三，可遗传变异源于罕见的个体**突变**。然而，目前普遍接受的观点是，自然选择作为一种**稳定（净化）机制**存在，以维持对这些突变的功能性响应。目前没有确凿证据支持“定向突变”能够导致个体功能性响应改善的观点。种群遗传学理论规定突变为可稳定传播的遗传变异的改变。

第四，有多个因素会影响遗传变异频率，包括突变、遗传漂变、基因流动和自然选择。然而，自然选择被认为是唯一能够导致频率变化而产生**正向适应**的原因。需要注意的是，自然选择被定义为不同遗传实体（如基因、表型不同的个体、物种以及种群）在后代产生数量上的**一致性差异**。
此时，有必要注意现代综合理论的很大一部分是旨在通过各种证据来源描述生物进化，这些证据主要表现为多细胞真核生物的缓慢世代变化，这种变化主要发生在高级分类群（例如动物）中。具体来说，这些个体的大型表型变化（即那些可以于物理上观察到的变化）是通过小规模且逐渐增量的变化在极长时间内发生的。物种被认为是性繁殖的、彼此隔离的种群群体。物种的进化分化发生于其种群的地理隔离。综上所述，现代综合理论 [44] 大致由以下组成：形式化通过可遗传变异频率变化解释进化的种群遗传学框架 [35, 47, 87]，以及对物种内部变异的解读 [26]。种群遗传学的核心理论已经吸收了随着发现而提出的新的突变形式，例如突变是否表现为单个碱基对替换（其中某个核苷酸被另一个核苷酸替代）到转座元件的插入（转座元件构成调控序列或区域中的大片核酸序列）。此外，自然选择这一概念本身并非简单，它可以极为复杂。例如，基因之间相互作用能够导致对适应度（即繁殖速率）的表观互作效应（显性效应）。进一步丰富了生物进化的复杂性的是物种的种类繁多，它们在与其他物种的相互作用中表现出的特化，而其中一些包括互相进化过程及其结果，即捕食者与被捕食者、寄主与寄生虫、竞争和互益关系中的协同进化形式 [27, 82]。鉴于如此复杂的生物进化视角，以自然进化的过程为灵感或设计原则的演化算法 (EAs) 也同样复杂这一点并不足为奇。事实上，具备上述现代进化综合理论的基本视角后，我们可以认为早期的EAs（例如遗传算法、演化编程和演化策略）通常反映了进化的高度简化和抽象模型。一方面，综述论文 [5] 以及采用类似表述的其他论文在其论述中是准确的，即EAs的过程在这种受限背景下是类比自然进化并从其获得灵感的。另一方面，用于搜索的更复杂且更深入的EAs，例如岛屿模型 [7, 79] 和合作与竞争协同进化 [11, 48, 67, 70] 中，没有绝对适应度的概念，而是相对适应度，其动态地依赖于且需要个体之间的交互来进行计算。我们在此提出的观点是，这类系统采用的过程更接近于现代综合理论下当前对生物进化的理解。例如，协同进化系统依赖于个体之间的合作交互，这些个体代表了针对子问题的潜在解，它们的协同适应可以促进对完整问题新颖解的发现。
换句话说，演化过程的丰富性似乎自然而然地激发了各种机制，这些机制可以被恰当地表述为演化计算和协同演化计算中的可计算算法。事实上，2015年发布的一篇后续观点性文章[28]在讨论自然演化与人工演化之间关系时提出了一个更为一般的问题。我们首先注意到，文中所使用的“人工演化”这一术语是为了概括那些属于演化计算范式（以计算机软件实现的形式）和演化机器人（以物质基底或硬件上运行的过程）的内容。更重要的是，并不是说演化算法（Evolutionary Algorithms, 简称EAs）准确地模拟了自然演化，而是通过具备三个基本组成部分——表示（遗传）、变异（突变）和选择，EAs构成了一种演化过程，与自然（生物学）演化的方式一致。这一点可以扩展到协同演化计算的所有其他过程性实现，因为它们都具备并基于这三大组成部分运行。从这样的视角来看，自然演化和人工演化作为一种包含这三大基本组成部分的通用过程的不同形式，那么两者之间存在可以在双向上利用的联系。

**2.3 协同演化的主要原则**  
协同演化计算在进行适应度评估时采取的方法，早期的一个动机是解决一个问题：即无法获得反映问题特性的绝对目标函数，或这些目标函数非常难以构造。相反，候选解的适应度通过使用测试案例进行评估 [48]。这种协同演化的适应度评估包括一个过程，其输入是候选解和一组测试案例，输出是一个标量值。这个过程所进行的测量需具备两个重要特性：

1. 该过程的输出值应唯一地反映候选解相对于测试案例集合的性能。  
2. 输出值的差异应对应那些被评估的候选解相对于测试案例集合的性能差异。
非正式地讲，这种协同进化的性能度量被认为在候选解集合上施加了一个度量（metric）。这是因为通过候选解之间适应度值的差异或距离，可以一定程度上了解它们之间的关系。该度量过程可以在基于测试的共优化（test-based cooptimization）背景下被更正式地描述 [66]。具体地，一个候选解 $\boldsymbol{s} \in \boldsymbol{S}$ 解决一个测试案例 $\boldsymbol{t} \in \boldsymbol{T}$ 的性能，由一个距离函数或度量 $M: \boldsymbol{S} \times \boldsymbol{T} \to F$ 来描述，函数的范围属于实数集的一个非负子集 $F \subset \mathbb{R}_{\geq 0}$。在协同进化中，候选解的适应度是相对于测试案例集合 $\boldsymbol{T}' \subseteq \boldsymbol{T}$ 而进行评估的。协同进化解的质量函数由 $M(\boldsymbol{s}, \boldsymbol{t})$ 在集合 $\boldsymbol{T}'$ 上的值的聚合来描述，从而得到质量或适应度值 $f(\boldsymbol{s})$。为简化表示，我们将 $\boldsymbol{T}' \subseteq \boldsymbol{T}$ 视为集合而非多重集合或袋（即元素可以重复），尽管后者在实际应用中较为常见。

聚合这些值的方法有多种，并且在若干研究中已经正式化，这些研究基于不同解概念（即“好解”的定义）[30]，例如，基于机器学习中的泛化 [17, 70]、多目标优化中的帕累托最优性 [25] 与博弈论中的纳什均衡和支配关系 [34, 77]。协同进化中一种常用的解概念是最大期望性能（maximum expected performance）[24]，与泛化性能相关 [17, 70]。如果假设测试集合中的每个测试案例的重要性都相等，那么可以简单地求和，$f(\boldsymbol{s}) = \sum_{\boldsymbol{t} \in \boldsymbol{T}'} M(\boldsymbol{s}, \boldsymbol{t})$（因为求和和取平均值之间仅差一个常数倍，该常数为测试案例集合的大小 $|\boldsymbol{T}'|$）。对于此解概念，性能最好的候选解是满足 $\max_{\boldsymbol{s} \in \boldsymbol{S}} f(\boldsymbol{s})$ 的解。值得注意的是，解概念的选择非常关键，因为它决定了对解的“好”之定义以及解的具体形式。对于我们之前定义的最大期望性能，此解的形式可以是单一候选解。而对于其他解概念，例如帕累托最优性 [32, 59, 60]，解可能是以多解集合的形式来表示帕累托前沿；对于纳什均衡 [33]，解可能是无限种群的一部分解的混合或有限近似比例。

尽管我们现在可以正式定义协同进化中的适应度评估，但它们在搜索过程中的实际操作会更加复杂。候选解的主观适应度评估涉及到与协同进化过程中复制成功相关的两个属性 [10]。协同进化的候选解适应度是相对的并且动态的，因为用于评估过程的测试案例集合本身也在不断演变。为了在更实际的设置中说明这两个属性，考虑用于协同进化搜索过程第 $k$ 次运行中第 $t$ 次迭代的测试案例集合 $\boldsymbol{T}'_{t,k}$。注意，与大多数标准做法（包括进化算法和协同进化算法）中使用的随机算法一样，搜索过程通常会重复运行 $K > 1$ 次，每次运行用索引 $k = 1, 2, 3, \dots, K$ 表示。假设在每次迭代和运行中，有一个独特的协同进化候选解 $\boldsymbol{s}$ 出现，那么相对于集合 $\boldsymbol{T}'_{t,k}$ 的适应度是 $f(\boldsymbol{s}, \boldsymbol{T}'_{t,k})$。这种适应度值可能因测试案例集合的不同而有差异，这就是相对适应度的概念，即候选解 $\boldsymbol{s}$ 的适应度值完全依赖于测试案例集合 $\boldsymbol{T}'_{t,k}$，因此当 $\boldsymbol{T}'_{t,k} \neq \boldsymbol{T}'_{u,j}$ 时，必然有 $f(\boldsymbol{s}_i, \boldsymbol{T}'_{t,k}) \neq f(\boldsymbol{s}_i, \boldsymbol{T}'_{u,j})$。动态适应度的概念涉及到运行 $k$ 内的情况，即当 $t \neq u$ 时，必然有 $f(\boldsymbol{s}_i, \boldsymbol{T}'_{t,k}) \neq f(\boldsymbol{s}_i, \boldsymbol{T}'_{u,k})$。

注意，对于涉及 $\max_{\boldsymbol{s} \in \boldsymbol{S}} f(\boldsymbol{s})$ 的具体解概念，如果条件为 $\boldsymbol{T}' = \boldsymbol{T}$，适应度变为客观适应度。在这种情况下，任何两个候选解 $\boldsymbol{s}, \boldsymbol{s}' \in \boldsymbol{S}$ 之间的偏好可以通过它们的适应度值来解决，例如，通过二元关系 $f(\boldsymbol{s}, \boldsymbol{T}) \leq f(\boldsymbol{s}', \boldsymbol{T})$ 来描述。例如，二元关系 $\boldsymbol{s} \rightarrow \boldsymbol{s}'$（偏好 $\boldsymbol{s}'$ 胜于 $\boldsymbol{s}$）的成立条件是 $f(\boldsymbol{s}, \boldsymbol{T}) < f(\boldsymbol{s}', \boldsymbol{T})$。如果假设二人博弈是对称的，那么有限解集合 $\boldsymbol{S}$ 的成对偏好完全包含在一个有向图（digraph）的结构中 [20]。如果结构允许存在一个独特的优势解 $\boldsymbol{s}^*$，满足对所有 $\boldsymbol{s} \in \boldsymbol{S} \backslash \{\boldsymbol{s}^*\}$，$f(\boldsymbol{s}, \boldsymbol{T}) < f(\boldsymbol{s}^*, \boldsymbol{T})$，则...
最大化问题$\max_{{\boldsymbol s} \in {\boldsymbol S}} f({\boldsymbol s}) = f({\boldsymbol s}^*)$的解为${\boldsymbol s}^*$。实际上，${\boldsymbol T}'={\boldsymbol T}$并未使用，因为计算$f({\boldsymbol s},{\boldsymbol T}), \ {\boldsymbol s} \in {\boldsymbol S}$的代价太高，例如集合${\boldsymbol T}$的规模极大。因此，为了使整个协同进化搜索的计算代价可行，通常使用小规模子集${\boldsymbol T}' \subset {\boldsymbol T}$。在这种情况下，协同进化适应度的相对属性和动态属性在搜索过程中发挥作用。为了理解这两个属性如何影响协同进化搜索，接下来继续先前的例子。

假设初始种群在重复运行中被初始化为相同的一组候选解$\{{\boldsymbol s}_i\}$。注意，为了简化叙述，我们省略了时间$t$和运行标识$k$的下标。然而，在每次运行和迭代过程中，测试用例集有所不同。此外，假设解决方案的适应度值在使用不同的测试用例集时有所不同。在这种情况下，对于初始种群在运行$k=1,2,3,\ldots,K$的场景，适应度值集合为$\{f({\boldsymbol s}_i,{\boldsymbol T}^{\prime}_{1,k})\}$。候选解$\{{\boldsymbol s}_i\}$在复制过程中是否会被选择取决于适应度值$\{f({\boldsymbol s}_i,{\boldsymbol T}^{\prime}_{1,k})\}$。对于优先考虑适应度值的选择机制（如适应度比例选择机制），可以观察到个体的选择概率${\mathbb{P}}_{{\boldsymbol s}_i}$会因运行$k$的不同而改变。对于基于适应度值排序的选择机制，$\{f({\boldsymbol s}_i,{\boldsymbol T}^{\prime}_{1,k})\}$的排序变化可能会影响$\{{\boldsymbol s}_i\}$的复制率。在这一具体例子中，即使初始种群的候选解相同，每次运行$k$的协同进化过程初始轨迹可能有所不同。

更重要的是，在每次运行中协同进化过程的行为或动态对于搜索成功至关重要，这需要设置合适的序列来呈现给候选解种群的测试用例。这通常被描述为军备竞赛动态，其中协同进化过程推动解决方案的搜索，并逐步提升其在针对更为多样化的测试用例时的整体可度量性能。这种动态通常在采用小规模测试用例集的情况下进行，同时这些测试用例集也在动态变化，并不断提高其对于更为多样化解决方案的挑战性。

这一动态在涉及捕食者-猎物协同进化的情况下尤为显著，其中解决方案和测试用例的角色界限十分清晰。然而，正如相关研究明确指出的，这种军备竞赛动态并非在协同进化设置中自动实现。例如，阻碍长期进展的循环动态很常见，并且需要额外的机制来解决这一问题[75]。
### 2.4 共进化中的概念

在之前的讨论中，我们简要提到了共进化过程中候选解和测试案例之间的特殊动态，即它们交替改进的“军备竞赛”现象。这种军备竞赛动力学在实现共进化搜索的成功中至关重要，因为它能够充分利用共进化的主观适应度评估方法，从而限制或解决使用相对和动态适应度值来指导共进化搜索时出现的内在问题。尽管我们以一种特定的共进化设置进行说明，但实际上共进化还设计了其他不同的设置，并被应用于解决各种类型的问题。在这里，我们将介绍并探讨两个重要概念，这些概念用于对各种共进化系统进行分类：其中一个是关于种群结构；另一个是关于协作种群的成员之间的交互类型。请注意，这两个概念并非空泛，它们对于描述这些复杂共进化系统以及识别能够为其分类的共同特征都至关重要。

#### 2.4.1 共进化中的种群结构

共进化系统中的种群结构是指个体在选择和变异过程作用下的具体配置和定位。共进化系统最简单的种群结构是只包含单一泛群（panmictic population）的情形。在这种单一种群共进化中，每个种群成员同时承担候选解和测试案例的双重角色。因此，单一种群共进化通常与**竞争性共进化**相关，但反过来并不一定如此。值得注意的是，大多数单一种群共进化系统常用于解决涉及**游戏对局**的问题（例如 [13]），以及那些具有对抗性性质的问题（例如可以建模为游戏的问题）。后者包括机器人学领域的问题 [78] 和国防领域的问题 [22]。

更加复杂的种群结构涉及**多种群设置**。在这种情况下，共进化系统中包含 $l \geq 2$ 个种群。引入多种群共进化对于构建能够解决不同问题的共进化系统至关重要，因为可以采用不同的机制。特别是，现在可以在共进化中结合多种问题解决方法。进一步区分和分类各种共进化系统需要更多关于共进化特性的概念。其中一个重要的概念是关于种群成员之间交互类型的，这将在下一节中详细讨论。作为简短介绍，有一些设计有特定**分而治之问题解决机制**的共进化系统，特别是这些系统执行问题分解，需要不同种群的成员分别表示分解子问题的候选解。

回到关于共进化特性讨论，多种群设置中的种群结构涉及两个需要进一步展开的重要且相关的方面：分别关于不同种群成员的遗传隔离或独立程度。
我们从两种种群协同进化的简单情况开始讨论。由于两种种群中个体所扮演的角色不同，它们之间可能会出现完全的遗传隔离。在大多数捕食者-猎物协同进化中，候选解和测试案例分别扮演不同的角色，通常具有不同的参数化表示形式。基于此背景，它们被放置在两个独立且相互隔离的种群中，并通过特定的变异操作生成新的种群成员以满足各自种群的演化需求。例如，这种捕食者-猎物模型用于协同进化排序网络的种群与测试案例种群，其中测试案例是需要排序的二进制数字的列表或序列[48]。另一个例子展示了利用捕食者-猎物模型协同进化细胞自动机分类器种群与测试案例种群，其中测试案例是需要分类密度（1或0）的二进制字符串[51, 65]。尽管在这两个例子中使用了编码使得解以二进制字符串形式表示，但用于表示解和测试案例的二进制字符串的长度不同，且关键在于指向解的优化性和测试案例的挑战评定的底层结构，这使得尝试在两种群之间使用交叉操作变得无意义。需要注意的是，在某些捕食者-猎物模型中，例如[50]中，实现协同进化的机器人分别具有不同的表型角色，例如追逐和逃避（如最大速度等具体规格），但在这些案例中底层基因型表示是相同的，即以人工神经网络（ANNs）作为控制器。另外，实现协同进化种群遗传隔离的一个重要原因还在于在系统中设计特性或机制以促进种群多样性，从而保证长期且持续的搜索性能。例如，捕食者-猎物模型可用于实现两人游戏的代理协同进化[72]，在此情况下，两种群中的成员或代理扮演相同的角色。种群之间仍然完全独立隔离，同时设计了其他增强多样性的机制，如适应度共享，以作为该协同进化系统的一部分以提升搜索性能。

这种双种群设置可以扩展为多种群设置。在[83]中，发展了九种群竞争协同进化模型，并显示该模型在搜索赛车控制器时具有优于单种群竞争协同进化的搜索性能。研究中采用了遗传隔离机制。然而，也可以引入迁移机制到这种多种群协同进化模型中，其中规定种群中的成员均扮演相同角色，并构成问题的完整候选解。在后一种情况下，多种群设置类似于为演化算法（EAs）引入并使用的岛屿模型[7, 79]。
### 2.4.2 共演化中的交互作用

交互作用在共演化中至关重要，因为它是个体适应度值被导出、获取和通过某种定义的解概念进行解释的内在机制，并用于指导搜索过程。[25]。迄今为止，我们的讨论主要集中于那些适宜被建模为竞争性和非合作性博弈的共演化交互作用，这是因为许多真实世界的问题具有对抗性质。对于单种群竞争性共演化来说，最简单的交互作用形式是对称的两人博弈。在这种情况下，两名玩家之间没有任何区别，即作为解和测试案例的角色完全相同。任意一个玩家可以从同一策略集$S$（或$\boldsymbol{S}$）中实施博弈策略。对称两人博弈可以同时进行。一些简单的例子包括IPD[1]（迭代囚徒困境）和鹰鸽博弈[34, 39, 40]。对于这些仅包含单轮次、一招一式的博弈，可以很容易地对交互作用及其结果进行完整规范描述。

每个博弈可以表述为一个对$(s_i, s_j) \in S \times S$（或$({\boldsymbol{s}}_i, {\boldsymbol{s}}_j) \in {\boldsymbol{S}} \times {\boldsymbol{S}}$），其中第一个玩家（用下标$i$表示）和第二个玩家（用下标$j$表示）实现的策略来自同一策略集，$s_i, s_j \in S$（或${\boldsymbol{s}}_i, {\boldsymbol{s}}_j \in {\boldsymbol{S}}$）。笛卡尔积$S \times S$（或${\boldsymbol{S}} \times {\boldsymbol{S}}$）指定了可以在任何策略组合$(s_i, s_j)$（或$({\boldsymbol{s}}_i, {\boldsymbol{s}}_j)$）上进行的所有博弈。在一个包含$V = |S|$（或$V = |{\boldsymbol{S}}|$）个纯策略的两人博弈中，可能的博弈数为$V^2$。

对于单轮次同时博弈，游戏结果可以直接通过收益来表述。然后，所有可能博弈的结果存储在一个称为正规形式（或标准形式）的方形收益矩阵中[58]。对于第一位玩家，其收益矩阵表示为$\mathbf{A} = (a_{ij} : 1 \leq i,j \leq V)$，其中每个元素$a_{ij}$表示$(s_i, s_j)$（或$({\boldsymbol{s}}_i, {\boldsymbol{s}}_j)$）互动结果的非负收益。对称的博弈结构允许直接通过转置得到第二位玩家的收益矩阵$\mathbf{B} = \mathbf{A}^{\mathsf{T}}$，即$(b_{ij} : 1 \leq i,j \leq V) = (a_{ji} : 1 \leq i,j \leq V)$。

可以建模更复杂的两人互动或角色之间的博弈。这类单轮次同时博弈，其结果由标准形式矩阵描述，可以扩展到多轮。其中一个经典例子是已被广泛研究的IPD博弈[12, 17, 19, 36, 37, 43]。需要注意的是，在原始囚徒困境或其他可以用标准形式描述的博弈中，由于参与的矩阵规模较小，通常能够立即进行分析。这包括确定是否有支配策略[58]，支配策略定义为：某个策略$s_i \in S$（或${\boldsymbol{s}}_i \in {\boldsymbol{S}}$），其对任何对手策略$s_j \in S$（或${\boldsymbol{s}}_j \in {\boldsymbol{S}}$）的结果$a_{ij}$满足$a_{ij} \geq a_{kj}$（其中$s_k \in S$或${\boldsymbol{s}}_k \in {\boldsymbol{S}}$为任意其他备选策略）。

但可以观察到，扩展这些博弈，例如引入多轮或其他类型的扩展（如多选项[14]），会导致纯策略数量的组合爆炸。这使得对博弈进行即时分析变得不可行，除非对博弈结果矩阵施加强约束。更重要的是，在涉及两位玩家的其他形式交互中，交互并非仅仅是从固定集合中抽取动作序列（例如囚徒困境中的“合作”与“背叛”）。棋类博弈是按序进行的，可能存在不对称角色（如白棋和黑棋可能拥有不同的玩法策略），其动作序列极其复杂、非线性且受到约束[16, 38, 41]。

这意味着，为了获取两位玩家的结果，必须通过直接模拟或计算实现博弈。这种情况在大多数实际共演化应用中遇到。

然而，共演化中的交互并不仅限于对抗性互动，它们也可以表现为合作博弈。事实上，在合作共演化框架的初始研究中[67]，已有文献和讨论提到了自然与人工系统中的真实世界问题，这些问题需要多个代理之间进行某种形式的联合互动以形成完整的解决方案。此外，结合合作博弈论的语言，还涉及确定是否有某些具体的代理联盟在作为一个整体时比其他联盟更优或更受偏好。

少数研究（例如[64, 86]）明确运用了合作共演化系统的博弈论分析。这些研究专注于一个涉及团队自适应代理的多智能体学习环境，这些代理必须同时学习并联合互动以解决任务。在这种环境中产生的挑战可以通过合作共演化学习系统自然地得到解决。进化机器人学是一个问题领域，其中合作共演化系统被广泛应用[42]。除了制定联合互动以解决协调任务所带来的复杂性之外，这些问题设置中的质量或适应度评估也极为复杂。

由具体代理联盟组成的联合解决方案，每个代理代表系统中多个种群之一，可以进行质量或适应度的评价。对于单个代理，其质量或适应度可能依赖于团队其余部分的具体组成。因此，通过代理对团队表现的边际贡献来精确确定代理的适应度可能具有挑战性或计算代价高昂。这需要检查从各自种群中抽取的所有可能代理组合，因此，在实际工作中，代理的适应度通常只能估计。

合作共演化还被应用于其他问题场景，例如包含问题分解为子问题的优化问题[56]。这里涉及候选解之间的互动...
其各自子问题的解与问题分解的性质密切相关。这是因为，在这种情况下，Divide-and-Conquer（分而治之）策略的关键在于识别独立的子问题或子组件，并能够对这些子组件的候选解进行评估。在研究中关注的具体性质是问题的可分性（separability）。为了说明这种可分性的概念，考虑一个具有$n$维解空间$S = \mathbb{R}^n$的连续优化问题。假设是最小化问题，一个完全可分的优化问题$f: S \rightarrow \mathbb{R}$应满足如下定义。
\[
\mathop{\mathrm{argmin}}_{x_1,\ldots,x_n} f({\boldsymbol x}) = \bigg(\mathop{\mathrm{argmin}}_{x_1} f(x_1,\ldots), \ldots, \mathop{\mathrm{argmin}}_{x_n} f(\ldots, x_n) \bigg).
\]

完全可分优化不涉及决策变量$x_i$之间的任何依赖关系。事实上，完全可分的$n$维最小化问题可以被重新表述为$n$个独立的一维最小化问题，并分别求解。通过建立$l = n$个独立种群，也可以通过协作共同演化来解决此类问题。当优化目标函数完全是加性可分时，适应度评估变得非常简单：
\[
f({\boldsymbol x}) = \sum_{i}^{n} f(x_i),
\]
只需标识出其余$n - 1$个子组件的代表性候选解即可。

对于一些非可分问题，它们在某种程度上是加性可分的，可表示为：
\[
f({\boldsymbol x}) = \sum_{i}^{m} f_i({\boldsymbol x}_i),
\]
其中存在$m \leq n$个独立子组件${\boldsymbol x}_1,\ldots,{\boldsymbol x}_m$。如果能够识别出具有依赖关系的决策变量并将它们归为一组，这些问题可以直接被解决。针对决策变量分组的机制包括随机方法[53]以及利用搜索方法[62]的技术。

---

### 2.5 结束语及进一步阅读的提示

在我们的介绍中，我们尝试将协作演化计算（Coevolutionary Computation）作为一种通用问题解决框架进行阐述，同时从更系统的角度介绍了其历史发展。在这一过程中，我们特别将协作演化系统作为一种基于演化的通用方法，以解决涉及战略决策的情景问题。这类问题可以被抽象化并建模为博弈。协作演化计算与博弈论之间存在自然的联系，因为两个领域的研究基础都基于“交互”的概念。

我们后续介绍了该框架在机器学习与优化背景下问题的应用，并进一步扩展到更高层次的问题解决，如元启发式算法和超启发式算法（metaheuristics和hyper-heuristics）。在竞争性协作演化设定中，这类协作演化系统中的候选解或代理则类似于算法。这时，协作演化原理不是搜索优化问题中常规决策变量的参数空间，而是搜索优化算法参数空间。具体优化算法（策略）实现的代理性能通过针对优化问题实例生成进行测试评估。

应用协作演化计算的关键要点是如何将问题解决设定框架化，使候选解演化过程与测试案例生成过程耦合在一起。这种耦合机制通过候选解和测试案例两个种群之间的交互实现。虽然两个种群是互相独立或隔离的，但它们的交互能够产生适应度或质量评估，用于各自种群内部选择某些候选解（测试案例）进行再生产。
我们以对协同进化计算与机器学习简要的说明结束本章节，这两个研究领域之间存在一些共同点。我们在此的讨论主要集中于从系统的角度探讨个体组件的共享设计特性。而我们的讨论会限制在概念层面，而非具体的实现细节。此外，我们会关注具有对抗性质的交互，并将其建模为竞争性游戏，在这种设定下，关注概念上的相似性更为直接。我们从协同进化原则的更宽泛或一般视角开始探讨，这里主要关注代理交互作为核心概念性连接点，而非起源于与不断变化或进化集合（例如，协同进化中的动态适应性景观视图[10]）的交互所产生的相对适应度评估的具体细化。

特别地，早期关于竞争性协同进化的研究之一明确参考了机器学习方法中使用的机制[70]。该研究主要因引入了两个重要机制而闻名：(1)一种通过适应度共享的多样性维护技术，以及(2)一个称为名人堂（Hall-of-Fame）的外部档案，用于存储特定的测试案例（对手策略），类似于禁忌搜索机制，旨在促进协同进化中的军备竞赛动态。该研究采用捕食者-猎物协同进化系统实现竞争性游戏的学习过程。有兴趣的读者可以注意到，作者早先在[69]中已经制定了竞争性游戏学习的理论框架。尽管该研究主要是理论性，并且大多涉及其提出的竞争性游戏计算学习算法的复杂性分析（例如，为发现主导策略建立时间复杂性），这些理论结果确立且指导了[70]中两种种群竞争性协同进化学习系统中具体机制的设计。

所提出的计算学习算法的复杂性分析依赖于一个具体且理想化的构造，其中包括两组不同的学习者和教师。这两组成员之间的交互被定义为两位玩家的竞争性游戏。学习者集合（学习集）代表一个种群，其成员通过迭代地应用学习算法可以发生变化，并且游戏的主导策略或最优策略的搜索过程发生于此。教师集合（教学集）构成用于评估学习者表现并区分学习者的对手策略。教师集合也应用了迭代算法，以确保满足区分学习者的第二项功能。每当当前学习者集合中的任何学习者被当前教师集合中的至少一个教师击败时，这一功能即被实现。

该过程的理论结果已为实现教学集合的重要需求提供了洞察（即，只要能够区分学习者，可以采用规模较小的集合）。这些需求后来通过适应度共享机制和外部档案的应用被封装吸收。
读者可以注意到，[69, 70] 使用了许多来自机器学习研究的概念和术语。这并不令人意外，因为这些研究旨在为竞争性博弈开发一个计算学习框架，同时受到早期在 [48] 中引入的演化方法的启发和影响。同样地，我们在 [17, 19] 中通过使用泛化(generalization)的概念来客观地评估竞争性协同进化（coevolution）的性能表现。为了简化介绍，我们考虑以对称的两人博弈形式进行分析。这类性能评估的核心在于将策略与从策略空间 $\boldsymbol{S}$ 中随机抽取的测试（对手）策略样本进行评价，其基础的概率分布为 $\mathbb{P}_{\!\boldsymbol{S}}$。令 $i, j \in \boldsymbol{S}$ 表示策略 $\boldsymbol{s}_i, \boldsymbol{s}_j \in \boldsymbol{S}$，策略 $i$ 的泛化性能 $G_i$ 定义为其期望性能：

\[
G_i = \mathbb{E}_{\mathbb{P}_{\!\boldsymbol{S}}(j)}[G_i(j)] = \sum_j^{|\boldsymbol{S}|} \mathbb{P}_{\!\boldsymbol{S}}(j) G_i(j),
\]

其中随机变量 $J$ 代表从 $\boldsymbol{S}$ 中以概率 $\mathbb{P}_{\!\boldsymbol{S}}(j)$ 选择策略 $j$，$G_i(j)$ 是策略 $i$ 和策略对 $\{i, j\}$ 之间的博弈结果。可以利用从 $\boldsymbol{S}$ 中随机抽取的一小组测试策略 $S_N = \{\boldsymbol{s}_1, \ldots, \boldsymbol{s}_N\}$ （其中 $N < |\boldsymbol{S}|$，参见 [17]）构建策略性能 $G_i$ 的无分布估计，同时使用已知的置信区间确定性能估计。通过利用中央极限定理对随机样本序列 $\{G_i(\boldsymbol{s}_1), \ldots, G_i(\boldsymbol{s}_N)\}$ 的近似高斯分布，可以收紧松散的置信区间，估计公式为：

\[
\hat{G}_i(S_N) = \frac{G_i(\boldsymbol{s}_1) + \cdots + G_i(\boldsymbol{s}_N)}{N}.
\]

后续研究 [66] 更明确地建立了竞争性协同进化（定义于协同优化(cooptimization)框架）的概念与监督学习之间的联系。这是通过将监督学习中的概念形式映射到协同优化框架中来实现的。该研究首先定义了协同优化的问题设置，正如我们在第2.3节引入协同进化中的适应度评估时所提到的那样。具体而言，协同优化中的竞争性协同进化涉及在解空间 $\boldsymbol{S}$ 上搜索，以最大化目标函数：

\[
f(\boldsymbol{s}) = \sum_{\boldsymbol{t} \in \boldsymbol{T}} M(\boldsymbol{s}, \boldsymbol{t}),
\]

其中 $M(\boldsymbol{s}, \boldsymbol{t})$ 是性能指标，由函数 $M : \boldsymbol{S} \times \boldsymbol{T} \rightarrow F$ 给出，且 $F \subset \mathbb{R}_{\geq 0}$。例如，一类协同优化问题可能包括以对称两人竞争博弈形式的交互，其胜负结果在集合 $\{0, 1\} \subset \mathbb{R}_{\geq 0}$ 中（如胜利时赋值为实数 $1$，失败时赋值为 $0$）。在这种设定下，目标是找到最优策略 $\boldsymbol{s}^*$，使 $f(\boldsymbol{s})$ 达到最大值，即：

\[
\max f(\boldsymbol{s}) = f(\boldsymbol{s}^*),
\]

此处 $\boldsymbol{T} = \boldsymbol{S}$，且 $\boldsymbol{s}^*$ 是一个占优策略，它满足对于所有 $\boldsymbol{t} \in \boldsymbol{T} \backslash \{\boldsymbol{s}^*\}$，有 $0 < M(\boldsymbol{s}^*, \boldsymbol{t})$ [20]。

类似地，研究 [66] 描述了监督学习环境如何通过协同优化的形式框架加以表达，并选择二元分类问题家族作为例子。在监督学习的设定中，问题解决涉及寻找正确的分配或目标函数：

\[
g : \boldsymbol{X} \rightarrow \boldsymbol{Y},
\]

其中 $\boldsymbol{X}$ 是待分类的对象集合，$\boldsymbol{Y} = \{0, 1\}$ 是标签集合。目标函数 $g$ 的学习通过一个有限的已标记样本集 $\{(\boldsymbol{x}_i, \boldsymbol{y}_i)\} \subset \boldsymbol{X} \times \boldsymbol{Y}$ 来监督，其中每个样本由对象 $\boldsymbol{x}_i$ 及其正确标签 $\boldsymbol{y}_i$ 对 $(\boldsymbol{x}_i, \boldsymbol{y}_i), i = 1, \ldots, N$ 构成。在实际操作中，$g$ 被实现为一种参数化形式的分类器函数 $c$，其内部参数由 $\boldsymbol{s} \in \boldsymbol{S}$ 表示。我们写为：

\[
c_{\boldsymbol{s}} : \boldsymbol{X} \rightarrow \boldsymbol{Y},
\]

以强调 $\boldsymbol{s} \in \boldsymbol{S}$ 的函数（输入-输出）响应。在协同优化形式框架中，参数 $\boldsymbol{s} \in \boldsymbol{S}$ 的搜索过程使用测试用例集合 $\{\boldsymbol{t}_i\} \subset \boldsymbol{T} = \boldsymbol{X}$ 以及性能指标：

\[
M(\boldsymbol{s}, \boldsymbol{t}) = 1 \{g(\boldsymbol{t}) = c_{\boldsymbol{s}}(\boldsymbol{t}) \}.
\]
$M({\boldsymbol s},{\boldsymbol t}) = {\mathbf{1}}_{\{g({\boldsymbol t})\}} \big(c_{{\boldsymbol s}}({\boldsymbol t})\big)$，其目标是最大化 $f({\boldsymbol s}) = \mathbb{E}_{{\boldsymbol t} \in {\boldsymbol T}} M({\boldsymbol s}, {\boldsymbol t})$，也可以写为 $f({\boldsymbol s}) = \sum_{{\boldsymbol t} \in {\boldsymbol T}} M({\boldsymbol s},{\boldsymbol t})$。注意，度量 $M({\boldsymbol s},{\boldsymbol t})$ 的类型是 $S \times T \to F$，其中 $F = \{0, 1\}$，由集合 $\{g({\boldsymbol t})\}$ 的指示函数定义。集合 $\{g({\boldsymbol t})\}$ 表示所有可分类对象 ${\boldsymbol t} \in {\boldsymbol X}$ 的正确标签。在这种情况下，如果一个分类器 ${\boldsymbol s}^*$ 能够正确分类集合 ${\boldsymbol X}$ 中的所有对象，并且满足 $\max f({\boldsymbol s}) = |{\boldsymbol T}| = |{\boldsymbol X}|$，则称其为最优分类器。特别地，当分类器与测试样本的实际标签一致时，即 $c_{{\boldsymbol s}}({\boldsymbol t}) = g({\boldsymbol t})$，满足 ${\mathbf{1}}_{\{g({\boldsymbol t})\}} \big(c_{{\boldsymbol s}}({\boldsymbol t})\big) = 1$。

这个度量可以通过零一损失函数重新定义为一种误差度量，表达如下：
\[
L({\boldsymbol s},{\boldsymbol t}) = 1 - {\mathbf{1}}_{\{g({\boldsymbol t})\}} \big(c_{{\boldsymbol s}}({\boldsymbol t})\big)
\]
此时目标变为最小化损失函数 $f({\boldsymbol s}) = \mathbb{E}_{{\boldsymbol t} \in {\boldsymbol T}} L({\boldsymbol s}, {\boldsymbol t})$，也可以写为 $f({\boldsymbol s}) = \sum_{{\boldsymbol t} \in {\boldsymbol T}} L({\boldsymbol s},{\boldsymbol t})$。

本章结尾比较了竞争性协同演化学习（Competitive Coevolutionary Learning）与时间差（Temporal Difference，简称 TD）学习，这是一类增强学习方法，在学习竞争性游戏策略方面得到了成功应用 [81]。一些研究（如 [71]）比较了协同演化学习和 TD 学习在竞争性游戏中的表现。两种方法都能通过某种自举机制（bootstrapping mechanism）在缺乏适当的目标教师集合或函数的情况下，适应代理行为与环境的交互。在竞争性游戏学习中，这些自举机制通常通过代理（可能是不同版本的）作为对手来生成游戏对局，从而指导学习过程。然而，这种相似性仅限于此，因为协同演化学习和 TD 学习的关键差异在于它们对游戏对局的利用方式。

协同演化学习通过多个代理策略在完整游戏对局中的结果来评估性能差异，从而指导搜索。而 TD 学习则通过代理的自我对局，使用游戏中的操作序列来指导搜索 [81]。这种根本差异来源于二者如何进行问题求解的不同解释，尽管在两种方法中都使用了类似的人工神经网络（ANN）作为解决方案表示形式 [71]。

在协同演化学习中，人工神经网络被作为一种非线性响应函数，将输入（游戏状态）映射到输出（合法动作），因此直接在游戏策略的空间中进行搜索。

而在 TD 学习中，人工神经网络被作为值函数（value function）的函数逼近器，将每一个游戏状态映射到一个长期性能度量。这个值函数与实现游戏策略（政策）的控制器相关联 [9]。
参考文献

1. Ashlock, D.A.: 关于图结构上的囚徒困境中的合作问题。在IEEE计算智能与游戏研讨会（CIG 2007）的论文集中，第48–55页（2007年）。
2. Axelrod, R.: 囚徒困境中的有效选择。《冲突解决期刊》24(1)，第3–25页（1980年）。
3. Axelrod, R.: 囚徒困境中的更有效选择。《冲突解决期刊》24(3)，第379–403页（1980年）。
4. Axelrod, R.: 在迭代囚徒困境中策略的演化研究。发表于Davis, L.D.（编辑）的《遗传算法与模拟退火》，第3章，第32–41页。出版商：Morgan Kaufmann, New York（1987年）。
5. Bäck, T., Hammel, U., Schwefel, H.-P.: 演化计算：关于演化计算历史与现状的若干评论。《IEEE演化计算学报》1(1)，第3–17页（1997年）。
6. Barricelli, N.A.: 数值测试演化理论：第二部分，性能、互生演化及陆地生命的初步测试。《生物理论方法学报》16(3–4)，第99–126页（1963年）。
7. Belding, T.C.: 用于超立方体的并行遗传算法。发表于Eshelman, L.J.（编辑）的第六届国际遗传算法会议论文集，第114–121页。出版商：Morgan Kaufmann, San Francisco（1995年）。
8. Bongard, J.C., Lipson, H.: 使用模型与测试的协同演化进行非线性系统识别。《IEEE演化计算学报》9(4)，第361–384页（2005年）。
9. Bradtke, S.J., Barto, A.G.: 时间差学习的线性最小二乘算法。《机器学习期刊》22，第33–57页（1996年）。
10. Bullock, S.: 动态适应性景观。技术报告：《研究论文CSRP 350》，认知与计算科学学院，Sussex大学（1994年）。
11. Cartlidge, J., Bullock, S.: 通过降低寄生性任务的毒性应对协同演化的脱离问题。《演化计算学期刊》12(2)，第193–222页（2004年）。
12. Chellapilla, K., Fogel, D.B.: 演化、神经网络、博弈与智能。《美国电气与电子工程学会学报》87(9)，第1471–1496页（1999年）。
13. Chellapilla, K., Fogel, D.B.: 不依靠人类经验演化一个专家级的西洋跳棋程序。《IEEE演化计算学报》5(4)，第422–428页（2001年）。
14. Chong, S.Y., Yao, X.: 行为多样性、选择与迭代囚徒困境中的噪声问题。《IEEE演化计算学报》9(6)，第540–551页（2005年）。
15. Chong, S.Y., Yao, X.: 多选项与名誉在多智能体交互中的作用。《IEEE演化计算学报》11(6)，第689–711页（2007年）。
16. Chong, S.Y., Tan, M.K., White, J.D.: 观察学习奥赛罗游戏的神经网络的演化过程。《IEEE演化计算学报》9(3)，第240–251页（2005年）。
17. Chong, S.Y., Tiˇno, P., Yao, X.: 在协同演化学习中测量泛化性能。《IEEE演化计算学报》12(4)，第479–505页（2008年）。
18. Chong, S.Y., Tiˇno, P., Yao, X.: 协同演化学习中泛化与多样性之间的关系。《IEEE计算智能与人工智能游戏学报》1(3)，第214–232页（2009年）。
19. Chong, S.Y., Tiˇno, P., Ku, D.C., Yao, X.: 提高协同演化学习中的泛化性能。《IEEE演化计算学报》16(1)，第70–85页（2012年）。
20. Chong, S.Y., Tiˇno, P., He, J., Yao, X.: 一种分析协同演化系统的新框架——有向图表示与随机游走。《演化计算学期刊》27(2)，第195–228页（2019年）。
21. Darwen, P.J., Yao, X.: 物种分化作为自动类别化模块化。《IEEE演化计算学报》1(2)，第101–108页（1997年）。
22. Darwen, P.J., Yao, X.: 在迭代囚徒困境中应用中等水平合作协同演化：用于导弹防御的研究。《计算智能应用国际期刊》2(1)，第83–107页（2002年）。
23. Darwin, C.: 《物种起源：通过自然选择或在生存斗争中保护有利种类》。出版商：John Murray, London（1859年）。
24. de Jong, E.D.: 协同演化中的Maxsolve算法。发表于2005年遗传与演化计算会议（GECCO’05）的论文集，第483–489页（2005年）。
25. de Jong, E.D., Pollack, J.B.: 从协同演化中理想评估。《演化计算学期刊》12(2)，第159–192页（2004年）。
26. Dobzhansky, T.: 《遗传学与物种起源》。出版商：哥伦比亚大学出版社，纽约（1937年）。
27. Ehrlich, P.R., Raven, P.H.: 蝴蝶与植物：协同演化研究。《演化期刊》18(4)，第586–608页（1964年）。
28. Eiben, A.E., Smith, J.: 从进化计算到物体演化。《自然》521，第476–482页（2015年）。
29. Falgueras-Cano, J., Falgueras-Cano, J., Moya, A.: 使用演化型元胞自动机的数字生物体协同演化研究。《生物学》10(11)，第1147页（2021年）。
30. Ficici, S.G.: 协同演化算法中的解概念。博士论文，Brandeis大学，MA（2004年）。
31. Ficici, S.G., Pollack, J.B.: 协同演化学习中的挑战：军备竞赛动力学、开放性及平庸稳定状态。发表于Adami, C., Belew, R.K., Kitano, H., Taylor, C.（编辑）的《人工生命VI：第六届国际人工生命会议论文集》，第238–247页。出版商：MIT出版社，剑桥（1998年）。
32. Ficici, S.G., Pollack, J.B.: 协同演化学习中的帕累托最优性。发表于第六届欧洲人工生命会议（ECAL’01）。《Lecture Notes in Computer Science》，卷2159，第316–325页。出版商：Springer，布拉格（2001年）。
33. Ficici, S.G., Pollack, J.B.: 协同演化中的游戏理论记忆机制。发表于2003年遗传与演化计算会议（GECCO’03）。《Lecture Notes in Computer Science》，卷2723，第286–297页。出版商：Springer，柏林（2003年）。
34. Ficici, S.G., Melnik, O., Pollack, J.B.: 协同演化选择方法的博弈论与动力学系统分析。《IEEE演化计算学报》9(6)，第580–602页（2005年）。
35. Fisher, R.A.: 《自然演化理论的遗传学基础》。出版商：Clarendon出版社，牛津（1930年）。
36. Fogel, D.B.: 在迭代囚徒困境中演化行为的研究。《演化计算学期刊》1(1)，第77–97页（1993年）。
37. Fogel, D.Б.: 探讨遭遇持续时间和迭代囚徒困境中的合作演化之间的关系。《演化计算学期刊》3(3)，第349–363页（1996年）。
38. Fogel, D.B.: 《Blondie24：人工智能的边缘游戏》。出版商：Morgan Kaufmann, San Francisco（2002年）。
39. Fogel, D.B., Fogel, G.B., Andrews, P.C.: 关于演化稳定策略的不稳定性。《生物系统》44，第135–152页（1997年）。
40. Fogel, D.B., Fogel, G.B.: 使用鹰-鸽博弈模拟有限人口的淘汰机制中的自然选择。《生物系统》104，第57–62页（2011年）。
41. Fogel, D.B., Hays, T.J., Hahn, S.L., Quon, J.: 一种自学习进化型国际象棋程序。《IEEE学报》92(12)，第1947–1954页（2004年）。
42. Fontbonne, N., Maudet, N., Bredeche, N.: 用于多机器运动资源分配问题的合作协同演化与适应性团队组成。发表于欧洲遗传编程会议（EuroGP 2022）。《Lecture Notes in Computer Science》，卷13223，第179–193页。出版商：Springer，柏林（2022年）。
43. Franken, N., Engelbrecht, A.P.: 粒子群优化方法协同演化策略，用于迭代囚徒困境问题。《IEEE演化计算学报》9(6)，第562–579页（2005年）。
44. Futuyma, D.J.: 今日演化生物学与扩展综合的呼吁。《界面焦点》7，文章编号20160145（2017年）。
45. García-Pedrajas, N., Hervás-Martínez, C., Ortiz-Boyer, D.: 合作协同演化人工神经网络组用于模式分类。《IEEE演化计算学报》9(3)，第271–302页（2005年）。
46. Gershenson, C., Trianni, V., Werfel, J., Sayama, H.: 自组织与人工生命。《人工生命期刊》26(3)，第391–408页（2020年）。
47. Haldane, J.B.S.: 《演化的原因》。出版商：Longmans, Green和Co., New York（1932年）。
