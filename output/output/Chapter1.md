# 第1章 演化计算：概述

## 1.1 演化计算作为一种现代搜索启发式方法

作为人工智能（AI）方法的一个现代分支，演化计算包含了受自然进化过程启发的计算系统和程序。它们被用于解决复杂的现实世界问题，并在合理的时间内提供足够优质的解决方案。演化计算被广泛应用于从物理、生命科学到社会科学等各类领域，既适用于被建模为优化与学习任务的问题，也适用于涉及建模和仿真的问题。在这些情形下，演化计算为那些经典精确方法无法在规定时间内保证获得最优解、需要针对特定问题结构做大量扩展或对支撑其大量形式化构造的强假设进行放宽的问题，提供了可行的替代方案。

尽管演化计算所采用的方法与经典方法在原理上存在根本性的不同，但两者之间同样存在共通点。实际上，通过搜索进行问题求解的思想具有普遍性，涵盖了众多方法家族 [114]。这些演化算法（EAs）是在一种“生成-测试”框架下被构建的，其核心是可以在计算机上实现的迭代过程 [131]。因此，问题求解实际上是对解空间进行迭代搜索。在每一步中，都会生成新的候选解，并依据一组测试准则对其进行检验，以判断搜索目标是否已经达成，从而决定是否终止搜索。较为直接的方法是利用问题定义来制定测试准则，同时可以采用不同且系统的方法来生成后续候选解。

然而，这种无信息（uninformed）搜索方式存在潜在的局限性。通过一个简单的例子说明，假设问题涉及离散结构，并且其解的表示参数化为使得整个有限解空间可以被排列成唯一候选解的列表。若暂停对搜索的终止，且保持问题本身不变，无信息搜索在特定生成方法下的行为，将近似于在这个列表的某一特定排列上进行操作。其搜索行为可理解为按照顺序由左至右遍历，在每一步对候选解进行测试。最坏情况下的搜索场景是，最能满足测试准则的候选解最后被生成，也就是位于该列表最右端。
同样的论点也适用于在生成后继体的策略固定而问题发生变化的情形。关键在于，如果希望通过牺牲部分最优性来避免最坏情况，从而在更短时间内获得可接受质量的次优解，那么还需要对问题本质具有额外（即便是部分）的知识。在实践中，这体现在使用某种启发式函数，该函数指示当前候选解距离最优解的远近，以引导后继候选解的选择。此外，人们还可以将后继候选解的生成限定在由变换算子定义的较小邻域内。现代启发式方法结合了上述两种方法论特征，进而产生了实际将搜索限制在解空间子集上的迭代搜索算法。继续我们的简单例子，当前的搜索空间实际上是一份显著缩短的列表。当然，现代启发式搜索方法采用了复杂的过程，即便它们的理论模型仅应用于现实问题的抽象时，也需要高度发展的数学工具进行分析。事实上，这对于进化算法（EAs）同样适用。一个例子是，在把进化算法作为处理离散优化问题的随机算法类别进行理论分析时所使用的概率论方法[47]。分析中所遇到的挑战来自于进化算法的搜索行为特性。理论分析需要：（i）在每一个时间步对代表整个候选个体群体的EA状态进行描述；（ii）跟踪这些状态随着群体进化而发生的变化。群体式EA所操作、且分析必须进行的状态空间，与其底层的搜索空间不同，而且更加复杂。尽管这些工具的发展推动了对EA的严格分析，也为设计和构建更高效EA提供了新的见解，但演化计算领域的部分根基依然是实验性的。对自然进化过程的观察为五六十年代这些新兴方法背后的部分基本原理提供了动力来源[13, 14, 20, 22, 64, 65]。感兴趣的读者会注意到，这些早期研究并不仅限于探讨将进化方法应用于某些抽象优化与决策问题。例如，文献[20]提出了一种EA类似的过程，将其应用于当时算力有限机器的工业制造运筹学背景中。还有研究致力于在有限计算机上实现进化过程，从而探究其与复杂自适应系统（Complex Adaptive Systems）和人工生命（Artificial Life）类似的涌现特性[11, 12, 61]。随后其他独立研究相继开展，形成了若干前驱分支。这些分支后来在九十年代，随着该领域的确立与统一，被统称为演化计算（Evolutionary Computation）的三大独立分支[9, 58]，即遗传算法（Genetic Algorithm, GA）、进化规划（Evolutionary Programming, EP）以及进化策略（Evolution Strategies, ES）。随后还引入了一些新方法，这些方法起初与前三大分支类似，但经过显著的发展，最终形成了自身独立的类别。部分新类别采用了诸如粒子群优化（Particle Swarm Optimization, PSO）[19, 34, 87]和分布估计算法（Estimation of Distribution Algorithm, EDA）[77, 96, 110]等术语。
在这里，对于熟悉或初学演化计算与神经计算的读者来说，值得注意的是，人工智能的创始人之一、图灵机和图灵测试的发明者[124]早在1948年就已经提出了有关这两种计算方法的一些模型与方法论（该报告于20年后，即1968年发表）[36]。在这份关于智能机器的报告[125]中，他在设计首台计算机之一——自动计算引擎（Automatic Computing Engine），并进行其试验版实体构建的同时，构想了三种统称为“无组织机器”的计算模型。尤其是，所提出的A型机器令人联想到布尔网络[86]，由固定连接的基础计算单元组成，每个单元能执行带有两个输入和一个输出的布尔函数，且具备功能完备性（例如，NAND门）[25]。与允许信号以不变形式通过的固定互连A型机器不同，B型机器的连接方式为可修改的开关型连接，信号可以被改变。赋予B型机器这种连接的主要概念目的是，使初始的无组织机器可以通过这些连接功能的演化变更，被转化为能够通过包括进化搜索和文化搜索在内的学习过程完成计算任务的有组织机器[124, 125]。

在现代背景下，遗传算法（GA）被视为并应用为一种进化方法，其采用二进制编码的解表示以及相关的遗传算子[40, 66]。为了直观说明GA搜索的准备方式，考虑非层次性的解表示问题。候选解即为由基础集合的笛卡尔积形成的搜索空间中的点。每个集合可以为离散型或支持指定长度的二进制字符串编码的浮点数类型，以便覆盖所有不同的元素。这种坐标定位方式保证了编码的可逆性（因为它是一一对应的映射）。对使用者来说，实用性体现在解的参数化现在表现为一条长且连续的二进制字符串，这类似于生物染色体。此时可以定义遗传算子，例如交叉算子，即从一对候选解的二进制字符串的随机选定位置之间交换相邻的等长区块，形成新的一对候选解。然而，Holland[80, 81]提出并进一步发展的GA理论，要求提出一种通过遗传适应进行计算的理论。目前常见的应用方式只是该理论的一个应用性解释。例如，解或程序并不限于作为函数或参数的优化器[42]。

同样，现代进化规划（EP）的成功似乎表明该方法是为参数优化而发展起来的。以此类观点如何产生为例，可以关注[60]中一名AI智能体被训练以无预编程知识的情况下进行两人零和棋类游戏，表现接近人类专家水平的最终结果。对实际应用而言，系统设计以训练棋类博弈智能体至关重要。在这种情况下，参数化的解表示被构建为一个大型前馈神经网络，对棋局进行评估，并用于浅层极小极大搜索以执行博弈。训练的成功似乎依赖于EP通过特定的变异算子对神经网络连接权重施加微小扰动，从而优化网络的效率。然而，Fogel[56]最早提出并被他人[5, 23]研究的方法，起初是作为发展人工智能的更广泛方法构想的。最早的实验主要采用有限状态机作为解的表示方式（例如，用于游戏策略[23]），其目的在于：

(i) 探索智能（尤其是行为智能在符号预测形式下的抽象）可以被演化的这一思想；
(ii) 展示智能行为可以适应，也就是说，进化变化可以直接作用于个体层面。
在这三种方法中，进化策略（ES）的发展动机更侧重于实际问题的求解应用。早期的研究包括了迭代过程及其相关分析[17, 112, 115]。在实验参数优化的最初设定中，候选解会经历物理上的调整，随后通过实际测量进行性能评估。这些随机启发式方法旨在对设计参数引入小且变化的调整，然后对其性能进行评估，同时可能受到噪声的干扰。这些调整值取自某种概率分布，从而得到随机过程，在具有多峰性且明显噪声存在的实际物理工程优化情境中，其性能超过了基于梯度的数值优化方法[17]。高性能计算机的出现及其更广泛的可获得性，推动了相关发展的加速。结合适当的抽象，将解的设计参数化以及后续适应度函数的构建，进化过程就可以在计算机上进行模拟。尽管进化计算在现实中取得了成功，这也使一些人倾向于将进化算法（EA）视为一组针对具有特定结构的难题而设计的具体解决方案，但我们的动机和更早一些研究者[40, 58, 66]一样，是希望强调该领域在问题求解的其他方面能为实践者带来的价值，而不仅仅是作为一种直接应用于具体问题的搜索方法。本书的主要主题之一，是强调在多个交互主体之间通过协同适应来引导搜索的强大原理。协同进化计算的这一核心思想并不新颖[61]，但过去二十年的发展带来了更深入的理解，并为新应用领域开辟了道路。针对协同进化自然而然地被用于驱动决策代理学习的情形，我们将展示协同进化算法（CEA）的新理论洞察和分析工具。这些工具将有助于帮助实践者识别当协同进化搜索受到病态问题影响时的表现，并为其缓解方法提供指导。另一方面，我们还将展示如何将协同适应原理作为一种高层次搜索的问题求解框架来进行思考。
对实践者而言，这并不是将元启发式扩展简单地应用于特定类型进化算法（EAs）的小众新领域。而是将人类专家在算法调优和设计过程中所采取的一些高层过程进行系统化，这些高层过程可以通过协同进化（coevolutionary）过程来表示。首先，通过适当的参数化来构建求解器空间，使得能够进行距离计算，并据此设计基本求解器的变换算子，进而令协同进化作用于这一高层搜索空间。通过类似的思路对问题测试用例空间进行构建，也能够应对如何制定恰当适应度评价机制的挑战。在进化算法种群与测试用例种群之间建立协同进化的模型，为解决投资组合优化方法（Portfolio Optimization）中与泛化能力相关的已知挑战奠定了基础。

在接下来的章节中，我们将更详尽地介绍进化算法的具体细节。第1.2节将重点介绍构成通用进化算法设计基础的关键要素：种群的使用、解的表示方法，以及进化中的变异与选择操作符。还将对进化计算中常用的重要术语进行描述和强调。我们会举出进化算法的若干实例，特别是与后续章节中介绍的协同进化算法（CEAs）特征相似的一些实例。紧接着，第1.3节将介绍进化算法参数控制（parameter control）的概念，并介绍一些先进方法，这些方法能够优化与进化算法运算相关的参数，以提升算法性能。

## 1.2 进化算法框架

进化算法属于一种基于种群的、受自然进化启发的随机搜索算法广义范畴。该领域普遍采用的共同抽象法，将算法搜索与自然进化过程都置于“生成-检验（generate-and-test）”框架之下。无论是计算过程还是自然过程，其本质都是在状态空间中运行，其中个体代表有限种群的候选解。我们将从三个视角理解进化算法，并阐述其设计如何反映和受到自然进化关键方面的影响。
初始化  变异算子  评估  选择  停止  否  是

图1.1 通用进化算法（EA）流程图

图1.1中的流程图展示了一个非正式的系统视角，在该视角下，无论是通用EA还是简化的新达尔文主义自然进化模型都包含三个主要的、相互依赖的组成部分，并在循环中进行交互。首先是对种群内父代候选解进行初始化，随后交替重复地应用变异和选择等进化算子，直到循环终止。

变异算子负责根据现有个体生成新的候选解。例如，当一个子代候选解由父代候选解产生，但其部分遗传解参数被施加了微小扰动从而改变其取值时，这与生物中的无性生殖过程中的基因突变类似。

选择算子则决定从当前种群中挑选哪些候选解，作为下一代种群的一部分。选择操作依赖于通过评估过程得到的候选解适应度。从系统角度来看，这两个组成部分在此被分开描述以提高清晰度，但在复杂的选择过程中二者往往是高度交织的。它们可能反映了作用于基因型或表现型水平的自然选择模型[101]。

例如，频率比例选择（frequency proportional selection）会根据每个候选解的适应度与种群总体适应度之和的比例，决定其被选中复制的概率。在经典的遗传算法（GA）中已采用此方式，这类似于生物种群中基因水平的选择压力（例如，不同基因变体在染色体特定位置上的保留频率）[81]。

其他EA方法，如进化规划（EP）家族中的算法，则采用在表现型水平进行局部竞争的复制模型，选择只作用于种群的子集[57, 62]。

算法1.1  通用进化算法
输入：$\boldsymbol{Y}$ 候选解种群，$\mathrm{s}_{\mathrm{term}}$ 终止准则选择  
输出：$\boldsymbol{X}$ 进化后的候选解种群

1: 过程 EA($\boldsymbol{Y}$, $\mathrm{s}_{\mathrm{term}}$)  
2: $t := 0$  $\Delta$ 初始化时间戳  
3: $\mathrm{b}_{\mathrm{term}} := \mathrm{true}$  $\Delta$ 初始化循环标志  
4: $\boldsymbol{X} := \mathrm{initialize}(\boldsymbol{Y})$  $\Delta$ 初始化父代种群  
5: while $\mathrm{b}_{\mathrm{term}}$ do  
6:  $\boldsymbol{X} := \mathrm{variation}(\boldsymbol{X})$  $\Delta$ 对$\boldsymbol{X}$施加变异操作  
7:  $\mathrm{evaluation}(\boldsymbol{X})$  $\Delta$ 对$\boldsymbol{X}$进行适应度评价  
8:  $\boldsymbol{X} := \mathrm{selection}(\boldsymbol{X})$  $\Delta$ 对$\boldsymbol{X}$施加选择操作  
9:  $t := t+1$  
10: $\mathrm{b}_{\mathrm{term}} := \mathrm{termination}(\boldsymbol{X}, t, \mathrm{s}_{\mathrm{term}})$  $\Delta$ 检查是否终止  
11: end while  
12: return $\boldsymbol{X}$  
13: end procedure

从算法的角度强调了这种带有内在设计灵活性的通用框架。可以从算法1.1中对通用进化算法（EA）数据结构的构建方式体现出来。主要的结构化数据 $\boldsymbol{X} = \big(({\boldsymbol{x}}, f)_i : i = 1, 2, 3, \ldots, n\big)$ 包含了每个候选解的参数取值 ${\boldsymbol{x}}$，这些参数共同描述了规模为 $n$ 的种群个体组成。换句话说，$\big(({\boldsymbol{x}}, f)_i : i = 1, 2, 3, \ldots, n\big)$ 构成了种群 $\boldsymbol{X}$ 的结构。存在两种主要的数据变换操作，由两个返回数据的过程表示——变异（variation）和选择（selection），它们都被明确写明是作用于整个 $\boldsymbol{X}$，并在每一步其实例取自$\{X_1, X_2, X_3, \ldots\} = \boldsymbol{\mathcal{X}}$中的某一特定种群配置。唯一一个小例外是初始化过程（initialize），它只被调用一次，并且可以在EA外部被调用并通过输入参数 $\boldsymbol{Y}$ 传入，其取值属于$\boldsymbol{\mathcal{X}}$。

尽管输入输出数据均要求为 $\boldsymbol{\mathcal{X}}$ 类型，变异与选择的内部操作可以根据实际设计需求尽可能复杂或灵活。其他过程可分为两类：第一类仅修改 $\boldsymbol{X}$ 中的特定数据。例如，在评价过程中，被处理的数据是个体候选解的适应度，可以通过索引访问（如 $\boldsymbol{X}[i].f$）。实际上，评价过程可以在选择过程中被调用。第二类过程是针对控制循环的局部变量的操作，例如本地变量时间戳 $t$ 的算术操作，用于记录迭代（代）次数。这个二元运算符 $t + 1$ 采用中缀表示法。终止过程（termination）用于检查循环的终止条件。当终止条件满足时，它返回 $\mathrm{false}$，否则返回 $\mathrm{true}$。这一过程通过改变本地布尔标志 $\mathrm{b}_{\mathrm{term}}$ 的取值，从而终止循环，并以此替代传统的循环条件。需注意，终止条件过程需要三个输入。前两个 $\boldsymbol{X}$ 和 $t$ 提供信息，第三个输入 $\mathrm{s}_{\mathrm{term}}$ 表示与如何利用这些信息判断循环终止有关的选择。
最后，我们可以将作用于群体配置空间的抽象进化过程描述为一个离散时间动力系统，即$F: \boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$。已有研究[127]将遗传算法（GA）在数学上建模为一个动力系统，并对进化算子的几何进行了显式建模。另一项研究[85]则将应用于一维问题的双种群进化算法（population-two EA）视为生成期望群体状态轨迹的离散时间动力系统。在此，我们仅详细介绍基本形式主义，着重于描述群体搜索行为为$\boldsymbol{\mathcal{X}}$中的轨迹的主要构建方法。抽象进化过程可以通过以下差分方程来表示：
$$
\boldsymbol{X}^{t+1} = \mathcal{F}\left(\boldsymbol{X}^{t}\right), \quad t=0,1,2,\ldots
$$
$$
\mathcal{F} = \mathcal{S} \circ \mathcal{V}
$$
其中，$\mathcal{S}: \boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$和$\mathcal{V}: \boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$分别代表选择算子和变异算子。本质上，这些过程涉及对群体$\boldsymbol{X}$成员的变换。通过这种方式，可以通过迭代$\boldsymbol{X}^{0}, \boldsymbol{X}^{1}, \boldsymbol{X}^{2},\ldots$在$\boldsymbol{\mathcal{X}}$中的轨迹观察进化过程。其搜索行为可通过描述这些轨迹的规律来确定。例如，令固定点$\boldsymbol{X}^*$定义为$\boldsymbol{X}^* = \mathcal{F}\left(\boldsymbol{X}^*\right)$，则落入某一$\boldsymbol{X}^*$的轨迹描述了向某个局部最优的搜索行为。需要注意的是，该模型中已隐含将适应度评估集成于选择算子之内。对于由其解参数$\boldsymbol{x}_i = \boldsymbol{X}[i]$（$\boldsymbol{x} \in \boldsymbol{\mathcal{R}}$，其中$\boldsymbol{\mathcal{R}}$为解空间的适当子集，例如约束连续优化情形下$\boldsymbol{\mathcal{R}} \in \mathbb{R}^D$）所描述的第$i = 1,2,3, \ldots, n$个候选体，这涉及计算$f(\boldsymbol{x}_i)$，其中$f: \boldsymbol{\mathcal{R}} \rightarrow \mathbb{R}_{\geq 0}$。由于选择算子作用于整个群体$\boldsymbol{X}$，因此其内部实际上包含两个过程。第一个过程$\mathcal{S}_{\mathrm{fe}}: \boldsymbol{\mathcal{X}} \rightarrow \mathbb{R}^n$针对所有$n$个个体进行适应度评估。第二个过程$\mathcal{S}_{\mathrm{cs}}: \mathbb{R}^n \rightarrow \boldsymbol{\mathcal{X}}$则利用这些适应度值指导下一代群体的个体选择。这两个过程的复合即$\mathcal{S}_{\mathrm{cs}} \circ \mathcal{S}_{\mathrm{fe}}: \boldsymbol{\mathcal{X}} \rightarrow \mathbb{R}^n \rightarrow \boldsymbol{\mathcal{X}}$，最终得到类型为$\boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$的选择算子$\mathcal{S} = \mathcal{S}_{\mathrm{cs}} \circ \mathcal{S}_{\mathrm{fe}}$。然而，我们在此主要关注如何通过如此抽象的模型揭示进化算法设计中的一个重要方面。需要指出，前述进化过程的表述是假定父代个体初始化后，首先执行变异算子。这仅是任意的选择，实际上也可以先执行选择算子，再施加变异算子，两者在本质上并无区别。主要的区分在于群体的初始化方式。事实上，我们可以将这一论点进一步形式化，并利用仅处理类型为$\boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$的函数及其结合律来说明。某一步群体本质上就是算子$\mathcal{G}$重复作用的结果。通过归纳法可以得出：
$$
\boldsymbol{X}^{m+1} = \mathcal{F} \left( \mathcal{F}^m (\boldsymbol{X}^0) \right) = \mathcal{F} \circ \mathcal{F}^m (\boldsymbol{X}^0)
$$
${\boldsymbol X}^{m+1} = {\mathcal F}\big({\mathcal F}^{m}\big({\boldsymbol X}^{0}\big)\big) = {\mathcal F} \circ {\mathcal F}^{m}\big({\boldsymbol X}^{0}\big)$。由于 ${\mathcal F} = {\mathcal S} \circ {\mathcal V}$，我们有

$$
{\mathcal F} \circ \cdots \circ {\mathcal F}\big({\boldsymbol X}^{0}\big) = {\mathcal S} \circ {\mathcal V} \circ \cdots \circ {\mathcal S} \circ {\mathcal V}\big({\boldsymbol X}^{0}\big) = {\mathcal S} \circ {\mathcal V} \circ \cdots \circ {\mathcal S}\big({\mathcal V}\big({\boldsymbol X}^{0}\big)\big) = {\mathcal S} \circ {\mathcal V} \circ {\mathcal S} \circ \cdots \circ {\mathcal V} \circ {\mathcal S}\big({\mathcal V}\big({\boldsymbol X}^{0}\big)\big) = {\mathcal S} \circ {\mathcal G} \circ \cdots \circ {\mathcal G}\big({\mathcal V}\big({\boldsymbol X}^{0}\big)\big)
$$
其中 ${\mathcal G} = {\mathcal V} \circ {\mathcal S}$。如果采用 ${\mathcal F}$ 作为演化过程建模的惯例，那么整个种群必须初始化完成——包含父代和子代候选者——以便选择算子可以作用。而我们采用的惯例则是，让初始种群 ${\boldsymbol X}^0$ 只部分初始化为父代候选者，因为变异算子 ${\mathcal V}$ 将从父代生成子代，从而完成整个种群的初始化。最后，正如 [127] 中对抽象遗传算法（GA）形式化的示例所指出，即使是在函数优化中，简单的种群搜索趋向全局最优，其行为描述也可能非常微妙。这是由于 GA 映射 ${\mathcal F} = {\mathcal S} \circ {\mathcal V}$ 的构造。一方面，除了与全局最优解相关且处于其吸引域内部的那个不动点外，选择算子 ${\mathcal S}$ 还拥有许多其它不稳定的不动点。另一方面，变异算子 ${\mathcal V}$ 的唯一不动点 ${\boldsymbol X}^{v}$ 对应于所有候选者均等出现的种群配置。该不动点的吸引域为 ${\boldsymbol {\mathcal X}} \setminus {\boldsymbol X}^{v}$。当将两者结合，即具备聚焦作用的 ${\mathcal S}$ 与在种群空间 ${\boldsymbol {\mathcal X}}$ 内具有类似扩散作用的 ${\mathcal V}$，所得的 GA 映射 ${\mathcal S} \circ {\mathcal V}$ 呈现出类似“间断平衡”的搜索过程。也就是说，在进化过程中，由于变异作用 ${\mathcal V}$，种群会在多个不动点（即 ${\mathcal S}$ 的不稳定不动点）之间迁移，最终轨迹会落入对应全局最优的稳定不动点并在其附近循环。

### 1.2.1 关于种群的使用

区分典型进化算法（EA）与其它启发式算法（若仅考虑经典形式而不涉及特定扩展或与其他算法的混合）的一大特点，就是使用候选者种群作为优化基础。遗传算法（GA）的核心特征是使用交叉算子，而交叉算子的定义和实现都要求存在候选者种群。在进化算法中，通常使用一个泛混合种群，候选者相互竞争以获得繁殖机会，虽然这并不是演化过程作用的唯一形式。也有并行进化算法的提出，这类算法包含多个种群，分别独立地进行进化，并通过较为松散的耦合形式进行交流，这类似于在邻近岛屿间所观察到的自然进化过程。在简单并行进化算法的构建中，每个种群被放置在独立的“岛屿”上，各自独立进化，只在特定的、通常较短的周期进行候选者之间的迁移 [15, 121]。这种迁移过程可以周期性安排，也可以采用更为复杂的方法。
这些基于岛屿的进化算法（EAs）可以在并行和串行计算环境下实现。在并行环境中，如果将单个岛屿（种群）的操作分配给特定的计算核心，则可以直接提出一个额外理由，即通过增加计算资源，在进化过程中能够加速求解过程，从而获得实际的加速效果。然而，在串行计算环境下，每个岛屿内的进化过程必须依次在单个计算机上运行，此时关于搜索加速的论证则更加微妙和复杂。此时，处理更多候选解会带来额外的计算开销。当这些在串行环境下实现的并行进化算法明显表现出比传统进化算法更优的搜索性能时，这说明采用更大规模候选解集本身具有某种内在优势。这一论证同样适用于传统的单一泛混种群结构的进化算法。尤其可以思考，进化算法与具备随机性和并行搜索能力的增强爬山算法（如文献[114]中描述的随机束搜索）之间是否存在本质区别。实际上，为什么使用种群对于进化算法成功至关重要，其根本原因在于进化搜索过程中种群需保持特定的多样性。为了形象说明这一问题，可以从一个极端情况入手——即种群已经退化为仅包含一个特定个体，其余个体只是该个体的复制品。最坏的情况是，该个体对应于一个局部最优点，由于当前进化算法的变异与选择算子协同作用，只能将该个体的复制品带入后续世代，无法跳出局部最优，从而导致算法发生了早熟收敛。此外，结合特定进化算法设计和问题结构的其他种群配置，也可能导致类似的搜索行为。例如，种群中的个体虽然彼此不同，但都分布在某个局部最优点的宽吸引域内。由于问题结构的原因，交叉算子的效果被抵消——任何两组相似个体的交叉，都将产生落在该吸引域内的新个体。突变同样不足以打破这一局面，因为只有极低概率才会生成落在该吸引域外、并且因适应度较高而被选择的新个体。确实，种群规模的不断增大甚至可能对进化优化器产生负面影响，尤其是在特定问题结构下。尽管[31]中提出的技术性证明源于特定的进化算法配置和问题设定，但其理论结果带来了更为广泛的启示。非正式地说，增大种群规模会增加施加于种群的选择压力，使其更容易陷入某些局部最优吸引域之中，这是因为这些吸引域通常伴随较高的适应度。可以通过调整变异算子来缓解这一问题，但须注意，在跳出局部最优后，不应影响搜索到全局最优吸引域时的表现。
因此，在进化算法（EAs）中利用种群来解决复杂的现实世界问题这一内在优势[134]，与在进化搜索的合适时间点或阶段拥有恰当的多样性紧密相关。已有研究确立了结合种群与多样性所带来的益处[16, 27, 38, 41, 68, 105, 111, 117, 126]，并且在讨论进化算法时需要将两者结合考虑。我们在此列举其中的四点，内容参考了[47]中对进化算法种群多样性理论研究现状的综述。首先，进化算法的设计初衷是实现全局探索，种群使不同的搜索空间区域得以被探索。在问题结构与进化算子结合带来额外挑战的情形下，全局搜索尤为重要。例如，对于具有高度多峰适应度景观的问题（详见第1.4节），需要依靠具有多样性的种群在进化搜索中提供一种内在机制，以帮助跳出局部最优。其次，一些进化算法的主要变异算子为交叉算子，而将变异算子置于次要地位以生成新的子代候选。在这类情况下，如果父代个体高度相似，则交叉操作的效果类似于低强度、低概率的变异，此时生成的子代会非常相似。因此，保持种群多样性有助于通过交叉操作更有效地支持全局搜索。第三，现实世界中存在一类需要同时兼顾多个、甚至相互冲突目标的问题，例如多目标优化问题[134]。这类问题隐含决策制定因素，即由智能体（人类或人工智能）从求解器获得的解集中进行选择。在这种情形下，生成一组解的种群是基本需求。因此，进化算法必须保持具有代表权衡关系的多样性候选解种群，以反映各目标的折中关系。第四，鲁棒性问题在某些现实世界问题求解中十分关键，其中某些问题特征可能随时间变化，即问题是动态而非静态的。这种变化可能源于解适应度实验评估中的噪声，或问题参数设定的变动。在这些情形下，进化算法需要产生鲁棒性高的解，而非依赖于当前实验测量设置或当前问题定义的最优解。如果构建出了能够发现多个最优解或能够追踪最优解变化的多样性种群，则更容易或更快速地实现鲁棒性。

### 1.2.2  解的表示
进化算法（EA）通用设计框架的一个结果以及其在不同问题领域的广泛应用，是可用于求解的多种解表示形式的出现。关于这些表示的讨论和阐述都离不开与之相关的变异算子，后者将在下一节详细介绍。在此，我们将介绍两种常见的、与EA结合使用的解表示形式，并简要讨论特定表示形式在不同问题设置下的应用方式。然而，为了更好地理解解表示及其编码方式如何影响EA的搜索行为，我们首先引入生物学中表现型与基因型的对应关系和概念以展开讨论。

与早期进化策略（ES）研究中实验参数优化设定不同，后者能够直接操作接近实际被优化对象的模型[10]，大多数EA在这些问题领域下进行的是模拟的进化优化。为使这些对象能够被使用，通常需要先进行抽象建模，以便验证其行为或输入-输出响应。与这些模型及其响应相关的参数，即被考虑用于优化模型响应的参数，被称为表现型。在这种情况下，所研究的参数空间便构成了表现型空间。

基因型的本质则源于计算机内部的模拟进化过程。在这种情形下，模型需要被表示为某种形式的计算模型（表示模型）。通常，会采用可以构造和应用变换算子的特定数学对象。这些计算模型的一个实例即代表一个候选解，被称为基因型。因此，基因型空间就对应于搜索空间，而变异算子则是那些在搜索过程中将一个种群个体从某个基因型变换为另一个基因型的变换算子[8, 9]。

显然，需要一种联系基因型与表现型的映射或编码函数，这通常在建立表示模型时被引入。然而，基因型-表现型映射在EA问题求解中却引发了诸多问题。在大多数应用中，EA并不能直接访问表现型空间，而是作用于表现型空间下覆盖的基因型空间。有关图示说明可以参考文献[59]。这种映射所带来的复杂性，不仅影响进化搜索的性能，还使分析过程更具挑战性。这些问题带来的挑战，可能和待解决问题的本质、所用EA的类型，以及最初推动其构建的理念差异一样重要。

特别需要指出的是，强调和倡导使用自然表示，并不像最初想象的那样直接。非正式地说，使用自然表示以进行高效搜索的本质，在于使EA能够直接在表现型（参数）空间上操作。一个例子是，在已知数学构造的连续优化基准问题上，使用以实数为基础的进化优化器（如ES和EP）时[75, 76]，实际上是实现了基因型空间与表现型空间的一一对应（双射）映射。如果仅考虑借助变异算子将父代候选体变换为子代候选体的情形，那么由此类算子引入的基因型空间中的邻域结构（即可达的点的邻域）能够一致地映射到表现型空间。在基因型空间中观察到的进化过程轨迹，与表现型空间中演化的轨迹完全相同。
在其他未采用自然表示，而是涉及某种编码方案（例如在遗传算法（GAs）中）的情形下，情况则更为复杂，其本质上表现为基因型到表现型的映射是多对一的 [59]。尽管如此，这里需特别注意的是关于进化过程可预测性的概念，无论是就其分析还是搜索行为的控制而言。固有问题结构如凸性（例如单峰连续优化问题）可以为带编码的进化算法（EAs）提供应用场景 [113]。对于完全离散的优化问题，既要有自然表示，又需使用能有效搜索的编码方案，这显然是极具挑战性的。除了这些问题的组合数学特性外，还必须处理表示上的问题。例如，经典的旅行商问题（TSP）涉及在给定加权图中搜索代价最小（如总距离最短）的哈密尔顿回路。非正式地说，一个解是遍历图中每个顶点一次的旅行路径，起点和终点相同。为TSP问题指定字符串编码方案是直接的，但还需要额外的路径验证步骤。对于大量图实例，几乎不可能提出自带有效回路编码的方案。通常会将修复算子与变异算子协同设计，以共同定义有效回路的邻域结构 [26]。这是与连续优化问题不同的，后者的参数与搜索空间仅涉及标准欧式向量空间。然而，我们仍可为类似自然表示与编码方案设定必要要求。将相关的特定问题知识引入可视作制定空间适当度量的过程，即通过指定距离度量，允许表现型与基因型空间的邻域结构能够保持一致地进行转换 [26, 49, 50]。关于字符串编码的问题，理论上认为 [63]，使用任何基数为$k=|A|$的字母表$A$指定的编码方案（例如在$k$元字符串表示中使用$k \geq 2$为基数），并无本质性的优势。搜索空间是由长度为$l$的特定$k$元字符串表示所形成，形式为$(a_i \in A: 1 \leq i \leq l)$，其变异算子定义了该空间中每个点（即$k$元字符串唯一实例）的邻域结构，相应的空间为$A^l$。可以在该搜索空间上制定概率质量函数（即“掷骰子的机制”），以定义生成某个候选解的可能性。关键在于，当$k$元字符串表示中使用任何其他$k$值时，总能专门设计相应的变异算子，以保持这些概率。
在更全面地理解了解决方案表示和编码如何作为进化算法（EA）搜索行为可观测特征与其底层操作过程之间接口的基础上，我们现在将注意力转向那些实际用于现实世界问题求解的表示方法。我们重点关注将在后续章节中讨论的表示方法，因此本节内容也将起到简要介绍的作用。首先介绍的是一种特定类型的实值表示，它构成了连接主义系统的一个广泛家族。以人工神经网络（Artificial Neural Networks, ANN）为例，它们本身就是人工智能方法论的重要分支。然而，很快人们发现，进化过程不仅仅是一种替代的训练方法，而且能够解决经典方法存在的一些缺陷【132】。ANN由多种结构各异的网络节点组成，每个节点都是一个神经处理单元（神经元）。一个典型神经元$y(\boldsymbol x, \boldsymbol w)$以有限个实数$\{x_i\}$为输入（存储于$\boldsymbol x$中），首先进行线性组合。这一求和过程由存储在权重集合$\boldsymbol w$中的实值系数或参数控制。该加权和$a$会传递给一个非线性传递（激活）函数$h$，输出一个实数$y$。数学关系为：
$$
y(\boldsymbol x, \boldsymbol w) = h\big(a(\boldsymbol x)\big), \quad a(\boldsymbol x) = \sum_{i} w_{i} x_{i} + w_{0}
$$
其中$w_0$表示独立的偏置项。典型的ANN用于解决足够复杂的学习问题时，通常采用前馈式结构，将神经元按特定方式分布于多层，每层之间有特定连接。特别地，网络结构为一个有向无环图（DAG）。之所以无环，是因为网络内禁止同一层之间的连接以及后续层向前层反馈的连接。当然，也可以引入循环连接，此时便形成循环神经网络（RNN）。我们依照文献【18】的常规阐述，描述典型的单隐藏层及输出层的前馈神经网络。ANN模型输入为$\{x_i : i = 1,\ldots,I\}$，输出为$\{y_k : k = 1,\ldots,K\}$，单隐藏层包含$J$个神经元。其构造方法直接明了，只需注意索引的使用。我们需进行两次计算，分别得到隐藏层神经元和输出层神经元的输出。有些示意图可能将输入$\{x_i : i = 1,\ldots,I\}$标为节点，但这些输入节点不做处理，仅向ANN传递实值（它们仅为恒等函数）。设$z_j$为隐藏层第$j$个神经元的输出，$J$个神经元（$j=1,\ldots,J$）的输出表达为：
$$
z_j = h\big(a_j^{(1)}(\boldsymbol x)\big) = h\left( \sum_{i=1}^{I} w_{ji}^{(1)} x_i + w_{j0}^{(1)} \right)
$$
其中，
$$
a_j^{(1)}(\boldsymbol x) = \sum_{i=1}^{I} w_{ji}^{(1)} x_i + w_{j0}^{(1)}
$$
接下来，对于输出层中的神经元$k = 1,\ldots,K$：
$y_k = h\big(a({\boldsymbol z})\big) = h \left( \sum_{j = 1}^{J} w_{kj}^{(2)} z_{j} + w_{k0}^{(2)} \right)$。

上式中，上标$(l)$用于明确指示权重属于与第一且唯一的隐藏层$(1)$和输出层$(2)$相关联的神经元。关键要注意，这种特定人工神经网络（ANN）的组成性质，因为每一层的输出会成为下一层的输入。在此情况下，我们拥有两个函数的复合映射：$\{x_i\} \rightarrow \{z_j\} \rightarrow \{y_k\}$。然而，现代的人工神经网络，例如深度神经网络（DNNs）[1]，采用了深层且多层的架构，具备多样化的处理能力，例如卷积操作用于捕捉空间结构（如图像），以及能够处理数据属性时序依赖关系的结构（如时间序列和文本）。这些深度神经网络被应用于诸多领域，并在计算机视觉、语音识别、自然语言处理等领域中得到了良好的分组与科学表述[70]。

神经网络能力的两个简单示例是将问题解决设定为回归和分类任务。简单的回归任务涉及用输入变量向量逼近连续因变量与目标变量之间的关系。直接的二元分类任务则是通过建立判决边界，将由输入向量表示的观测样本分配到两个离散类别或标签之一。这些前馈神经网络在问题求解中的强大能力，体现在它们作为泛逼近器（universal approximator）的潜力上：对于紧致域（如单位超立方体$[0, 1]^n$）上的任意连续函数，都可以在结构上作出一定限制的情况下，以任意精度进行近似，这一点已经被充分建立（参见[37, 82, 104, 106]等）。如果能够在神经网络宽度（隐藏层数量固定，每层神经元数目任意）或深度（每层神经元数目固定，层数任意）增长时，为其建立这样的理论保证，将为有效训练方法的研究提供动力。这就构成了神经网络用于问题求解的第二方面——即其机器学习能力。

一个简单的例子是考虑监督学习场景，其中可制定出一套迭代过程，通过利用带标签的训练样例，对神经网络的内部结构进行调整。在此过程中，神经网络通过从原始数据中提取模式，被称为“获得了解决问题所需知识”[70]。值得注意的是，这种通过训练获得的学习能力也可以通过适应性实现。演化算法（EAs）被开发出来，以优化ANNs的参数及其结构[132]。针对ANNs的参数优化，可以直接采用具有实值变异算子的演化算法。而ANNs的结构具有离散性，因此在这一情况下需要采用某种编码方式。鉴于这些深度神经网络设计的复杂性，演化算法也被开发用于这些DNNs架构和参数的自动化进化优化[136, 137]。
接下来我们介绍的解表示形式是树结构。树是一种连通无环图，对于任意一对节点，只能通过唯一的一条边进行连接。通常将树以顶部只有一个节点（称为根节点）的方式进行描述，根节点通过路径连接到其他节点的子集。在演化计算领域，遗传编程（Genetic Programming, GP）形成了一类进化算法家族，该算法演化的计算机程序以树结构为表示形式。最早提出进化计算机程序的思想可以追溯到遗传算法（GA）的开创性工作 [80]，但真正形式化并应用于GP还是在后来的文献 [91] 中实现的。GP所采用的语法树表示为直接表达以形式化语言书写、具有语法结构的计算机程序提供了手段。一个简单的GP树由若干连接的节点组成，用于表示原语集合。该原语集合是一个简单程序，由叶节点（称为终端节点，表示变量和常数）和内部节点（包括根节点，表示可执行的简单函数，如二元关系等指令）构成。其结构特点在于，当前节点所表示的指令的参数由与其直接相连的子节点表示。一个GP树的简单例子是实现以下数学表达式的程序：$\mathrm{min}(x*y,2*x+y)$。在该示例中，指令$\mathrm{min}$由根节点表示。由于$\mathrm{min}$的参数不是简单的数值，而是数学表达式$x*y$和$2*x+y$，因此它们各自也形成了子树。这正是树结构递归本质带来的主要优势之一。注意，原始表达式$\mathrm{min}(x*y,2*x+y)$在标准数学写作中结合使用了中缀记法（加法和乘法运算符）和前缀记法（极小值运算符）。而在LISP等语言中，通常会用纯前缀记法（即符号表达式s-expression）来书写以使GP中的树结构通过语法直接体现，如$\mathrm{(min\ (*\ x\ x)\ (+\ (*\ 2\ x)\ y))}$ [95]。若给定一个层次较浅的树结构，用s表达式后，不同的分支结构对人类读者更加直观，例如右分支$\mathrm{(+\ (*\ 2\ x)\ y)}$本身也包含子树。这种树结构可以扩展为更为高级的GP树，以表示如人类程序员所编写的复杂程序。在标准编程中，特定指令序列通常会被重用，可以将这些指令创建为模板，之后作为组件或子程序形式存在，并根据不同输入参数实例化后用于更大的程序中。较为常见的扩展包括自动定义函数（Automatically Defined Functions, ADFs）[92]。此外，还有其他类型的子程序表示被开发出来，如自动定义迭代（Automatically Defined Iterations）、自动定义循环（Automatically Defined Loops）、自动定义递归（Automatically Defined Recursions）等 [93]。它们在实际应用中作为高级GP树的分支存在，并被归类在特殊的根节点之下。上述定义的子程序既可以执行操作，也可以产生结果。

需要注意的是，还有其他形式的GP采用不同的有向无环图结构，如笛卡尔GP（Cartesian GP, CGP）[128]和基于度量的GP（Metric-Based GP, MBGP）[49, 50]。这些具有特定编码方式的解表示最初是为了适应CGP中数字电路的进化以及MBGP中布尔函数进化的需求而提出和应用的。鉴于GP树几乎可以表示所有类型的计算机程序，因此在不同领域、各种应用中利用其进行问题求解也就不足为奇了。然而，GP树与人工神经网络（ANNs）中的图结构的主要区别在于它们属于符号模型与连接主义模型的区别。例如，GP实现的是符号回归，而进化ANNs则实现参数回归 [91]。GP中的符号方法旨在通过进化过程构造具有系数的一般函数，而不是像在结构固定的ANNs进化过程中那样去寻找预定义函数的系数。同样地，GP中所采用的树结构还适用于符号分类 [89]以及其它表述形式，例如运筹学中的路径决策问题策略制定 [129] 等任务。
### 1.2.3 变异算子

在上一节中，我们讨论了在做出简化假设的前提下，解的参数表示与生物染色体具有类比关系。它们构成了解空间基础的坐标系，使得描述复杂、特定个体的信息能够以特定方式进行结构化，并作为解空间中的唯一点相互区分。在此基础上，可以定义变异算子，用以描述这些点的邻域结构，从而构建搜索空间。在本节中，我们将探讨变异算子的更为实际的方面，即在将一种特定候选解变换为另一种候选解的操作机制下的应用。考虑到任何变异算子的设计选择都与所采用的解表示方式紧密相关，我们将重点关注常用于实数编码和离散表示的典型例子，尤其是针对我们前文介绍过的人工神经网络（ANNs）和基因编程树（GP树）。

作为概念性引入，我们首先描述应用于二进制字符串表示（即规范遗传算法中常用的表示方式）的两类变异算子，分别为变异（mutation）与重组（recombination，或称交叉crossover）算子[40, 66]。我们以最简单的变异算子为例进行说明。设有一个长度为6的定长二进制串，其序列记作 $(b_5, \ldots, b_0),\ b_i \in \{0, 1\}$。注意到我们这里将索引 $i$ 反向，以便 $b_5$ 表示最高有效位，$b_0$ 为最低有效位。在此，简单的均匀变异可通过位翻转（bit-flip）操作实现，即每个比特位 $b_i$ 以相同概率被改变其当前取值。在规范遗传算法中，变异被视作次要的变异算子，因此每个位发生翻转的概率应设置较小。在本例中，对每个位 $b_i$，从均匀分布 $r \sim U(0, 1)$ 中抽取一个值，当 $r < p_m$ 时，$b_i$ 的当前值就会被改变。其中，$p_m \in [0, 1]$ 是变异概率参数，也即每个位通过位翻转操作发生变异的概率为 $\mathbb{P}(r < p_m)$。
交叉算子是标准遗传算法（GA）中的主要变异算子[40, 66]。与变异算子类似，存在一个参数 $p_c \in [0,1]$，用于指定交叉发生的概率。通常，$p_c$ 的取值显著高于 $p_m$。在实际应用中，将 $p_c$ 设为至少比 $p_m$ 高一个数量级的情况并不罕见（例如，$p_c = 0.5,\ p_m = 0.01$），这表明生成新候选解的主要任务由交叉操作承担。此外，在交叉操作中，通常会随机选择两个父代个体，在一特定过程中产生两个子代个体。在生成子代的过程中，父代的部分子序列（在GA术语中称为等位基因）会被交换。

在标准的 $k$ 点交叉中，随机选择 $k$ 个交叉点，以指示哪些子序列会被交换。最简单的情况是 $k = 1$，即一位点交叉算子，其交叉点以均匀概率选取。我们将通过如下方式说明这一操作。设有两个父代 $(x_i^1), (x_i^2)$ 和两个子代 $(y_i^1), (y_i^2)$，其中 $i = 5, \ldots, 0$，比特值取自 $\{0,1\}$。在一位点交叉下，交叉点选定为比特 $\{j\}$，记作 $\otimes_{\{j\}}^{(1)}$。下文我们采用前缀表示法来表述该操作。为简明起见，省略比特的序号 $i$，在元组表示中按照自然顺序（此处为倒序）排列，以清楚展示交换的过程。以 $j=3$ 为例，$\otimes_{\{3\}}^{(1)}$ 将产生如下两个子代：

$$
\begin{align*}
\big\{(y_i^1),(y_i^2)\big\} &= \otimes_{\{3\}}^{(1)} \big\{(x^1,x^1,x^1,x^1,x^1,x^1),(x^2,x^2,x^2,x^2,x^2,x^2)\big\} \\
&= \big\{(x^1,x^1,x^1,x^2,x^2,x^2),(x^2,x^2,x^2,x^1,x^1,x^1)\big\}.
\end{align*}
$$

两点交叉算子的一个具体实例 $\otimes_{\{4,2\}}^{(2)}$，其交叉点位于 $\{4,2\}$，将产生：

$$
\begin{align*}
\big\{(y_i^1),(y_i^2)\big\} &= \otimes_{\{4,2\}}^{(2)} \big\{(x^1,x^1,x^1,x^1,x^1,x^1),(x^2,x^2,x^2,x^2,x^2,x^2)\big\}\\
&= \big\{(x^1,x^1,x^2,x^2,x^1,x^1),(x^2,x^2,x^1,x^1,x^2,x^2)\big\}.
\end{align*}
$$

除此之外，还有多种其他形式的交叉算子[40, 66]。其中一些变种是专为具有二进制编码表示的、包含特定离散结构（如带修复机制以生成有效解的旅行商问题TSP）的问题设计的。然而，即使是对于那些目标最优解已知为整数值的高维连续函数优化问题，标准的用于二进制串表示的交叉与变异算子也可能无法满足需求。编码方式及其对应的变异算子可能会由于改变了邻域结构而在新的搜索空间中引入原实值表示空间中不存在的局部最优解[43, 113]。
在需要处理连续问题域的情境下，例如在人工神经网络（ANNs）参数优化等问题中，部分进化算法（EA）采用了实数编码的变异和重组算子。历史上，演化策略（ES）和演化规划（EP）是演化计算中两大主要分支，它们强调在个体（表型）层面的适应性。ES和EP通常提供的变异算子是利用一个父代候选解生成一个子代候选解，这类算子可被建模为一种扰动过程。设${\boldsymbol x},{\boldsymbol x}' \in {\mathbb{R}}^n$分别为父代和子代候选解的解向量，包含$n$个实值设计参数。考虑一个由单峰多元分布描述源的扰动。采用各向同性扰动${\boldsymbol z}$的简单变异算子如下所示：

$${\boldsymbol x}' = {\boldsymbol x} + {\boldsymbol z}, \\ {\boldsymbol z} \sim \sigma {\boldsymbol N}({\mathbf{0}},{\mathbf {I}}).$$

这里，${\boldsymbol z}$是一个多元随机变量，其取值来自球面高斯分布$\sigma {\boldsymbol N}({\mathbf{0}},{\mathbf {I}})$，该分布已按标准差$\sigma$缩放。${\boldsymbol z}$具有标准正态随机向量的形式。每一个分量都是独立同分布（iid）的随机变量，且其取值都来自同一个高斯分布，即$z_i \sim N(0,\sigma)$，适用于所有$i = 1,\ldots,n$ [17]。上述高斯变异算子可以按以下方式表示，针对被索引的设计参数 $i = 1, \ldots, n$：

$$x^{\prime}_i = x_i + \sigma N_i(0,1).$$

由于$z_i$是iid随机变量，因此可以对每个$i$单独从标准正态分布$N(0, 1)$中重新采样。我们也可以不采用球面对称分布，而使用常密度面的形状为椭球的分布。在这种情况下，$z_i$独立但不再同分布。每个$z_i$仍然来自高斯分布，但具有各自不同的$\sigma_i$，从而得到：

$$x^{\prime}_i = x_i + \sigma_i N_i(0,1).$$

例如，这允许我们增大某些$\sigma_i$，以便为部分设计参数$x_i$生成更大幅度的扰动。更一般地，该变异算子可以采用带相关性的多元高斯分布$N(0, \boldsymbol\Sigma)$，其中$\boldsymbol\Sigma$是非对角、正定协方差矩阵。这样会相应地旋转描述多元高斯分布的坐标系，使得变异算子能够在解空间中引入更具方向性的扰动 [17]。

我们之所以从上述较为正式的描述着手，是为了更清晰地阐释用于高维连续优化问题的一些早期变异算子的机制细节及其设计方法。如果问题仅为一维，这样的复杂性则不会显得突出。需要注意，前述变异算子依赖于用户预先设定的扰动模型（如多元高斯分布）。而在ES和EP中，一类更为复杂的变异算子则对参数$\sigma_i$实现了自适应，使分布形状在进化过程中也能一定程度地自我调整。针对索引为$i = 1, \ldots, n$的设计参数，这种自适应变异算子可描述如下：
$\sigma^{\prime}_i = \sigma_i \exp\big(\tau' N(0,1) + \tau N_i(0,1)\big)$，

$x^{\prime}_i = x_i + \sigma^{\prime}_i N_i(0,1)$，

其中固定参数为$\tau' = 1/\sqrt{2\sqrt{n}}$，$\tau = 1/\sqrt{2n}$。这种自适应变异算子已被应用于进化神经网络的进化过程[28, 32, 33]。此外，基于扰动的变异算子还可以在其他方面进行扩展。例如，有些算子设计为通过使用具有重尾分布（如Cauchy分布）以及更一般化的Lévy分布族[97, 133]，实现更频繁的大步长变异。需要注意的是，自适应机制也可以被引入到这些基于重尾扰动的变异算子中。

还有一些变异算子并非基于围绕多元随机分布进行扰动的模型。例如，在差分进化（DE）算法[39, 120]中，变异算子的来源是从父代种群中随机选择的两个候选解，获得一个缩放差分向量。通常的实现需要三个不同的父代候选${\boldsymbol x}, {\boldsymbol y}, {\boldsymbol z}$，其中${\boldsymbol x}$是用来生成子代${\boldsymbol x}'$的直接父母，另外两个父代${\boldsymbol y}$和${\boldsymbol z}$提供差分向量。标准的差分进化变异算子可以描述为：

$x^{\prime}_i = x_i + \upsilon (y_i - z_i)$，

其中$\upsilon \in [0, 2]$。

对于连续优化问题，进化算法中的重组算子在生成新候选解时的作用次于变异算子。实值重组算子的设计原理可类似于遗传算法中的交叉算子。在这里，重组算子作用于解的实值向量表示。具体来说，当坐标系统通过标记各轴并与序列中的特定位置相关联后，可以将其编码为一组实数序列。在这种情况下，有${\boldsymbol x} \in {\mathbb{R}}^n$，表示为$(x_i \in {\mathbb{R}} : i = 1, \ldots, n)$。

可以设计两种类型的重组算子。它们从一组随机选取的供体父代$\{{\boldsymbol y}^1, \ldots, {\boldsymbol y}^m\}$中生成一个子代候选${\boldsymbol x}$。第一个类型称为离散重组。对于每一个设计参数$i=1,\ldots,n$，具体机制包含从供体父代中复制相关分量，具体如下：
$x_i = y_i^j, \quad j \sim U\{1, \ldots, m\}$，其中 $j$ 服从离散均匀分布 $U\{1, \ldots, m\}$，即在 $\{1, \ldots, m\}$ 的每一个值被选中的概率都相等。第二种类型称为中间重组（intermediate recombination）。其机制是简单地取由父代供体集合表示的解向量的质心。对于每个设计参数 $i = 1, \ldots, n$，可以表示为
$$
x_i = \frac{1}{m} \sum_{j = 1}^m y_i^j.
$$

本节最后简要讨论在遗传编程（GP）中常用的标准变异算子，特别关注GP树结构所采用的重组和变异算子。GP中的交叉算子机制类似于二进制字符串遗传算法（GA）中的操作，但在算子的设计上有额外的约束。这些约束是为了解决GP树进化中常见的两个问题。第一个是结构的无节制增长，导致冗余膨胀的大型树结构，这些结构在行为上与更紧凑的树类似（如具有相似的适应度值）。第二个且更为关键的问题是生成非法树。当待解决的问题域需要使用含有多种数据类型函数的原语集时，常常会出现非法树的生成。例如，情况可能涉及 $\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ 类型的函数（如算术操作 $x + y = z$）以及 $\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{B}$ 类型的函数（如不等式 $x \leq y \equiv b, \ b \in \{\mathrm{true}, \mathrm{false}\}$）。为了解决生成非法树的问题，可以将数据类型作为原语集元素的描述部分加以约束。这一扩展被引入并研究，称为强类型遗传编程（Strongly Typed GP, STGP）[109]。STGP已被成功应用于进化计算机程序[3,4]。一旦这些约束被识别出来，就可以将其融入到GP中变异算子的设计中，从而确保生成的树都是合法的。

一种简单的重组算子是标准的子树交叉（subtree crossover）[95]。该算子以两个父代候选解为输入，生成一个子代候选解。在每个父GP树上首先随机选择一个交叉点，该交叉点对应以该节点为根的子树。接下来，将第一个父GP树中的所选子树用第二个父GP树中对应的子树进行替换。需要注意的是，应用中随机选择交叉点的过程通常是带有偏差的。这是因为大多数GP树的平均分支因子至少为二（例如由于使用二元运算符和关系符）。与较大的子树相关联的交叉点更少。例如，在深度为二的完全二叉GP树中，六个交叉点中有四个是叶节点（终端符）为根。如果均匀随机选择，则更有可能选择这些叶节点，而不是其上方的子树，导致孩子个体仅发生较小的遗传物质交换。

其他更为复杂的交叉算子通常涉及匹配过程，以确保被交换的子树在结构上相似，例如[94]中提出的等尺寸交叉算子（size-fair crossover operator）。
GP中的变异算子同样需要更为细致的设计，以确保对树结构的修改既合法又可解释。根据GP树中被选作发生变异的位置，可以从最简单的结构（即叶节点）开始，逐步扩展到更复杂的子树。如果被选中的叶节点仅包含常数值，那么可以采用简单的扰动过程对这些常数进行修改。如果选中的是内部节点，则可以对该节点应用点变异算子。其实现方式是将节点中的元素替换为满足配接数（即参数数量）约束的基本集合中的另一个元素。例如，一个表示减法操作的节点，可以通过点变异变为加法操作。接着，还可以采用子树变异算子来生成新的子树结构。首先选择一个变异点，然后在该位置附加一个随机生长的子树。对于此算子，可以设置一些约束条件，例如限定子树可以生长的最大深度[3, 4]。

### 1.2.4 选择算子

进化算法（EA）中选择算子的主要任务是形成下一代的新种群。一般而言，这一过程通常涉及从当前完整种群中选取一部分候选解，这些候选解将作为下一轮进化过程中的父代个体。选择算子通过利用评估后分配给候选解的适应度值来完成此任务。这使其与基于遗传信息对个体进行操作的变异算子有所区别。虽然上述描述较为简要，但事实上选择算子机制在改变种群结构时会产生更为深远的影响。例如，下一代所选父代候选的集合通常为一个多重集（或称为袋），其元素来源于当前种群。适应度值较高的个体被选中的概率更大，且被多次选中的可能性也更高，因此，新生成的父代种群中可能会包含这些个体的多个拷贝。然而，选择过程并不一定是精英式的。也就是说，更为复杂的机制有时也会选择适应度相对较低的个体，以提升并维持进化种群中的多样性。尽管如此，可以通过仅基于适应度值的简单过程，更深入地理解选择算子的本质。设想在一个以全局最优为目标的优化问题中应用EA。作为一种基于种群的搜索方法，这意味着需要首先发现最优解，随后种群逐步收敛并专一于该最优解，这一过程构成了成功搜索的各个阶段。有必要确认成功的进化搜索过程是否与选择算子相关参数的设定有关。对此，可以在选择压力（selection pressure）[7]的背景下进行研究。选择压力是选择算子的一个属性，它表征了个体候选的适应度值与其被采样并复制进入新种群的概率之间的关系。
已有理论研究关注了选择压力对演化搜索的影响。早期的分析方法采用了接管时间（takeover time）等概念，用以量化种群收敛到最优解所需的时间 [67]。而现代成熟的EAs运行时间分析（runtime analysis），将EAs视为随机算法，提供了一种严谨的方法，用来量化种群向最优区域漂移的速度 [47]。该方法被用于研究不同选择压力的选择算子对EAs运行效果的影响 [30, 45]。在应用与实验研究中，选择压力的定义通常较为宽泛且不够正式，其可以通过调整参数设定或对相关算子的设计来改变，以影响演化搜索的进程。较强的选择压力会使演化搜索偏向于在表现优秀个体所描述的搜索空间区域进行开发；而较弱的选择压力则鼓励演化搜索去探索与表现较差个体相关的其他区域，这些区域潜在地可能需要经过数代演化才能到达新的、更具潜力的区域。在这一背景下，可以考虑多种为EAs设计的选择算子。下面我们将介绍几种常用的选择算子。

第一种是适应度比例（或称轮盘赌）选择，它通常用于遗传算法（GA）中。假设解空间为 $S$（例如 $S \subseteq \mathbb{R}^n$）。这种特定的算子采用简单的概率方法，决定当前种群中个体 $x_i,\ i = 1, \ldots, s,\ x_i \in S$（种群规模为 $s$）的复制率。复制率基于个体适应度值 $f(x_i)$ 相对于种群适应度总和 $\sum_{i}^s f(x_i)$ 的比例。个体被选中复制并进入下一代种群的概率为
$$
\mathbb{P}_i = \frac{f(x_i)}{\sum_{i}^s f(x_i)}
$$
其中 $\sum_{i}^s \mathbb{P}_i = 1$。对适应度值的归一化处理使其可直接作为概率解释。这样就在集合 $\{x_1, \ldots, x_s\}$ 上定义了离散概率分布，从中可以随机抽样产生下一代的父代种群。需要注意的是，适应度值必须为正实数。对于适应度函数 $f : S \rightarrow \mathbb{R}_{\geq 0}$ 的最大化问题，适应度比例选择的计算极为直接。而对于如最小化问题或存在负适应度值的情形，则需要对适应度函数进行重构，或采用适当的缩放函数。后者通常将候选个体的原始适应度值与最差个体的适应度值之差作为新的适应度赋值 [7]。
接下来介绍锦标赛选择算子。该机制简单明了，需指定两个正整数参数：锦标赛规模$q$和下一代父代种群规模$p$。该算子将从当前种群中随机抽取$p$次（带放回抽样）。每次抽样中最优的候选体将被复制，用以构成下一代的父代候选体。文献[7]给出了这个算子的形式化组合描述，并推导了与当前种群中每个候选体$i$（种群规模为$s$）被选择用于复制相关的概率$\mathbb{P}_i, \ i=1,\ldots,s$。这里，我们描述该算子的非正式实现。可以假设当前种群服从离散均匀分布，然后从该分布中独立同分布地随机抽取$p$次样本。这样得到$p$个样本$(\boldsymbol{x}_k)^j, \ j=1,\ldots,p$。每个样本$(\boldsymbol{x}_k)^j$是一组候选解，我们考虑满足$f(\boldsymbol{x}_i)\leq \cdots \leq f(\boldsymbol{x}_q)$（即按适应度值递增顺序排列）的排列$(\boldsymbol{x}_i,\ldots,\boldsymbol{x}_q)$。设$\boldsymbol{x}_{k,j}$为第$j$个有序列表中的第$k$个元素，该有序列表来自$(\boldsymbol{x}_k)^1,\ldots,(\boldsymbol{x}_k)^p$。以最大化问题为例，下一代父代种群可通过取$\boldsymbol{y}_j = \boldsymbol{x}_{q,j}$获得；对于最小化问题，则取$\boldsymbol{y}_j = \boldsymbol{x}_{1,j}$。已经有多种基于排序的选择算子被提出[71]。一般来说，这类算子用候选体在种群中的排序而非适应度值作为主要选择标准。采用排序有两个优势。首先，在难以获得有用的目标函数或任何替代函数以判定候选体质量的情况下，为候选体分配等级可能更可取；此时，可以通过在种群中进行候选体的两两比较获得排序。第二个优势是，排序方法消除了构建离散概率分布时可能出现的缩放问题（如适应度值为负时），及依赖于种群结构的其它缩放问题（如大多数候选体适应度值接近，或种群中存在少数适应度悬殊的候选体）。其中一种特定的实现是线性排序选择算子，其对当前已经根据适应度值递增排序的种群中$i = 1, \ldots, s$的候选体，以线性方式按其排序分配概率。概率形式为$\mathbb{P}_i = \frac{1}{s}\left(\alpha + (\beta - \alpha)\frac{i-1}{s-1}\right)$。该算子有两个参数，$1 \leq \beta \leq 2$及$\alpha = 2 - \beta$。$\beta$和$\alpha$分别与当前种群中最佳和最差候选体的预期复制数相关。其它基于排序的选择算子则采用几何函数及指数函数等不同形式来调整概率[71]。计算出概率后，算子便可从所得的离散概率分布中抽取随机样本。
接下来，我们将介绍一类基于确定性机制的选择算子。特别地，$(\mu, \lambda)$和$(\mu + \lambda)$选择算子通常应用于进化规划（EP）和进化策略（ES）中。在这两种情况下，首先应用变异算子，从$\mu$个父代候选生成$\lambda = k\mu, \ k \geq 1$个子代候选。也就是说，每个父代候选会生成$k$个子代候选。在$(\mu, \lambda)$选择中，$k$通常被设置为大于1的值，这样可以从$\lambda$个生成的子代候选中选择最优的$\mu$个个体组成下一代的父代种群。而在$(\mu + \lambda)$选择中，符号$+$表示$\mu$个父代和$\lambda$个子代候选合并作为备选池，由此进行复制操作。在该池中，从$\mu + \lambda$个个体中选出性能最佳的$\mu$个，用作下一代的父代种群。

除了上述选择算子之外，还有许多其他选择算子。我们将在本节最后介绍一种在EP中使用的特殊选择算子，其机制上是前文描述的锦标赛选择和$(\lambda + \lambda)$选择的混合（即$k = 1$，故$\mu = \lambda$）。称之为$(\lambda+\lambda)$选择的原因在于变异算子用$\lambda$个父代候选生成$\lambda$个子代候选，这两部分共同组成完整的候选种群以供选择。[7]中从技术上证明了该选择算子的本质属于概率性$(\lambda + \lambda)$选择。这里我们通过简化假设，给出其非正式、直观的说明。

考虑一个最大化问题，令合并后种群$\{{\boldsymbol x}_1,\ldots,{\boldsymbol x}_{2\lambda}\}$按照个体适应度从小到大且互不相同进行自然排序。然而，该算子使用的是基于锦标赛得分排序得到的排名，这些得分通过将候选个体${\boldsymbol x}_i$与合并种群中其他样本进行两两比较得到。如果对所有个体均参与比较，则排名可保留自然顺序。否则，若仅用种群中的一部分样本计算锦标赛得分，则会打乱自然顺序，从而实现锦标赛排名。

下面描述该算子的具体机制。对于每个候选个体${\boldsymbol x}_i, \ i = 1,\ldots,2\lambda$，关联一个大小为$q$的随机样本集$T_q^i = \{{\boldsymbol y}_j : j = 1,\ldots,q\}$，其中${\boldsymbol y}_j$是从整个合并种群中按照离散均匀分布采样得到的，即${\boldsymbol y}_j \sim U\{{\boldsymbol x}_1,\ldots,{\boldsymbol x}_{2\lambda}\}$，且${\boldsymbol y}_1,\ldots,{\boldsymbol y}_q$为独立同分布的随机变量，每个都取值于$\{{\boldsymbol x}_1,\ldots,{\boldsymbol x}_{2\lambda}\}$。

则每个${\boldsymbol x}_i, \ i = 1,\ldots,2\lambda$的锦标赛得分可按如下方式计算：

$$
g\big({\boldsymbol x}_i,T_q^i\big) = \sum_{j \in T_q^i} {\mathbf{1}}_{{\mathbb{R}}_{\geq 0}}\big(f({\boldsymbol y}_j) - f({\boldsymbol x}_i)\big),
$$
$$
{\mathbf{1}}_{{\mathbb{R}}_{\geq 0}}\big(f({\boldsymbol y}_j) - f({\boldsymbol x}_i)\big) =
\begin{cases}
1, & \text{如果 } f({\boldsymbol x}_i) \geq f({\boldsymbol y}_j), \\
0, & \text{否则}.
\end{cases}
$$

需要注意，每个${\boldsymbol x}_i$的锦标赛得分可以理解为该个体在与自己锦标赛样本$T_q^i$中的每一个对手进行二人对战时获得胜利的次数。指标函数${\mathbf{1}}_{{\mathbb{R}}_{\geq 0}}$本质上实现了游戏的判定，并为第一个玩家${\boldsymbol x}_i$输出结果。具体来说，即对双方适应度值进行成对比较，若$f({\boldsymbol x}_i) \geq f({\boldsymbol y}_j)$则视为${\boldsymbol x}_i$胜利并计1分，否则计0分。

最终，可通过选择锦标赛得分最高的$\lambda$个个体，完成锦标赛选择。
## 1.3 演化算法中的参数控制

在第1.2节开头，我们已经详细介绍了如何通过种群为基础的随机搜索方法的框架来描述演化算法（EA）解决问题的过程。随后，在1.2.1到1.2.4各小节中，我们描述了实现EA所需的主要组成部分：即种群、解的表示方法，以及变异和选择这两类进化算子。可以使用标准的设定，例如遗传算法（GA）、进化规划（EP）和进化策略（ES）的典型形式，或者使用为提升性能而设计的改进型算法，亦或针对特定问题结构进行定制的变体（如遗传程序设计（GP）及其符号进化方法用于程序进化）。需要注意的是，EA存在许多参数需要初始化以保证其正常运行。这些参数与EA的主要组成部分相关（例如算法1.1），包括种群规模以及用以调整变异强度和选择压力的进化算子参数，因此会影响搜索性能。这表明，EA的自定义程度远不止于为每一个组成部分预先决定要采用的具体设定、表示设计和算子选择。

我们首先区分两类可用于调整EA参数的方法，遵循文献[54]中在EA背景下提出的分类方法。还有其他分类方法，例如文献[83]提出的适用于更广义的元启发式方法的分类。首先，参数控制（parameter control）是指在EA运行过程中对这些参数进行动态调整。通常认为，在EA搜索过程的不同阶段，需采用不同的参数值以提升搜索效果。其次，参数设置（parameter tuning）是在EA执行前静态地设定这些参数。一般来说，EA在目标问题上的性能依赖于初始参数值。因此，有必要在EA初始化阶段就合理设定参数，而非任意赋值。

在文献[54]中，将EA中的参数控制方法划分为三大类。确定性方法（deterministic approach）通常利用固定的计划（schedule）对参数进行更改；而自适应（adaptive）和自我适应（self-adaptive）两类方法，则为EA赋予了参数调整机制，常常通过对搜索过程的反馈进行调整。自我适应方法可看作是前两者的进一步细化，其中EA的参数以适当的形式表示，并将调整机制融合进进化过程之中。需要注意的是，这一参数控制的分类方法在文献[46]中被进一步细分和拓展，目前已有五个类别。
这两类（参数调整与参数控制）的主要区别在于参数允许变化的时机。在参数调整中，这一过程是以离线方式进行的，而在参数控制中，参数的变化是在进化算法（EA）执行过程中以在线方式发生的。尽管如此，这两者在实现的一般设计以及需要解决的挑战上也存在共性。接下来，本节分别在不同小节中讨论参数调整和参数控制是如何通过对EA的种群、变异及选择算子的操作来实现的。我们的讨论总结并反思了早期在文献[84]中综述的相关研究成果，并结合了文献[46]等新研究中的最新进展。

### 1.3.1 种群规模的参数控制

针对给定问题寻找合适种群规模的主要目标，是为理解种群规模对EA成功搜索的影响提供理论依据，并进而为种群规模的控制程序制定提供指导。早期的一些理论研究采用了Building Block模型[69]，并作出了简化假设。在离散优化的背景下，问题结构被假定为可以加性地分解为各个独立子分区。在每个分区中，存在多种子解或配置，其中某一种优于其他，并且关键地属于整体最优解的一部分。分析通常着重于遗传算法（GA）如何将所有构建块（building blocks）组装成正确的解。有些研究将该过程建模为马尔可夫链[100]，特别是一维随机游走[103]。通过研究该模型，可以解释种群规模对成功搜索概率与失败概率的影响。

与进化计算领域的历史和现代发展一致，理论研究通常通过广泛且系统的实验研究加以支持和补充。为了便于数学分析，理论假设中对问题结构或EA设计的强假设，可以在实验研究中适当放宽。据文献[84]，与种群规模参数调整和控制相关的主要问题主要有三类。第一类问题涉及免去设置种群规模的需求，大多数相关研究考察了模拟个体寿命的控制机制——即在初始化获得足够规模后，通过生命周期来从种群中移除个体[2, 35]。第二类问题涉及如何估算搜索所需的种群规模，大多数机制注重以受控的方式扩大种群规模，例如通过贪婪[118]和随机[72, 73]方法实现种群数量的倍增。最后，不同研究还考察了在进化过程中采用可变种群规模的有效性，包括确定性控制[90]、自适应控制[116]和自我适应控制[122]等不同机制。
### 1.3.2 变异算子参数控制

正如文献[84]所指出的，相较于进化算法（EA）中的其他组成部分，有关变异算子相关参数的调整与控制已进行了大量研究。这并不令人意外，因为变异算子的主要作用是在搜索过程中产生新的候选解以供评估，这些候选解随后会被传递给选择算子，后者决定哪些候选解将在下一代中复制以形成种群。在此背景下，这些研究的动机主要集中在解决两个密切相关的核心问题。

第一个问题涉及在全局探索与局部开发之间保持有效的平衡，这对于搜索过程来说至关重要。第二个相关问题则聚焦于变异算子的有效性，例如，为进化算法合理设定步长，以便能够更充分地搜索解空间[29]。接下来，我们将重点讨论在进化算法中针对变异算子实施参数控制的两类主要设计机制。

现代进化算法的运行时分析已使我们得以深入研究静态参数设定（如变异率）[78]和变异算子的动态参数设定机制[46]。尽管理论分析通常受限于较为简单的EA实现，并需与精心设计的基准问题相配合以确保数学分析的可行性，但已有多项理论研究证实，对变异算子的参数进行调整和控制能够带来积极效果。更为关键的是，这些研究进一步揭示了参数调整和控制为何有效的根本原因。

例如，早期的研究[51]提出了一种确定性方法，该方法在经典的$(1+1)$EA离散优化中，采用简单的调度方案，每次迭代将变异率翻倍。实验表明，对于具有某些特定结构的问题，这种方法优于采用固定变异率的相同EA。直观地说，这类问题的全局最优点常被局部最优点包围，局部最优点起到“陷阱”的作用，因为它们易于被搜索到。一旦算法陷入局部最优，要跳出困境到达全局最优，往往需要变异算子能够实现较大的扰动。在这种情形下，允许$(1+1)$EA提高其位反转变异率，有助于其跳出局部最优找到全局最优。然而，对于其他特性的问题，采用固定变异率可能反而更为合适。

这些严格而具有解释性的理论发现也体现在大量经验研究中，这些研究进一步考察了变异算子参数控制的复杂机制。其中一种方法涉及根据进化算法过程中某些可度量的状态变化自适应地调整变异算子的参数设定，这类机制在文献[46]中被称为状态依赖型参数控制机制。其中的一个具体实例即多样性维持技术。早期研究[119]采用了这样一种机制——根据表征种群收敛水平的特定测度值动态调整交叉率与变异率。该测度值为种群中最优个体与平均个体适应度的差值，即 $f_{\mathrm{max}} - f_{\mathrm{avg}}$。算子的具体实现采用了一个简单的缩放函数，使变异算子参数与收敛水平呈反相关关系，从而动态改变交叉率和变异率。然而，该方法还引入了额外检查，即当种群收敛且多样性较低（例如 $f_{\mathrm{max}} - f_{\mathrm{avg}}$ 较小）时，对适应度较低的个体施加更高的交叉率和变异率。
我们上文所描述的机制需要用户设计调度方案、函数，以及任何用于更改参数的操作。其有效性往往依赖于对问题结构的某种先验知识。作为该方法的替代，可以采用自适应控制方法。这种方法将变异算子的参数与种群中的候选体相关联，参数的变化通常通过某种扰动过程进行，但只有当对应候选体在进入下一代时被选择复制时才会真正应用。例如，文献[135]为差分进化（DE）引入了这种自适应控制。在该情况下，DE的变异算子中的交叉概率与变异因子通过扰动来调整，例如利用基于柯西分布（Cauchy-distribution）的扰动来改变变异因子。需要注意的是，由于变异算子中的参数与解表示中的参数采用不同的调整机制，因此这被视为一种自适应控制方法。当进化过程直接用于同时调整两组参数时，则称之为自适应（self-adaptive）参数控制机制。我们在第1.2.3节中已经介绍了一种针对实值变异算子的特殊自适应参数控制方法，其基于对解向量表示中每一分量独立地施加对称单变量概率分布的独立扰动。

接下来我们要讨论的最后一种方法则采用了更为复杂的机制，使得变异算子的变化不仅仅体现在参数层面，也体现在其符号化操作描述层面。这类机制设计背后的主要操作性问题是，在进化过程中如何将有限且固定的计算资源分配给不同的变异算子，以最大化进化算法（EA）带来的收益，即生成适应度更高的新候选解。此类机制的设计与实现通常采用两种主要方法论：第一种源自机器学习领域，将该分配过程形式化为多臂老虎机（multiarmed bandit）框架；第二种则根植于元启发式算法（metaheuristics），引入了超启发式（hyper-heuristics）概念，即除了可以从现有算子集中选择操作器外，还可利用生成器从基础版本产生更加复杂的算子。早期的研究[107]对此类应用于进化算法变异算子的机制进行了详细综述和实证研究。该研究聚焦于离散优化问题，特别是经典的布尔可满足性问题（Boolean Satisfiability Problem，简称SAT），其任务是为各变量寻找合适的赋值，使得某个命题逻辑表达式得到满足（即表达式的结果为 $\mathrm{true}$）。解可以按照标准的合取范式（Conjunctive Normal Form, CNF）进行表示。CNF 是若干子句的合取，而每个子句为若干文字或变量的析取（即每个变量可取布尔集合 $\mathbb{B} = \{\mathrm{true}, \mathrm{false}\}$ 中的一个值）。例如，2SAT 问题限制命题表达式的每个子句最多包含两个变量，并要求这两个变量中至少有一个为 $\mathrm{true}$。因此，候选解即为针对变量赋予的一组布尔值的组合，从而满足命题逻辑表达式。与精确算法不同，进化算法属于一种近似方法，通过某种代理函数（如最小化为 $\mathrm{false}$ 的子句数量）来引导进化式搜索过程，以寻找问题的解。

在文献[107]中，提出并融合到进化算法(EA)中的一种复杂的算子管理系统，该系统能够实现交叉算子的选择与生成。从原理上讲，这要求构建交叉算子的空间。该空间的构建基于识别出的四个基本特征，每个特征包含了可用于对父代候选体（以CNF形式表示的可能解实例）施加变化的若干动作选项。通过针对每个特征选择一个动作，将这些动作组合在一起即可生成一个交叉算子。实际上，可以对交叉算子空间进行在线搜索，之后筛选出最适合当前进化搜索阶段的算子供使用。对算子的评估涉及表征种群多样性、解质量和执行时间的三个度量。并非所有变异算子的自适应算子选择和超启发式参数控制方法都如[107]中提出的那样复杂。例如，由于固有的技术挑战，唯一针对这类参数控制的少量理论研究之一[48]探讨了一种可通过单一参数调整其变异强度的简单位翻转(bit-flip)变异算子。一般而言，会构建一个参数集或$k$个参数值的集合，通过某种机制从中选择用于变异算子的参数值。基本的参数值选择方法包括概率匹配[46, 107]。在该方法中，每个$i = 1, \ldots, k$的参数值都关联有置信值$c_i$，表示该参数值在当前EA搜索阶段$t$时的适用性。该方法给定选择第$i$个参数的概率$\mathbb{P}_i$，并使之与相应的置信值$c_i$成比例，具体如下：
$$
\begin{align*}
\mathbb{P}_i(t) &= \mathbb{P}_{\mathrm{min}} + (1 - k\mathbb{P}_{\mathrm{min}})\frac{c_i(t)}{\sum_{j = 1}^k c_j(t)}, \\
c_i(t + 1) &= (1 - \alpha)c_i(t) + \alpha r(t)。
\end{align*}
$$
置信值通过归一化的奖励或增益$r(t)$进行加权更新，该奖励反映了EA在应用第$i$个参数设置的变异算子后获得的收益。超参数$\alpha \in (0, 1)$用于控制置信值的自适应速率。需要注意的是，每个第$i$个参数值被选中的概率至少为$\mathbb{P}_{\mathrm{min}}$。
还有其他更为复杂的概率匹配方法，通过对参数值的选择采用更精细的公式设计来实现。在自适应追踪（adaptive pursuit）方法中，更新规则会增加所选参数值的置信度，同时降低在一次进化算法搜索迭代中未被选中的参数值的置信度。在上置信界算法（upper confidence bound algorithm）中，参数值的选择基于最大化两个项加权和的原则。第一项涉及与参数值相关、固定分布下的期望奖励。这模拟了参数值带来最大适应度增益时的利用性搜索行为。第二项则是一个与参数值在历史上被应用次数成反比、并与进化过程迭代次数的对数成正比的函数。该项建模了机制的探索性搜索行为，用于平衡和选择在进化算法早期较少应用的参数值[46]。

### 1.3.3 选择算子上的参数控制  
选择算子的参数控制机制旨在通过对算子参数设置进行特定改变，从而调整其选择压力。例如，可以通过对选择压力进行预定式的变化来实现参数的确定性控制，这种方式是由用户设计的，应用于进化算法其他组件时也经常采用。已有研究和应用的机制之一，基于在随机优化器模拟退火（Simulated Annealing, SA）中所采用的方法。最初的研究[88]将SA解决TSP问题的方法与物理系统中的退火过程建立了紧密联系。非正式地说，后者采用了对多体热力学物理系统的统计描述。在粒子系综的某一特定状态构型 $i$ 下的概率 ${\mathbb{P}}_i$ 遵循玻尔兹曼分布，其概率与 $\exp(-E_i/kT)$ 成正比，其中 $E_i$ 是状态 $i$ 的能量，$k$ 为玻尔兹曼常数，$T$ 是系统的温度。物理退火过程中，通过冷却计划获得热力学系统基态，这一思想被用于设计优化问题的随机搜索过程。此外，生成-检测型搜索过程中包含了概率验收机制。在最小化问题中，若生成的候选解带来改进，即 $\varDelta f \leq 0$，则该解被接受。否则，较低质量的候选解被以概率 $\exp(-\varDelta f / kT)$ 接受。

在文献[44]中，研究者设计了一种玻尔兹曼选择算子，对标准的适应度比例选择算子进行了修改。该修改通过对种群中个体的原始适应度值应用缩放的指数变换来实现，变换函数形式为玻尔兹曼分布。在包含 $s$ 个候选解的种群中，对于第 $i$ 个候选解（$i = 1, \ldots, s$）的选择概率被定义为：
${\mathbb{P}}_i = \frac{\exp\big(f({\boldsymbol x}_i)/T\big)}{\sum_{i}^s \exp\big(f({\boldsymbol x}_i)/T\big)}$，对于最大化问题为 $P_i = \frac{\exp(f(x_i)/T)}{\sum_{i=1}^s \exp(f(x_i)/T)}$。而在最小化问题中，则采用 $-\exp\big(f({\boldsymbol x}_i)/T\big)$ 变换。需要注意的是，如果采用恒等函数，则玻尔兹曼选择算子会退化为适应度比例选择算子。因此，玻尔兹曼选择算子中引入了参数 $T$，该参数可以用来调节选择压力。当 $T$ 取较小值时，这种变换会放大原始适应度值之间的差异，从而增加高适应度个体被复制的概率；而当 $T$ 取较大值时，这种变换会削弱原始适应度值之间的差异，使得复制机会分配得更加均匀。因此，文献 [44] 设计了一种线性降温策略，以期在进化算法初始阶段促进更具探索性的搜索，而随着进化的进行，逐渐转为更具利用性的搜索。

接下来，文献 [108] 对锦标赛选择算子采用了一种自适应、状态相关的参数控制方法。具体而言，该方法通过多样性维护机制，动态调整锦标赛样本的规模，以便在进化搜索的不同时期调节选择压力。文中引入了一种特定的多样性度量方法，称为健康种群多样性（Healthy Population Diversity, HPD）。锦标赛的规模随 HPD 值的变化而动态调整，且与 HPD 成正比。HPD 的计算形式为各候选体与种群平均值之间的适应度加权欧氏距离。

在文献 [55] 中，采用了一种自适应的方法来调节锦标赛选择算子的选择压力。每个个体都附带了一个可随进化过程自适应变化的参数。锦标赛规模的设定则依据不断进化的个体提供的这些参数值的集合来进行调整。

## 1.4 结论与进一步阅读注记  

在对进化算法主要内容的介绍与讨论中，我们强调了这一基于群体、随机和迭代搜索方法的广义问题求解能力。尤其是，进化算法可以通过“生成－筛选”框架来理解，即作为一个包含三大组成部分的计算系统。目前，关于这些组件的实现机制以及参数设定对进化算法性能影响的相关研究已十分充分，包括详尽的实验验证和理论分析。因此，进化算法可以根据待解决问题的结构和性质，合理设计和搭配各组成模块。读者可以查阅现有的进化算法相关文献，借鉴其中在解决类似问题时表现出的有效策略，并可结合文献建议或自身初步实验结果对算法进行调整，以期进一步提升性能。
人们可以很容易地开发出用于解决新问题的遗传算法（EA），但这种便利性掩盖了其搜索行为背后的复杂性。为了让遗传算法作为主要启发式方法并成为精确方法的主要替代方案而被广泛接受，深入理解其进化搜索过程的行为是可以理解且必要的。然而，现实世界遗传算法各组成部分中的机制设计极为复杂，这使得相关分析任务变得具有挑战性。

以适应度景观为例。适应度景观是用于概念理解和分析 EA 解决的优化问题的常用工具。其形式化定义为三元组 $L = (S, f, d)$，其中 $S$ 表示搜索空间，$f: S \rightarrow \mathbb{R}$ 为适应度函数，$d: S \times S \rightarrow \mathbb{R}_{\geq 0} \cup \{+\infty\}$ 是距离度量。对于连续优化问题，适应度景观主要由适应度函数（如无约束优化问题中的 $f: \mathbb{R}^n \rightarrow \mathbb{R}$）来描述，相对直接。不过，即使对于单目标优化这种较为直接的情形，也可以设计出具有不同问题特征的函数【76】，这些函数通常构成基准集，用于评估遗传算法的性能【79】。而对于离散优化问题，或者在需要对解空间进行连续域编码的情形，难度则大幅提升。具体内容可参见文献【43】，以下简要概述。

非形式地说，完整的 $(S, f, d)$ 形式是必要的，因为离散搜索空间 $S$ 的结构取决于其中点 $\boldsymbol{s}$ 之间的拓扑关系。可以将搜索空间 $S$ 表示为图 $G = (V, E)$，其中顶点集 $V$ 表示所有候选解，连通集 $E \subseteq V \times V$ 表示变异算子作用下的解之间的转化。因此，$\boldsymbol{s} \in S$ 的拓扑关系由其邻域结构描述，而该邻域结构又由变异算子的具体形式决定。例如，二进制字符串编码结合单比特变异将诱导出超立方体结构的搜索空间。若采用覆盖二进制字符串全长的多比特变异，则会形成完全图结构。在这样的背景下，随着不同的解表示和编码方式的变化，问题的结构也会发生变化（如引入新的局部最优），这是由于邻域结构的改变所致【43】。因此，通过严谨分析来深入理解现实 EA 的搜索行为极具挑战。这同样适用于理论研究领域，为此，已有大量努力致力于将现实 EA 抽象为更简洁的形式，以及构建具备细致问题结构的基准函数。例如，文献【47】对20年来关于现代遗传算法在离散优化问题上运行时分析的研究工作进行了全面的综述，展示了所涉技术难点。在该领域，EA 被建模为随机算法，其运行时分析包含三个步骤【98】。首先，需要针对进化算法在第 $t$ 轮迭代或时间步之后的进展，确定合适的距离度量 $X_t$。接下来，需要对度量一步变化的性质进行建模和理解，即对任意 $X_t$，研究随机变量 $X_t - X_{t+1}$ 的行为。随后，利用上述知识来刻画 EA 的运行时间 $T$，即解决问题所需的迭代步数。即使是对于在极小化问题上表现良好的简单 EA，其搜索行为也会带来各种挑战。例如，假设这一过程可以构造为马尔可夫链的形式（$X_t \in S : t \in \mathbb{N}_0$），其中 $X_t$ 取自 $S = \{0\} \cup [1, \infty)$，而 $\mathbb{N}_0 = \{0\} \cup \mathbb{N}$。即便在这样的构造下，想要根据漂移 $\mathbb{E}[X_t - X_{t+1} \ | \ X_t = \boldsymbol{s}] \ (对所有\ \boldsymbol{s} \in S)$ 推导出期望首次命中时间 $\mathbb{E}[T]$（即随机变量 $T$，表示使得 $X_t = 0$ 时 EA 最早达到的 $t \geq 0$ ）也并非易事【99】。
我们将在本章结尾简要讨论现代进化优化器与经典数值优化器之间的概念差异与相似性。回到相对简单的单目标优化问题，现代现实世界进化算法（EA）的搜索过程依然体现出高度的复杂性。考虑无约束最小化问题 $f: \mathbb{R}^n \rightarrow \mathbb{R}$，其中 $f$ 是凸函数且具有二阶可微性。特别地，我们关注凸二次最小化问题的范畴（例如，详见文献[21]第9章）。大多数标准基准测试问题[76]均采用了此类二次最小化问题，比如简单的Sphere函数，其形式为 $f(\boldsymbol{x}) = \|\boldsymbol{x}\|^2$，其全局最优解在原点 $\boldsymbol{x}_{\mathrm{opt}} = \mathbf{0}$。在这种情况下，可以采用梯度下降法[21]来求解该问题，因为可以推导出负梯度。对于简单的Sphere问题，不考虑精确线搜索所需的计算量，此方法会沿着当前点指向原点的方向下降。

然而，作为无导数的搜索方法，EA将该问题视为黑箱优化（即关于目标函数的知识仅限于对候选解进行评估的调用或查询[6]），并不会对问题结构进行建模，这也导致其搜索行为有别于其它方法。尽管Sphere问题中的凸性结构保证了精英主义的 $(1+1)$ EA在适应度景观上是下降的（即，只有当 $f(\boldsymbol{x}') < f(\boldsymbol{x})$ 时，生成的子代候选解 $\boldsymbol{x}'$ 才会被接受），但EA的搜索轨迹常常呈现锯齿状（zig-zag），而不是将初始点直线移动至原点。然而，一些现代、种群规模大于1的EA，其搜索行为在定性上可能更接近基于梯度下降方法所展现的特性。总体而言，这涉及到引入能够利用问题结构信息的机制，以引导整个种群的进化搜索过程。回顾一下，诸如进化策略（ES）与进化规划（EP）这样的EA，采用实值的、基于扰动的变异算子，直接由父代候选解产生子代候选解。

在这些方法之中，如协方差矩阵适应进化策略（CMA-ES）则是通过在搜索空间 $\mathbb{R}^n$ 内根据多元高斯分布进行采样，直接生成子代候选解[74]。该方法设计了一种复杂机制，通过利用进化搜索路径的信息来更新协方差矩阵 $\boldsymbol{\varSigma}$，以适应搜索空间。进化路径中的每一步都是 $\mathbb{R}^n$ 中的一个点，其描述为当前代进化种群中表现最好的 $\mu$ 个解在 $\lambda$ 个候选解中的加权均值。因此，在每一代中，子代候选解仅仅是从以当前种群均值为中心的自适应多元高斯分布中采样获得的。
尽管CMA-ES在演化搜索过程中采用了更为机械化的构建方式，但它在概念上为进化策略（ES）家族与依赖于回顾性梯度估计的方法之间建立了联系。随着自然进化策略（NES）的发展[130]，这一联系更加紧密。CMA-ES的主要机制性工作原理，是通过使用在演化过程中受高适应度个体影响而变化的种群，从问题的适应度景观中提取信息，这一点在NES中得到了形式化[102]。原则上，这要求将原始的最小化问题重构为关于参数化搜索分布空间上的期望最小化问题，即$\min_\theta J(\theta) = \mathbb{E}_\theta [f(\mathbf{x})]$，其中通常选择以参数$\theta$为参数的多元高斯分布作为搜索分布。种群在适应度景观中的演化搜索行为，可以看作是在多元高斯分布参数空间上的搜索过程，而搜索的推进则需要依赖用于更新多元高斯分布的搜索梯度。与CMA-ES采用进化种群对期望适应度的采样梯度的机械更新方式不同，这里可以明确地构建多元高斯分布的参数空间，并在此空间中进行优化。对参数空间的优化通过使用自然梯度实现，后者可以推导出最陡峭的搜索方向。如文献[130]中图2所示，直观展示了采样适应度梯度与自然梯度之间的区别。

在本章结尾之前，我们重访前文关于图灵在图灵机与无组织机器方面工作的介绍，它们构成了演化计算与神经计算的理论先驱。自这些理论提出后，经过多年发展，一系列理论研究（如[24, 52, 53]）将所有这些计算概念与相关方法相结合，深入探讨了演化计算的范式。特别地，进化图灵机（Evolutionary Turing Machine）被提出作为研究进化算法（EA）的形式化计算模型。这使得我们能够以某种方式检验EA的表达能力，并回答EA是否能优于那些在数字机器上运行、因而可表示为图灵机的算法等一般性问题。停机问题为此提供了一个形式化的研究环境。具体而言，该问题旨在判定一个任意计算机程序（算法）是否会在给定输入下无限运行或最终终止。已经证明，由图灵机表示的算法无法解决万能图灵机的停机问题（即具备计算任何可计算序列能力的图灵机，因此可以表达任何图灵机）[123]。换言之，不存在能够解决该停机问题的算法，因此这体现了图灵机作为算法类别的可计算性极限。
在文献 [52] 中，进化图灵机被定义为一系列（可能为无限个）图灵机 $\mathbf{T}(t)$，这些图灵机对解群体 $\mathbf{x}(t)$ 进行操作，其中 $t = 0, 1, 2, \ldots$。图灵的理论框架被用来评估进化算法（以进化图灵机表示）的表达能力。多项理论研究结果之一显示，由于进化算法的非算法性搜索行为，其表达能力高于传统算法（传统算法按定义会终止并产生所需解）。可以证明，进化算法能够不断进化解，并使其渐近地收敛到最优解（在有限距离范围内）。除此之外，还可以提出其他可证明的论点。在文献 [53] 中，将进化算法表示为有限状态自动机（FSA），可以用来进化有限状态自动机表示的解，从而使这些解的表达能力超出该类自动机本身的计算能力。展望未来，这类理论洞见对于进化算法在实际问题求解中的设计至关重要，因为，与其开发更加复杂但表达能力无法突破上限的进化算法，不如将进化算法的原理作为元算法进行应用，例如在投资组合优化中进化进化算法。目前，这一方向的研究正在不断增加。
