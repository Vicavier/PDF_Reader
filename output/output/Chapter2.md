# 第2章 协同进化计算简介

## 2.1 协同进化系统：概述

协同进化计算（Coevolutionary Computation）通常是指一类广义的计算系统，这些系统采用了与演化计算（Evolutionary Computation）相同的基本原则。也就是说，这些协同进化系统是基于种群的，同时在搜索过程中应用了变异和选择两种演化算子。作为面向问题求解的搜索过程，这两者都可以在“生成-检验”（generate-and-test）框架中实现，以实现迭代的算法流程。实际上，协同进化计算的早期发展阶段，沿用了演化算法（EAs）中已经提出的通用设计原则，并且采用了相同的演化算子。二者的区别在于，用于确定种群中每个候选解或个体质量的适应度评估过程的具体设计。

一方面，演化算法（EAs）通过绝对性能度量来评估每个候选解的客观适应度（objective fitness）。对于优化背景下表述的问题，通常已知并以封闭形式构造一个适应度函数 $f$，因此候选解的适应度（质量）可以通过对 $f$ 的直接查询得到一个实值输出。另一方面，协同进化系统则通过测试用例评估每个候选解的主观适应度（subjective fitness），而这些测试用例可以在搜索过程中不断变化。此外，协同进化中的适应度评估还需要一个显式的过程（例如通过某种计算过程）来判定候选解相对于这些测试用例的质量。

总之，将协同进化计算视为具有特定区分特征的一般问题求解框架，这一点至关重要。这些特征使协同进化在许多问题设置下表现出色，而这些问题对于传统的演化方法而言则更具挑战性。在接下来的第2.2节中，我们将从类别视角回顾协同进化系统的主要发展，并简要总结自然进化的现代综合理论，以此为背景，考察协同进化系统与自然进化之间的联系。之后，我们将分别在接下来的两个小节中详细介绍和讨论协同进化的基本原理与核心概念。第2.3节将侧重于在“生成-检验”框架下，涉及主观适应度评估过程的协同进化基本原理，我们将探讨这一适应度评估的性质，并论述描述成功协同进化搜索的条件。在第2.4节，将讨论支配协同进化操作、具有特定问题求解能力的两个主要概念，包括种群结构以及协同进化中主体之间的两种交互类型。
## 2.2 协同进化计算的发展

我们在第2.2.1节中，从协同进化系统的若干关键历史发展开始回顾。这一部分旨在为后续章节中关于协同进化搜索过程及主导协同进化系统中机制与主要组件设计的核心概念的更为详细的讨论提供背景。对于促成这些发展的相关研究的回顾，并非以时间顺序进行。相反，我们采用按类别分类的回顾方法，重点关注这些研究试图解决的动机。这些动机可能涉及通过检验与自然协同进化过程中的机制相关的假设，或者涵盖被实现为用于现实世界问题求解的计算系统的设计原则或概念框架。实际上，这也正是演化与协同进化计算研究的两大基本动机：一方面，理解自然进化和协同进化过程中的机制；另一方面，以此指导问题求解的计算系统的设计。在第2.2.1节中，我们将简要介绍生物学中自然进化的现代综合理论，该理论通常结合了群体遗传学理论及对物种内部变异的解释。如此可以采用进化生物学的最新、现代观点，作为讨论自然进化与协同进化系统之间关系的基础。

### 2.2.1 关键发展的分类视角

不出所料，涉及战略决策情形的问题领域，在协同进化系统的研究与开发中受到了早期且重要的关注。首先，以博弈论的形式，对这些问题进行形式化处理的方法自其在文献[84]中提出以来，便不断发展。其次，现代世界中，各类形式的计算设备——从高性能计算集群到移动终端，从公共到私有各个领域——广泛互联。基础研究与应用技术的发展推动了这些战略决策类问题求解能力的普及与提升，而这些问题正是诸多人类活动的显著特征[58]。在人工智能领域，博弈为评估系统智能行为的开发与测试提供了手段。具体来说，博弈是某些智能体为获取奖励而付出特定资源开销的行为活动的模型。
抛开人工智能中更为形式化的方法，早期协同进化计算的关注点在于理解一个由多个主体组成的群体如何通过自然进化过程，仅凭有限的预置知识，在相互之间做出和执行决策的互动中，发展出智能的决策行为 [12]。更具现实意义的挑战在于，主体是否能够仅依靠其战略性互动，通过协同进化过程学习到有效的决策行为，这些互动可以被建模为博弈过程。以两位博弈者之间的竞争型零和博弈为例。在该过程中，某一玩家获得的收益均来源于另一玩家的损失，即在任何允许的移动序列中体现出对立的收益分配。由于收益分配方式带来的竞争性特征，最终必将产生一方获胜、另一方失败（尽管有时结果会平局，但规则亦可被设计用于打破最终累计收益的平手局面）。重要的是，博弈的结果信息直接可得，无需像处理某些特定博弈性质（如累计收益损失的程度）那样进行额外的信息收集与相关计算。在这种情形下，可以将协同进化过程设计为在博弈主体群体中选择那些胜局次数较多的个体。在任何一次对局中，主体仅具备以状态描述为输入，并输出其据以完成移动、分配资源的决策能力，这些能力受限于博弈规则。这样的输入-输出响应行为可以通过诸如人工神经网络（ANNs）等合适且可能非线性的参数化表示方法建模。这一建模方式也限制了可被集成到主体决策能力中的博弈知识总量，或许仅包括按照博弈规则完成合法落子的某种知识。主体通过其策略表示中的参数实现唯一标识；在协同进化过程中，通过变异算子的参数变动及选择算子带来的复制机会，主体能够调整自身对局行为。然而，仍需探讨的问题是，是否通过仅依赖主体间战略性互动或博弈结果的协同进化，就足以产生具备有效决策能力的个体。此外，每个对局结果本身实际上是主体所做决策序列对应收益的总和，并不存在任何显式机制赋予某些对问题领域知识体系公认至关重要的决策模式更高权重。事实上，早在 [6, 68] 的研究中，就已尝试通过协同进化培养智能决策主体。然而，直到数十年后，伴随着更深入的研究及计算机算力的提升，才真正实现了在几乎不依赖专家知识预编程的前提下，通过协同进化促使主体学会在竞争性零和棋类博弈中对弈 [13, 41]。这些协同进化得到的主体不仅能够在这些棋类博弈中学到高水平的竞争性对弈技巧 [38]，还能展现出堪比专家级人类玩家的战略性对局风格 [16]。
用于学习策略行为的竞争性协同进化框架已被应用于其他类型的博弈。例如，非合作博弈家族中的非零和博弈——以迭代囚徒困境（Iterated Prisoner’s Dilemma, IPD）为代表——就受到了广泛关注。标准的IPD涉及两个玩家在一系列回合中同时选择“合作”或“背叛”。由两位玩家所做出的四种联合动作的收益，可以用标准形式的矩阵表示，该矩阵反映了集体理性（合作）与个体理性（背叛）之间的对立动机[2, 3]。尽管IPD的构造极其简单，但当玩家能够基于历史行为作出决策时，IPD能够在多次迭代中产生复杂的智能体行为[4]。这也导致了固定响应的纯策略数量众多。协同进化的动态过程可能相当复杂，因为IPD策略的不同要素会根据博弈的不同配置（例如博弈中允许选择超过两种操作以及引入噪声时）而在群体中共存[14, 22]。IPD博弈的协同进化框架还被进一步扩展，引入了更加复杂的机制，比如间接交互（例如通过声誉进行）[15, 90]和联盟形成（例如当有超过两位玩家能够同时参与交互时）[73, 74, 88, 89]，这些机制与现实世界中的交互过程紧密相关。尽管这些协同进化过程能够产生复杂的智能体行为，但用于约束交互的博弈描述实际上是明确规定的。博弈作为对实际交互（如经济和社会体系中的交互）的抽象表述，使分析与识别令某些策略行为有效的重要特征变得更为容易。

当我们更希望探索或者以“假设情景”方式评估在放宽智能体交互限制时可能出现的策略行为时，协同进化系统就被设计成一种模拟工具。在这里，软人工生命（soft Artificial Life, ALife）提供了相应的理论框架，从数学和计算两个方面支持了类生命行为的建模与仿真[46]。例如，元胞自动机（Cellular Automata, CA）通常被用作空间或其它类型局部交互的模型，其通过定义特定的类似网格的邻域结构，使智能体在有限种群中的交互具有空间局部化特性[29]。这有别于大多数协同进化中的选择机制，多数选择机制采用某种形式的随机抽样来从种群中选择用于交互的智能体。具有开创性的研究[76]考虑了更符合现实复杂性的类生命行为仿真。交互方式依然采用双智能体对抗模型，即从种群中抽取任意一对智能体进行资源竞争，以求生存和繁殖。然而，这些交互所处的环境本身具有现实中的复杂性。首先，智能体活动的环境是一个三维世界，具备包括重力、摩擦、碰撞等多种模拟物理效应。其次，这些智能体本质上是虚拟生物体，其结构极为复杂，决策过程由具有各种固定功能的神经节点组成的架构所主导，智能体配备输入传感器用于环境感知，并通过输出执行器实现运动与任务执行。生物体的实际运作，包括身体的物理运动，受其形态结构（即各组成部分间的关系）所影响。用以控制身体的形态结构拓扑和神经结构均可通过有向图进行统一描述。这一设计允许构建专用的变异算子，以实质性地改变虚拟生物体，从而实现仅通过交互对智能体的物理形态与操作行为进行协同进化模拟。
协同进化计算与机器学习研究之间存在着强烈的协同作用。有些研究利用机器学习的原理和机制来开发和改进针对学习问题的协同进化系统 [17, 19, 21]。也有一些研究使用协同进化方法来解决各种学习问题。此前，我们已经介绍了博弈策略的协同进化学习，这类问题家族在没有广泛利用领域知识和高性能计算能力的情况下，采用机器学习方法很难有效解决。对于更为经典的学习问题，以二元密度分类任务为例，早期已有工作 [51, 63, 65] 试图通过协同进化的方法演化元胞自动机（CA）规则来完成这一任务。该任务涉及一个一维格点或数组 $N$（其两端单元格相连形成一个环），每个单元格的取值为 $\{0, 1\}$ 这两个二元状态之一。任务目标是根据初始配置中的“1”和“0”的分布判断其是否为高密度（即数组中的“1”多于“0”）。对于配备有足够内存的计算机而言，仅需统计“1”和“0”的数量并加以比较即可轻松完成该任务。然而，真正的挑战在于，这里只允许局部计算并且只能使用极为有限的内存。CA规则用于在若干时间步内，依据每个单元格周围邻域的当前状态改变其自身状态，从而对每个单元格进行变换，直至获得稳定配置 [57]。在这种设置下，若演化后的最终配置全为“1”，则判定初始配置为高密度，反之亦然。即便如此，协同进化学习已被证明可以产生高性能的CA规则，这些规则与先前被认为有效的策略相对应 [85]。这是通过一种双种群（捕食者-猎物）协同进化框架实现的，其中一类种群由CA规则的候选解组成，另一类种群则由不同的初始配置组成。CA规则的适应度等于其正确分类或解决的初始配置的总数；而初始配置的适应度则是没有被正确分类或解决它的CA规则的总数。双种群协同进化设置还可以结合多样性维护技术，以确保种群具有足够多样性，从而促进持续的协同进化搜索进展 [18]。[85] 中采用了一种特殊的竞争性适应度共享机制，其核心思想是根据具体测试用例的解决难度而调整贡献值或权重，而非默认采用均匀分布。在CA规则的相对适应度计算中，被较少CA规则正确解决的初始配置给予更高权重。同理，这一原则也适用于进化初始配置的共享适应度计算。
这种双种群共进化学习的其他应用还包括语法归纳、基因调控推断以及演化机器人学。特别地，所有这些应用都被框定在系统辨识（systems identification）的问题背景下，其中主要的学习目标是构建一个能够代表目标系统底层或内部过程的模型，而该系统的外部输出行为可以在输入数据提供后被观测到[8]。与大多数数据驱动的机器学习方法不同，系统辨识任务中可用的数据通常非常有限。举例来说，获取数据可能成本高昂，即使能够获得数据，这些数据也可能存在偏差，因而很难获得具有代表性的数据集。因此，系统辨识中的主要挑战在于模型学习必须通过有限且谨慎的实验序列来执行。对此，可以利用类似主动学习（active learning）方法的双种群共进化框架来应对这一挑战[8]。具体而言，独立进化的测试用例种群既绕开了数据集可用性的限制，还能生成用于最佳区分另一种群内目标模型的附加测试用例。

共进化原理长期以来一直被用于解决具有挑战性的优化问题。早期的一个经典示例可见于[48]中的开创性工作。该研究关注于寻找一种最小化的排序算法，此算法能够将一个未排序元素列表转化为已排序列表。这种算法被称为排序网络（sorting network），因为其操作具有形象的图形表示形式。排序网络表现为$n$条平行的水平线，分别对应于列表中的$n$个元素。水平线的左端表示未排序的列表，右端对应已排序的列表。算法中的操作通过定向的垂直线表示，每根垂直线由一个箭头指示，连接着第$i$和第$j$条水平线，其中$i, j \in \{1, \ldots, n\}$。每条定向垂直线表示对第$i$和第$j$条水平线所在元素的比较与交换操作。箭头的方向表示交换的方向，即尾端永远拥有较小的元素（例如见[48]中的图1和图2）。本研究展示，双种群共进化框架能够在标准的采用固定测试用例集的演化优化方法基础上取得改进。

最后值得一提的是，共进化已被发展为一种更高层次的通用问题求解框架。其总体动机与超启发式（hyper-heuristics）等其他框架类似，关注点在于自动搜索低层次的问题求解方法以应对目标问题。该框架采用共进化原理作为在算法或启发式搜索空间中进行竞争性搜索的手段，及包括问题分解等问题求解的其他方面。事实上，在后一种情形下，合作共进化（cooperative coevolution）早期就被用于求解那些其解表示允许分解结构作为组件的复杂问题[67]。很明显，并非所有现实世界问题皆可被分解为独立的组件。这些组件之间常常存在复杂的相互依赖关系。因此，该框架旨在对这些组件进行协同适应。针对每个组件，候选解都来自于一个遗传上隔离的种群（即不与其他种群进行交叉或候选迁移）。然而，所有组件的候选解将协同合作，形成问题的完整解。剩下的步骤包括适应度评估，并在各自的种群内对这些候选解施加适当的选择压力。这可以被表述为一个积分分配（credit assignment）问题，其中来自其他种群的固定代表用于对当前隔离种群中的候选体进行适应度评估。
对这种协作协同进化框架的受控实证研究已经证明了其在训练用于模式分类任务的人工神经网络（ANNs）中的可行性。事实上，该协作协同进化框架还可以集成多种其他扩展，充分展示了其通用性。在文献[45]中，该研究将该框架扩展用于ANN训练，以协作进化集成方法。具体而言，组件现在以单独的神经网络形式出现，可以采用机器学习中集成方法常见的软组合方式进行组合。在性能评估和协同进化解的选择过程中，应用了多目标优化方法，这些解现在表现为两个独立的目标，分别涉及分类性能以及单个ANN输出与所构建集成输出之间的歧义性或相关性度量。这种协作协同进化框架在现实世界问题求解中的其他应用还包括优化与设计问题。在文献[91]中，该框架被用于解决一个特殊的二次指派问题（QAP）实例，该问题体现为为涉及多个功能模块并具有一定底层数据流依赖（典型于信号处理与多媒体应用）的算法的调度执行分配结点（多处理器）映射。在文献[55]中，协作协同进化框架的并行实现被直接用于整个生命周期内复杂工程设计问题的求解，这类问题适合问题分解，并允许对子问题进行并发优化任务。这种更高层次、通用的问题求解协同进化框架并不仅限于协作场景。事实上，该框架还可扩展到前文所述的竞争协同进化场景。例如，可以通过引入多样性维护机制的单种群竞争环境下，协同进化并生成游戏策略集成[21]。定量分析已经验证，所构建的集成体由于覆盖效应（即每个个体能击败对手策略的不同子集），在泛化性能上优于集成体内的个别策略[17, 18]。这种协同进化原理已被用于开发自动化并行组合优化器。在文献[54, 80]中，采用了一个双种群竞争架构，用于协同进化一组优化器种群和一组组合优化问题实例种群。这需要对优化器与问题实例都进行参数化。大多数启发式优化器都带有参数设置，可结合转换算子一起利用，用于构建其配置或参数空间。像旅行商问题（TSP）这样的组合优化问题通常具有某种规模度量，可以作为扰动过程的固定设置，用于生成问题实例。这两个种群以竞争方式协同进化，并行实现的框架已成功生成一组优化器种群，其整体性能能够接近专家设计的优化器，用于解决新生成的问题实例。
### 2.2.2 演化生物学及其与协同进化计算的关系

在1997年关于演化计算的综述论文[5]中，简要提及了新达尔文主义综合理论或自然进化模型[49]，该理论结合了达尔文进化论[23]和孟德尔遗传学，用以阐述进化算法（EA）的基本结构。具体而言，一个标准的进化算法包含有一个个体种群，该种群经历变异与选择的过程。许多现代进化算法在进化搜索过程中采用了比前述基本进化算法更为复杂和深入的方法。然而，多数演化计算领域的研究论文（包括综述论文[5]）在其引言部分，通常仅以简明扼要的方式介绍新达尔文主义的进化综合理论。事实上，这一理论的原始形式以及演化生物学研究的传统介绍更加复杂和丰富，涵盖了遗传学、生态学和古生物学等多个领域的概念与发现[49]。实际上，该现代综合理论（即生物进化的综合理论）自身也处于不断发展中，领域内专家对于是否需要对其进行更新仍存在持续争论[52]。尽管如此，本文仍将根据演化生物学教材[44]，对现代综合理论进行简要但更为深入的介绍。我们的动机是，一方面更全面地介绍该进化模型，另一方面探讨其与演化计算中所设计的一些更复杂系统（如协同进化系统）的关系。

现代综合理论有若干核心概念作为支撑[44]：首先，基本的生物进化过程是在种群层面上进行的，而非个体层面。这意味着，生物进化过程被概念化为种群中可遗传变异频率的变化，而不是特定个体的变化。第二，遗传是通过基因实现的，这些基因目前普遍被认为是DNA或RNA。特别需要指出的是，拉马克关于个体经验向后代传递的观点，现在仅被视为一种调节自然选择的文化遗传形式。以此为例，在有性生殖过程中，真核生物通过配子传递给后代的DNA序列并不会受到父母经验的影响。第三，遗传变异来源于个体中罕见的突变；然而，被普遍接受的观点是，自然选择作为一种稳定化（净化）过程，使具有功能性的变异能够得以保持。迄今并无确凿证据支持定向突变能够导致个体功能性提高的观点。群体遗传学理论规定，突变应被视为可稳定传递的、可遗传变异的改变。第四，有多种因素影响可遗传变异的频率，包括突变、遗传漂变、基因流动和自然选择。然而，自然选择被视为导致这些频率变化并促进正适应的唯一因素。此处需要注意的是，自然选择被定义为具有生殖能力实体（包括基因、表型不同的个体、物种和种群）在后代产生数量上的持续性差异。
在这一点上，需要特别注意的是，现代综合理论的大部分内容旨在描述我们能够通过多种证据来源观察到的生物进化现象，特别是多细胞真核生物在以高等类群（如动物）为主的物种中的逐代缓慢变迁。具体来说，这类个体的大规模表型变化（即那些可以直接观察到的物理性状）通常是通过微小且渐进的变化，在极其漫长的时间尺度上发生的。物种被认为是由性繁殖、隔离的种群群体构成的。物种的进化分化则往往是由于这些种群之间因地理隔离而产生的结果。总的来说，现代综合理论[44]主要由群体遗传学的理论框架[35, 47, 87]构成，该理论形式化了以遗传变异频率变化为基础的进化过程，以及对物种内变异的解释[26]。群体遗传学的核心理论不断吸收和融合新发现的突变形式，例如，无论突变是作为每次涉及一个碱基对互换的单碱基替换，还是作为一段转座元件插入调控序列或区域，从而影响较长的核酸序列。进一步来说，自然选择本身也是一个非平凡且高度复杂的概念。例如，适应度（生殖率）的上位效应就是由基因间的相互作用产生的。此外，生物进化的丰富性还体现在物种的多样性、它们在与其他物种相互作用过程中的专化，以及其中某些过程与结果涉及互惠进化变化，即在捕食与猎物、寄主与寄生、竞争与互利共生关系中共同进化[27, 82]。鉴于生物进化如此复杂，自然不难理解这样灵感来源于自然进化过程，或以自然进化过程为设计原则的进化算法（EA）同样会表现出复杂性。实际上，在具备上述现代进化综合理论的基本认知后，可以认为早期的进化算法如遗传算法、进化规划和进化策略，通常只是高度简化和抽象的进化模型。一方面，综述性论文[5]及类似观点的文献正确地指出，在如此受限的设定下，进化算法中的过程确实与自然进化中的过程具有类比关系，并受到其启发。另一方面，更加复杂和精细的搜索型进化算法，如采用岛模型[7, 79]、协作与竞争共进化[11, 48, 67, 70]的算法，则不存在关于个体的绝对适应度概念，而是以相对和动态的方式表现，依赖并要求个体间的相互作用来计算适应度。我们在此提出的观点是，这类系统采用的过程更加贴合现代综合理论所揭示的真实生物进化过程。例如，共进化系统依赖于代表子问题潜在解个体之间的协作交互，其协同适应有助于发现整体问题的新颖解。
换言之，演化过程中丰富多样的机制自然而然地激发了各种可以在进化计算和协同进化计算中被合适地形式化为可计算算法的机制。事实上，2015年一篇后续的立场论文[28]在论述自然进化与人工进化之间关系时，提出了一个更为普遍的观点。首先需要指出，文中所用的“人工进化”一词，是用来涵盖进化计算范式下的软件实现（在计算机中实现），以及进化机器人学（过程在物理基质或硬件上运行）。更关键的是，进化算法（EAs）并不一定严格忠实地再现了自然进化，而是通过包含三个基本组成部分——表现形式（遗传）、变异（突变）、选择——进化算法同样构成了一种进化过程，与自然（生物）进化在本质上是一致的。这一点可以扩展到协同进化计算的所有过程实现，因为这些实现都具备并依赖于这三个组成部分。从这样的观点来看，自然进化与人工进化都可被看作包含这三大基本组成要素的“进化”一般过程，两者之间因此存在可以双向利用的联系。

## 2.3 协同进化的基本原理

协同进化计算在进行适应度评估时的早期动机之一，是为了应对这样的问题：即缺乏一个能准确反映问题属性的绝对目标函数，或者这样的目标函数难以构建。相反，候选解的适应度通过一组测试用例来评估[48]。这种协同进化的适应度评估过程以候选解与测试用例集合为输入，输出一个标量值。该过程所执行的度量应具备两个重要属性。首先，该过程的输出能唯一地反映候选解在该组测试用例下的性能。其次，输出值之间的差异应对应于这些候选解相对于测试用例集合性能上的差异。
非正式地说，这种协同进化的性能度量被称为在候选解集合上施加了一个度量。这是因为人们可以通过候选解之间适应度值的差异或距离，来获得关于任意一对候选解之间关系的某种理解。该度量过程可以在基于测试的协同优化（test-based cooptimization）背景下更为正式地描述[66]。候选解 $\boldsymbol{s} \in \boldsymbol{S}$ 解决测试用例 $\boldsymbol{t} \in \boldsymbol{T}$ 的性能，由距离函数或度量 $M: \boldsymbol{S} \times \boldsymbol{T} \rightarrow F$ 描述，其中 $F \subset \mathbb{R}_{\geq 0}$ 是实数集的一个子集。在协同进化中，候选解的适应度评估是针对一组测试用例 $\boldsymbol{T}' \subseteq \boldsymbol{T}$ 进行的。协同进化解的质量函数由集合 $\boldsymbol{T}'$ 上 $M(\boldsymbol{s}, \boldsymbol{t})$ 聚合后得到的质量或适应度值 $f(\boldsymbol{s})$ 来描述。需要注意的是，为了表述简便，我们将 $\boldsymbol{T}' \subseteq \boldsymbol{T}$ 视为集合而非多重集（即元素可以重复），但在实际应用中多重集或包（bag）是非常常见的。对于这些值的聚合，可以采用多种方法。这一点在一些研究中得到了形式化，这些研究基于不同的解概念（优良性的定义）[30]，如机器学习中的泛化[17, 70]、多目标优化中的帕累托最优性[25]、以及博弈论中的纳什均衡和支配关系[34, 77]。在协同进化中，一个常用的解概念是最大期望性能（maximum expected performance）[24]，这与泛化性能有关[17, 70]。如果假设集合中的每个测试用例同等重要，则只需直接求和，即 $f(\boldsymbol{s}) = \sum_{\boldsymbol{t} \in \boldsymbol{T}'} M(\boldsymbol{s}, \boldsymbol{t})$ （由于求和与求平均之间只差一个常数乘子，该乘子等于测试用例集合的大小 $|\boldsymbol{T}'|$）。对该解概念而言，性能最优的候选解为 $\max_{\boldsymbol{s} \in \boldsymbol{S}} f(\boldsymbol{s})$。注意，解概念的选择极为关键，因为这不仅决定了解的优良性该如何解释，同时也决定了解的表达形式。在前述的最大期望性能这一解概念下，解可以表现为单个候选解。而对于其他解概念，则可能是一组解（如帕累托前沿，Pareto Front）[32, 59, 60]，或如纳什均衡那样以解的混合体或在无限种群中取有限近似比例的方式存在[33]。虽然我们现在能够形式化定义协同进化中的适应度评估，但其在搜索过程中的具体操作要复杂得多。候选解的主观适应度评估关注两大性质：适应度值与协同进化过程中的繁殖成功相关联[10]。协同进化候选解的适应度是相对的且动态的，因为用于评估的测试用例集本身也在不断演化。为在更实际的情境中说明这两种性质，假设在协同进化搜索过程中第 $k$ 次运行的第 $t$ 代，使用的测试用例种群为 $\boldsymbol{T}^{\prime}_{t,k}$。需要指出的是，与大多数包括进化算法和协同进化的随机算法惯例一样，搜索过程通常重复 $K>1$ 次，单次运行的索引为 $k=1,2,3,\ldots,K$。假设有某个特定的协同进化候选解 $\boldsymbol{s}$ 在每一代与每一运行中都存在，则其在 $\boldsymbol{T}^{\prime}_{t,k}$ 下的适应度为 $f(\boldsymbol{s}, \boldsymbol{T}^{\prime}_{t,k})$。这里存在候选解 $\boldsymbol{s}$ 对不同测试用例集合的适应度取值不同的可能性，这正是相对适应度的概念，即 $\boldsymbol{s}$ 的适应度值完全依赖于 $\boldsymbol{T}^{\prime}_{t,k}$，即当 $\boldsymbol{T}^{\prime}_{t,k} \neq \boldsymbol{T}^{\prime}_{u,j}$ 时，$f(\boldsymbol{s}_i, \boldsymbol{T}^{\prime}_{t,k}) \neq f(\boldsymbol{s}_i, \boldsymbol{T}^{\prime}_{u,j})$。动态适应度的概念则是指在同一次运行 $k$ 内，只要 $t \neq u$ 且 $\boldsymbol{T}^{\prime}_{t,k} \neq \boldsymbol{T}^{\prime}_{u,k}$ ，则有 $f(\boldsymbol{s}_i, \boldsymbol{T}^{\prime}_{t,k}) \neq f(\boldsymbol{s}_i, \boldsymbol{T}^{\prime}_{u,k})$。注意，对于涉及 $\max_{\boldsymbol{s} \in \boldsymbol{S}} f(\boldsymbol{s})$, $f(\boldsymbol{s}) = \sum_{\boldsymbol{t} \in \boldsymbol{T}'} M(\boldsymbol{s}, \boldsymbol{t})$ 的这一特定解概念而言，当采用 $ \boldsymbol{T}' = \boldsymbol{T}$ 时，适应度即具有客观性。在这种情况下，对任意两个候选解 $\boldsymbol{s},\boldsymbol{s}' \in \boldsymbol{S}$ 之间的优劣可以由它们的适应度值来判定，例如用二元关系 $f(\boldsymbol{s}, \boldsymbol{T}) \leq f(\boldsymbol{s}', \boldsymbol{T})$ 来描述。例如，若 $f(\boldsymbol{s}, \boldsymbol{T}) < f(\boldsymbol{s}', \boldsymbol{T})$，则有二元关系 $\boldsymbol{s} \rightarrow \boldsymbol{s}'$（即 $\boldsymbol{s}'$ 优于 $\boldsymbol{s}$）。若假设两人博弈是对称的，则有限集 $\boldsymbol{S}$ 的所有两两偏好关系的完整底层结构可以用有向图（digraph）来刻画[20]。如果结构满足存在唯一支配解 $\boldsymbol{s}^*$，即对于所有 $\boldsymbol{s} \in \boldsymbol{S} \backslash \{\boldsymbol{s}^*\}$ 都有 $f(\boldsymbol{s}, \boldsymbol{T}) < f(\boldsymbol{s}^*, \boldsymbol{T})$，那么……
$\max_{\boldsymbol{s} \in \boldsymbol{S}} f(\boldsymbol{s}) = f(\boldsymbol{s}^*)$，其解为$\boldsymbol{s}^*$。在实际应用中，通常不会采用$\boldsymbol{T}' = \boldsymbol{T}$，因为对于$s \in \boldsymbol{S}$获得$f(\boldsymbol{s}, \boldsymbol{T})$的计算代价过高，例如集$\boldsymbol{T}$极其巨大。因此，实际中会选用较小的子集$\boldsymbol{T}' \subset \boldsymbol{T}$，以保证整个共演化搜索的计算成本可控。在该情形下，共演化适应度的相对性和动态性在搜索过程中起到关键作用。为了更好地理解这两种性质如何影响共演化搜索，我们继续之前的例证。假设初始种群在所有重复实验中都以相同的个体候选解集合$\{\boldsymbol{s}_i\}$初始化。为便于表述，这里省略了$t, k$等下标。然而，每次重复运行和每个算法迭代中，测试用例集均不相同。并假定当采用不同测试用例集时，同一解的适应度值会发生变化。在这种情况下，对于各个实验$k=1,2,3,\ldots,K$的初始种群，有一组适应度值$\{f(\boldsymbol{s}_i, \boldsymbol{T}'_{1,k})\}$。$\{\boldsymbol{s}_i\}$中个体的选择依赖于其适应度$\{f(\boldsymbol{s}_i, \boldsymbol{T}'_{1,k})\}$。对于优先考虑适应度高低的选择机制（如适应度比例选择），可以观察到，每次实验中个体$\boldsymbol{s}_i$被选择的概率${\mathbb{P}}_{\boldsymbol{s}_i}$在不同$k$之间会有所不同。对于根据适应度对候选解排序的选择机制，$\{f(\boldsymbol{s}_i, \boldsymbol{T}'_{1,k})\}$的排序变化也可能影响$\{\boldsymbol{s}_i\}$的繁殖率。在这一具体示例中，即使每次实验初始化的候选解集合完全相同，不同的实验$k$之间，共演化过程的初始轨迹也可能不同。更重要的是，在一次有效搜索过程中，共演化的行为或动态特性取决于为进化中的候选解种群呈现的一系列测试用例集。这一过程常被描述为“军备竞赛”动态，即共演化推动解对不断增长的多样性测试用例获得更高的整体性能[31, 50, 61]。关键在于，这一动态是在使用规模较小、但不断变化和改进、以对更丰富的解带来挑战的测试用例集背景下实现的。此类动态在捕食者-被捕食者共演化等场景中表现得更为明显，此时解和测试用例的角色具备明确分工。然而，如相关研究所指出的，这种“军备竞赛”动态并不会随着共演化的建立而自动发生。例如，防止长期进展的周期性动态很常见，通常需要额外的机制来加以解决[75]。
## 2.4 协同进化中的概念

前文中，我们简要讨论了协同进化过程中候选解与测试用例之间的“军备竞赛”动态，这种双方不断交替改进被视为协同进化搜索取得成功的标志。这种军备竞赛的动态对于充分利用协同进化所采用的主观适应度评估方法至关重要，因此能够限制或解决由采用相对和动态适应度值引导协同进化搜索所带来的固有问题。文中通过一个具体的协同进化设置进行了说明。然而，协同进化还存在其他设计和应用于解决各种问题的设置。在这里，我们将介绍并讨论两个重要概念，这两个概念有助于对这些不同的协同进化系统进行分类。它们分别涉及种群结构，以及共同进化种群成员之间的交互类型。需要注意的是，这两个概念并非无关紧要，它们对于描述这些复杂的协同进化系统以及识别其中具有共性的特征以便进行分类都具有重要作用。

### 2.4.1 协同进化中的种群结构

协同进化系统中的种群结构是指在选择与变异算子作用下，个体的具体配置与分布。协同进化系统中最简单的种群结构是只包含一个随机交配种群的情况。在这种单种群协同进化中，种群中的每个个体同时扮演候选解和测试用例的双重角色。因此，单种群协同进化通常与竞争性协同进化相关联，尽管反之未必成立。同样可以理解，大多数单种群协同进化系统主要应用于博弈（游戏）相关的问题[13]，以及那些本质上具有对抗性的、能够被建模为博弈的问题。例如，机器人学[78]和国防领域[22]中的相关问题。

更为复杂的种群结构则涉及多种群设置。在这种情况下，协同进化系统中存在$\ell \geq 2$个种群。引入多种群协同进化对于构建能够通过不同机制解决多类问题的协同进化系统具有关键意义。特别地，各种问题求解方法可以集成到协同进化框架中。为了区分和分类这些不同类型的协同进化系统，还需要进一步关于协同进化特征的概念。其中之一便是种群成员之间的交互类型，这将在下一节详细讨论。作为简要介绍，存在一些协同进化系统设计了特定的“分而治之”问题求解机制。具体而言，这些系统通过问题分解，需要不同的种群，每个种群的成员代表分解子问题的候选解。回到协同进化特征相关的讨论，多种群设置下关于种群结构的两个重要且相关的方面需要进一步阐述，即不同种群成员之间的基因隔离或独立程度。
我们首先讨论两个种群协同进化的简单情况。由于种群成员所扮演的角色不同，两者之间可以实现完全的遗传隔离。在大多数捕食者-猎物协同进化中，候选解和测试用例分别扮演不同的角色，通常具有不同的参数表示方式。在这种情况下，它们被放置在两个独立且完全隔离的种群中，因为需要特定的变异算子才能在各自的种群中产生新的个体。例如，这种捕食者-猎物配置被用于协同进化一组解（以排序网络的形式）与一组测试用例（为待排序的二进制数字列表或序列） [$48$]。另一个例子中，捕食者-猎物设置被用于协同进化一组解（以CA分类器的形式）与一组测试用例（需对其1或0的密度进行分类的二进制字符串） [$51, 65$]。尽管在上述两个例子中，都采用了编码技术使解以二进制字符串的形式表示，但由于代表解和测试用例的二进制字符串长度不同，且尤其是其底层结构（决定了解的最优性或测试用例的挑战度），因此无法有效地在两个种群间使用交叉操作。需要注意的是，也有如文献[$50$]中所述的捕食者-猎物设置，协同进化追逐和逃避的机器人个体（例如，具备不同的最大速度等不同表型规格），但其底层基因型表示方式是相同的，即均以人工神经网络($\mathrm{ANN}$)为控制器。协同进化种群之间的遗传隔离的另一个方面，与系统中促进种群多样性的设计特性或机制有关，这有助于实现长期且持续的搜索性能。再举一例，捕食者-猎物设置也可用于协同进化二人对弈游戏的智能体 [$72$]。此时，两个种群成员或智能体所扮演的角色是相同的。对于这些种群，实施了完全的遗传隔离，并引入了增强多样性的机制，如适应度共享作为此类协同进化系统中的设计特性，用以提升搜索性能。

这种双种群结构可以扩展为多种群结构。在[$83$]中，提出了九种群竞争协同进化，并证明其在搜索赛车控制器时，相比于单种群竞争协同进化具有更优越的搜索性能。该研究采用了遗传隔离，尽管在这种多种群协同进化设置下，也可以引入迁移机制，此时所有种群成员扮演相同的角色，因此可以构成问题的完整有效候选解。在这种情况下，多种群结构类似于用于进化算法($\mathrm{EA}$)的岛模型 [$7, 79$]。
### 2.4.2 协同进化中的交互作用

交互作用在协同进化中极为重要，因为它们是个体适应度值的内在来源——通过明确定义的解概念获得、解释，并进一步用于引导搜索过程[25]。迄今为止，我们的讨论大多集中在将协同进化中的交互作用适当地建模为竞争性和非合作性博弈上，这是因为在现实世界中存在大量具有对抗性本质的问题实例。对于单种群竞争性协同进化，其最简单的交互形式是对称的二人博弈。在这种情况下，两位参与者之间没有区别，也就是说，作为解答者和测试者的角色是完全相同的。任一位参与者都可以从同一策略集合 $\boldsymbol S$ 中选择博弈策略。对称二人博弈可同时进行。此类博弈的简单例子包括囚徒困境(IPD)[1]和鹰鸽博弈[34, 39, 40]。对于只进行单步对局的一次性博弈，其交互方式及结果均可被完整地描述。每场博弈被定义为一对 $(\boldsymbol s_i, \boldsymbol s_j) \in \boldsymbol S \times \boldsymbol S$，其中第一位玩家（下标为 $i$）和第二位玩家（下标为 $j$）均从同一集合 $\boldsymbol S$ 中各自选择策略 $\boldsymbol s_i, \boldsymbol s_j \in \boldsymbol S$。笛卡尔积 $\boldsymbol S \times \boldsymbol S$ 指定了所有可以基于任意一组策略对 $(\boldsymbol s_i, \boldsymbol s_j)$ 进行的博弈。对于一场有 $V = |\boldsymbol S|$ 个纯策略的二人博弈，可能的博弈共有 $V^2$ 种。一场一次性、同时进行的博弈还允许直接用收益(payout)表述其结果，而所有可能的博弈结果被存储于一个称为正规型(normal form)或标准型(standard form)[58]的方阵收益矩阵中。对于第一位玩家，这一矩阵用 $\mathbf{A} = (a_{ij} : 1 \leq i, j \leq V)$ 表示，每个矩阵元 $a_{ij}$ 对应 $(\boldsymbol s_i, \boldsymbol s_j)$ 的博弈结果分配的非负收益。由于博弈结构的对称性，第二位玩家的收益矩阵可直接取为 $\mathbf{B} = \mathbf{A}^{\mathsf T}$，即 $(b_{ij} : 1 \leq i, j \leq V) = (a_{ji} : 1 \leq i, j \leq V)$。除此之外，还可以有建模两名参与者或角色之间更复杂交互的其它类型游戏。上述用标准型矩阵描述**一次性同时博弈**的方式，可推广至多轮（多步）博弈。经典实例包括被广泛研究的迭代囚徒困境（IPD）[12, 17, 19, 36, 37, 43]。需要注意的是，对于原始的囚徒困境或其它能够用标准型描述的博弈，通常能够即时进行分析，因为相关矩阵规模较小。这包括判断是否存在占优策略[58]，即是否存在策略 $\boldsymbol s_i \in \boldsymbol S$，对于任意对手策略 $\boldsymbol s_j \in \boldsymbol S$，都有 $a_{ij} \geq a_{kj}$（对所有其他策略 $\boldsymbol s_k \in \boldsymbol S$ 恒成立）。显然，若将此类游戏扩展为多轮、多选或引入其它扩展形式[14]，会导致纯策略数量的组合性爆炸。如果不对博弈结果矩阵施加强约束，则无法立即进行分析。**更为重要的是，除从固定集合中抽取动作序列（例如囚徒困境中的合作与背叛）外，还存在其他涉及二人更为复杂的交互形式。**棋类游戏就是按顺序进行的，角色可能不对称（如黑白方可能拥有不同的下法策略），动作序列极为复杂、非线性且受限[16, 38, 41]。这意味着，博弈过程必须通过直接仿真或计算加以实现，以获取双方面的结果。这也是大多数实际、现实协同演化应用中遇到的情形。

然而，协同进化中的交互作用并不限于对抗性博弈，也可以采用**合作博弈**的形式。实际上，在最早关于合作协同进化框架的研究中[67]，文献和讨论均表明**现实世界的自然及人工系统在形成完整解时需要多个体之间的某种集体交互形式。**此外，用合作博弈论的术语，还需要判定是否存在特定的代理体联盟，作为整体相较于其他组合更加优越或更受青睐。只在少量文献[64, 86]中明确采用了对合作协同演化系统的博弈论分析，这些研究聚焦于多智能体学习（Multi-agent Learning）场景——该场景下团队中的多个自适应代理体需要同时学习、协同互作完成任务。此类环境中呈现的挑战可以自然地通过合作协同演化学习系统加以应对。演化机器人学就是一个实例，其中运用到了合作协同进化系统[42]。除了解决协调任务中共同交互带来的复杂性之外，这类问题中解或适应度的评估同样极为复杂。由特定代理体联盟组成的整体解（每个体代表系统中的不同种群），可以据此评估其质量或适应度。对于单个代理体而言，其适应度往往依赖于团队其他成员的具体组成组成情况，因此，通过其对团队整体性能的边际贡献来确定一个个体的适应度极具挑战且计算开销高昂。这需要考查代理体可能的所有组合，因此，实际中个体适应度只能为估算值。

合作协同进化还被应用于其他问题求解场景，如允许问题分解的静态目标函数优化[56]。在这些场景下，候选解之间的交互……
它们各自子问题的求解与问题分解的方式密切相关。这是因为，在这种情境下，关键的分而治之（Divide-and-Conquer）策略在于识别相互独立的子问题或子组件，并能够对这些子组件的候选解进行评估。已经被研究的一个具体属性是问题的可分性（separability）。为了阐明可分性的概念，考虑一个具有$n$维解空间$S = \mathbb{R}^n$的连续优化问题。假设是在最小化的语境下，一个完全可分的优化问题$f: S \rightarrow \mathbb{R}$满足如下条件：
完全可分的优化问题指决策变量$x_i$之间没有任何相互依赖性。实际上，一个完全可分的$n$维最小化问题，可以被重新表述，并分别作为$n$个独立的一维最小化问题来单独求解。该类问题也可以通过合作式协同进化进行求解，具体方式是设置$l = n$个独立种群。当适应度函数是完全可加可分的，即$f(\boldsymbol{x}) = \sum_{i}^{n} f(x_i)$，若其余$n-1$个子组件的代表性候选解已被确定，则适应度评估将变得非常直接。也存在非可分问题在可加意义下是可分的，即$f(\boldsymbol{x}) = \sum_{i}^{m} f_i(\boldsymbol{x}_i)$，此时有$m \leq n$个独立的子组件$\boldsymbol{x}_1,\ldots,\boldsymbol{x}_m$。如果能够识别出具有相互依赖性的决策变量并将其归为一组，此类问题也能被直接解决。关于变量分组的机制，从随机方法[53]到采用搜索的方法[62]均有涉及。

## 2.5 总结性说明及进一步阅读建议

在本章的介绍中，我们试图将协同进化计算作为一个通用问题求解框架进行呈现，并在这一语境下从更为范畴化的视角回顾了其历史发展。尤其，我们将协同进化系统作为一种普适的、基于进化的解决问题方法，主要用于解决涉及策略决策的情形，这类问题可以被抽象和建模为博弈。协同进化计算与博弈论之间具有天然的联系，因为这两个研究领域的基础都是“交互”。我们对于该框架的介绍，进一步扩展到了其在机器学习与优化语境下的问题应用，并最终引向类似元启发式与超启发式的更高层次问题求解。在后一种情况下，特别是在竞争性协同进化设定中，协同进化系统中的候选解或智能体承担着算法的角色。在这里，协同进化原理被用于在优化器参数空间上进行搜索，而非在传统的优化问题决策变量的参数空间上。针对特定优化算法（策略）实现的智能体，其性能评估以测试为基础，通过在生成的优化问题实例上进行对抗测试。

应用协同进化计算的关键要点在于，**如何对具体的问题求解场景进行建模，使得候选解所经历的进化过程与测试案例的生成过程紧密耦合。**这种耦合机制是通过候选解种群与测试案例种群之间的交互来实现的。尽管这两个种群彼此是独立或隔离的，但它们的交互会产生适应度或质量度量，这些度量又将被各自所属的种群用于优选并繁殖特定的解（测试案例）。

本章最后，我们简要讨论协同演化计算与机器学习领域的相关性。两者在研究内容上存在一定的共性。我们的关注点更侧重于从系统观点出发，对个体组成部分在设计层面上的共享特性进行探讨。接下来的讨论将限制在概念层面，而非具体的实现方式。此外，我们将考虑那些具有对抗性质、可被建模为竞争性博弈的交互关系，因为在此情境下，寻找概念上的相似性更加直接。我们首先从协同进化原理在智能体交互背景下的更宽松或更一般化的视角入手，将其视为主要的概念纽带，而非仅关注因个体与动态或进化集合交互（例如协同进化中的动态适应度景观观点[10]）所带来的相对适应度评价的具体细化。

特别地，关于竞争性协同进化的一项早期研究清楚地引用了机器学习方法中所用机制，这项工作见于[70]。该研究主要被认可为引入了两项促进协同进化军备竞赛动力学的重要机制——（1）通过适应度共享实现多样性维护技术，以及（2）类似于禁忌搜索机制、被称为荣誉殿堂（Hall-of-Fame）的外部存档机制，用以存储特定的测试案例（对手策略）。该研究采用了捕食者-猎物协同进化系统来实现竞争性博弈的学习过程。有兴趣的读者可能会注意到，同一组作者在更早的时候于[69]中提出了博弈竞争性学习的理论框架。尽管该研究的很大部分内容为理论分析，主要处理他们所提出的竞争性博弈计算学习过程的复杂性分析（例如，确立发现主导策略的时间复杂度），但其理论结果极大影响并指导了[70]中双种群竞争性协同进化学习系统内具体机制的设计。

所提计算学习算法的复杂性分析依赖于一个特定且理想化的构造，该构造涉及两组完全独立的学习者集与教师集。两组成员间的交互被设定为二人对抗博弈。学习者集（记作学习集）代表种群，其成员可随算法迭代应用而变化，且博弈主导或最优策略的搜索过程在此展开。教师集（记作教学集）由用于评估学习者表现、区分学习者的对手策略构成。迭代算法同样应用于教学集，以保障区分学习者这一特性得以满足。当且仅当学习集中的任一学习者被当前教学集中的至少一名教师击败时，可实现该目标。该流程的理论结果为教学集的实施提供了重要的需求启示（即，只要能够区分学习者，教学集规模可以很小）。这些需求后来通过适应度共享机制和外部存档机制加以实现。
读者会注意到，[69, 70]在其研究中借用了机器学习领域的多种概念和术语。鉴于这些研究旨在为竞争性博弈开发一种计算学习框架，并受到早期在[48]中提出的演化方法的影响和启发，这种现象并不令人惊讶。同样地，我们的工作[17, 19]也采用了泛化的概念，作为在竞争协同进化中实现客观绩效评价的一种手段。为便于阐述，这里我们将交互简化为对称的双人博弈形式。这种绩效评估的概念，即通过随机抽取自策略空间${\boldsymbol S}$、满足概率分布${\mathbb{P}}_{\!{\boldsymbol S}}$的测试（对手）策略样本，来对某一策略进行评估。令$i, j \in {\boldsymbol S}$分别表示策略，${\boldsymbol s}_i, {\boldsymbol s}_j \in {\boldsymbol S}$是具体的策略实例。策略$i$的泛化绩效$G_i$定义为其期望表现：
$$
G_i = {\mathbb{E}}_{{\mathbb{P}}_{\!{\boldsymbol S}}(j)}[G_i(J)] = \sum_j^{|{\boldsymbol S}|} {\mathbb{P}}_{\!{\boldsymbol S}}(j) G_i(j),
$$

其中，随机变量$J$以概率${\mathbb{P}}_{\!{\boldsymbol S}}(j)$选择$j \in {\boldsymbol S}$，$G_i(j)$表示策略对$\{i, j\}$间博弈的对$i$的结果。可以利用一个规模为$N<|{\boldsymbol S}|$的随机测试策略子集$S_N = \{s_1,\ldots,s_N\}$[17]，便捷地构造$G_i$的无分布假设估计量，并可获得已知的置信区间。通过利用估计$\hat{G}_i(S_N) = \big(G_i(s_1) + \cdots + G_i(s_N)\big)/N$近似服从高斯分布的特性及中心极限定理，可以进一步收紧该置信区间，这里随机样本序列为$\{G_i(s_1),\ldots,G_i(s_N)\}$[19]。

后续研究[66]更明确地将竞争性协同进化（在协同优化背景下建模）与监督学习之间的概念联系起来。具体做法是将监督学习的概念形式主义映射到协同优化框架中。该研究首先定义了协同优化的问题设定，我们在第2.3节引入协同进化适应度评估概念时已简要提及。更具体地说，协同优化下的竞争协同进化涉及在解空间${\boldsymbol S}$中搜索，以最大化目标

$$
f({\boldsymbol s}) = \sum_{{\boldsymbol t} \in {\boldsymbol T}} M({\boldsymbol s},{\boldsymbol t}),
$$

其中$M({\boldsymbol s}, {\boldsymbol t})$为评估指标，定义为$M: {\boldsymbol S} \times {\boldsymbol T} \rightarrow F$，且$F \subset {\mathbb{R}}_{\geq 0}$。例如，协同优化问题族可包括以胜负结果（如$\{0,1\} \subset {\mathbb{R}}_{\geq 0}$，胜为$1$、负为$0$）为表现形式的对称双人竞争博弈。在该设定下，目标是寻找最优策略${\boldsymbol s}^*$，使

$$
\max f({\boldsymbol s}) = f({\boldsymbol s}^*),
$$

此时${\boldsymbol T} = {\boldsymbol S}$，且${\boldsymbol s}^*$为支配性策略，即$\forall {\boldsymbol t} \in {\boldsymbol T} \backslash \{{\boldsymbol s}^*\}$，都有$0 < M({\boldsymbol s}^*, {\boldsymbol t})$[20]。

类似地，文献[66]在协同优化的形式主义框架下描述了监督学习，并以二元分类问题家族为例加以说明。在此情形下，监督学习的问题求解涉及找到正确的赋值或目标函数$g: {\boldsymbol X} \rightarrow {\boldsymbol Y}$，其中${\boldsymbol X}$为需分类的对象集，${\boldsymbol Y} = \{0,1\}$为标签集。目标函数$g$的学习是“有监督的”，因为该过程利用了有限的带标签样本集$\{(x_i, y_i)\} \subset {\boldsymbol X} \times {\boldsymbol Y}$，每个样本由对象$x_i$及其正确标签$y_i$对$(x_i, y_i), i=1,\ldots,N$唯一标识。实际中，$g$通常以带参数的分类器形式$c$实现，其内部参数为${\boldsymbol s} \in {\boldsymbol S}$。我们记$c_{\boldsymbol s}: {\boldsymbol X} \rightarrow {\boldsymbol Y}$，以突出${\boldsymbol s} \in {\boldsymbol S}$的输入-输出响应。在协同优化形式主义下，${\boldsymbol s} \in {\boldsymbol S}$的搜索通过测试用例集$\{{\boldsymbol t}_i\} \subset {\boldsymbol T} = {\boldsymbol X}$进行，性能度量函数为$M({\boldsymbol s}, {\boldsymbol t})$。
$M({\boldsymbol s},{\boldsymbol t}) = {\mathbf{1}}_{\{g({\boldsymbol t})\}} \big(c_{{\boldsymbol s}}({\boldsymbol t})\big)$，其目标为最大化 $f({\boldsymbol s}) = \mathbb{E}_{{\boldsymbol t}\in {\boldsymbol T}} M({\boldsymbol s}, {\boldsymbol t})$，即 $f({\boldsymbol s}) = \sum_{{\boldsymbol t} \in {\boldsymbol T}} M({\boldsymbol s}, {\boldsymbol t})$。注意，度量 $M({\boldsymbol s}, {\boldsymbol t})$ 是一种类型为 ${\boldsymbol S} \times {\boldsymbol T} \rightarrow F$ 的函数，其中 $F = \{0, 1\}$，它由集合 $\{g({\boldsymbol t})\}$ 上的指示函数给定，$\{g({\boldsymbol t})\}$ 是所有可分类对象 ${\boldsymbol t} \in {\boldsymbol X}$ 的正确标签组成的集合。在这种情况下，如果一个分类器 ${\boldsymbol s}^*$ 可以对 ${\boldsymbol X}$ 中的所有对象进行正确分类，则称其为最优分类器，此时 $\max f({\boldsymbol s}) = |{\boldsymbol T}| = |{\boldsymbol X}|$。特别地，当分类器与实际标签一致，即 $c_{{\boldsymbol s}}({\boldsymbol t}) = g({\boldsymbol t})$ 时，有 ${\mathbf{1}}_{\{g({\boldsymbol t})\}} \big(c_{{\boldsymbol s}}({\boldsymbol t})\big) = 1$。该度量可以利用零一损失函数重新表述为错误项，定义为 $L({\boldsymbol s}, {\boldsymbol t}) = 1 - {\mathbf{1}}_{\{g({\boldsymbol t})\}} \big(c_{{\boldsymbol s}}({\boldsymbol t})\big)$，此时优化目标便转化为最小化损失 $f({\boldsymbol s}) = \sum_{{\boldsymbol t} \in {\boldsymbol T}} L({\boldsymbol s}, {\boldsymbol t})$。

我们以一则评论结束本章，比较竞争性协同进化学习（competitive coevolutionary learning）与时序差分（Temporal Difference，TD）学习[9]，后者是一类强化学习方法，已被成功应用到竞争性游戏策略学习问题[81]。相关研究（如[71]）比较了协同进化与TD学习在竞争性游戏中的表现。这两种方法都能通过某种自举机制，在无合适目标教师集合或函数的情况下，使智能体行为随环境自适应。在竞争性博弈学习中，这些自举机制原则上采用（可能是不同版本的）智能体自身作为对手，通过对弈生成游戏过程轨迹，引导学习过程。不过，二者的相似性仅此为止，因为协同进化和TD学习在利用游戏过程方面存在根本差异。一方面，协同进化通过各种策略组成的智能体群体之间完整对弈的结果来指导搜索，根据各自表现优劣调整策略；另一方面，TD学习则可利用智能体自我对弈过程中动作序列本身进行搜索引导[81]。这种本质性差异源于对博弈学习问题求解方式的不同理解，尽管二者通常都采用类似的人工神经网络（ANNs）作为解的表示方式[71]。在协同进化学习中，人工神经网络作为非线性响应函数，把（输入）博弈状态映射为（输出）合法行动，从而直接搜索博弈策略空间；而在TD学习中，人工神经网络则作为价值函数的近似器，将每个游戏状态与其长期绩效指标相关联，该价值函数与实现博弈策略（策略函数，policy）的控制器相关联[9]。
