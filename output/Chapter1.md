### 第1章 演化计算：概述
#### 1.1 作为现代搜索启发的演化计算

作为人工智能（AI）方法的一个现代分支，演化计算融合了源自自然演化过程的计算系统和方法。它们被用来解决复杂的实际问题，并在合理的时间内提供质量充分的解决方案。这些方法广泛应用于多个领域，从物理学、生物学到社会科学，处理以优化和学习任务表述的问题，以及涉及建模和仿真的问题。在这些情况下，它们为传统的精确方法提供了工作替代方案，后者往往无法在规定的时间框架内保证提供最优解，或者需要进行显著增强来应对特定问题结构，还可能需要放宽支撑这些方法大部分形式化建构的强假设限制。

尽管典型演化计算方法与传统方法之间存在原则上的工作差异，但两者也有共同之处。实际上，通过搜索进行问题求解的概念具有普遍性，并涵盖了许多方法家族[114]。这些演化算法（EAs）是在一种“生成-测试（generate-and-test）”框架内构建的，这个框架采用一个可在计算机上实现的迭代程序[131]。因此，问题求解本质上是对解空间进行迭代搜索。在每一步中，生成新的候选解，然后根据一组标准进行测试，以确定是否达到了搜索目标，从而是否停止搜索。直接的方法是使用问题定义来制定测试准则，同时可以采用不同的系统化方法来生成连续候选解。

然而，这种“无信息搜索”可能存在潜在限制。通过一个简单的例子，考虑涉及离散结构的问题，其解的表示形式通过下述方式进行参数化，使整个有限解空间被布局为一个由独特候选解组成的列表。若暂停搜索停止并保持问题固定不变，则使用特定生成方式的“无信息搜索”行为类似于对该列表的某种排列进行操作。可以将搜索行为理解为按照从左到右的顺序进行，并在每一步测试候选解。在最坏的搜索情境下，最满足测试准则的候选解最终被生成在最后一步，也即位于列表最右端。
当生成后继解的策略固定而问题发生变化时，可以提出类似的论点。重要的是，如果希望在合理减少计算时间的情况下避免最坏情况，换得一个质量上可接受但可能次优的解决方案，那么就需要对问题的性质拥有额外甚至是部分的理解。在实际应用中，这通常涉及一种启发式函数，该函数指示当前候选解距离最优解的远近，从而为后继解的选择提供指导。此外，还可以将后继解的生成局限于通过变换操作符定义的小邻域范围内。现代启发式方法结合了这两种方法学特征，生成迭代搜索算法，其效果是在搜索中限制解空间的子集。继续我们的简单示例，搜索空间现在是一个显著缩短的列表。当然，现代启发式搜索方法采用复杂的程序，其中甚至其理论模型在应用于现实问题的抽象时都需要完备的数学工具进行分析。这一点同样适用于演化算法（EAs）。一个例子是理论分析中使用的概率处理方式，用于将演化算法视为求解离散优化问题的一类随机算法 [47]。遇到的挑战将来自于演化算法的搜索行为性质。分析需要：(i) 在每个时间步形成对演化算法状态的描述，这反映整个候选解种群的整体情况；(ii) 跟踪种群在演化过程中的变化。演化算法工作的状态空间与分析所需的区域不同，并且比底层搜索空间更复杂。尽管这些工具的开发使演化算法的严格分析成为可能，同时也为设计和构造更高效的演化算法提供了新的见解，但演化计算领域的某些根基深植于经验观察。在20世纪50至60年代，关于自然演化过程的观察为这些新型方法提供了一些基础性原则的动机 [13, 14, 20, 22, 64, 65]。感兴趣的读者会注意到，这些研究不仅限于探索演化方法在一些抽象优化和决策问题上的应用。例如，研究 [20] 提出了一个类似于演化算法的程序，该程序当时用于机器计算能力有限的工业制造环境中的运筹学背景。而其他研究则探索了有限计算机上的演化过程并考察其涌现特性，与复杂适应系统（Complex Adaptive Systems）和人工生命（Artificial Life）有着类似的方式 [11, 12, 61]。随后，其他独立研究接踵而至，成为后来在20世纪90年代演化计算领域统一且被统称下的三个主要分支的前身。这三大分支分别是：遗传算法 (Genetic Algorithm, GA)、演化编程 (Evolutionary Programming, EP) 和演化策略 (Evolution Strategies, ES) [9, 58]。后来一些新方法被提出，起初与这三个主要分支类似，但随后显示出显著的发展，逐渐在概念成熟后形成自己的新类别。一些这些类别采用了像粒子群优化 (Particle Swarm Optimization, PSO) [19, 34, 87] 和分布估计算法 (Estimation of Distribution Algorithm, EDA) [77, 96, 110] 等命名。
在此，对于熟悉或刚接触演化计算与神经计算的读者而言，或许值得注意的是，人工智能的奠基人之一，同时也是图灵机和图灵测试的发明者[124]，在1948年提出了一些关于这两种计算方法的模型和方法论（这些内容在20年后的1968年以报告形式发布）[36]。在这份《智能机器》（Intelligent Machinery）报告中[125]，提出了三个统称为“无组织机器”（Unorganized Machines）的计算模型。这些模型的提出正值作者设计世界上最早的计算机之一——自动计算引擎（Automatic Computing Engine）以及其试验版本正在物理建造阶段。特别地，提出的A型机器（A-type Machine）使人联想到由基本计算单元组成的布尔网络（Boolean Network）[86]。这些计算单元形成一个固定网络，每个单元能够执行一个具有两个输入和单输出的布尔函数，并具有功能完备性（如NAND门）[25]。与信号只能通过固定连接并保持不变的A型机器不同，B型机器（B-type Machines）的连接可以通过开关类型的连接进行修改，从而使信号发生改变。赋予B型机器这种可修改连接的主要概念目的是为了将初始“无组织机器”通过连接功能的变化转化为能够通过学习程序（包括演化搜索和文化搜索[124, 125]）执行计算任务的“有组织机器”。

在现代设定中，遗传算法（GA）被视作一种演化方法，它利用二进制编码的解表示以及相关的遗传算子进行应用[40, 66]。为了简单说明遗传算法的搜索如何准备，考虑非层次化解表法的问题。候选解是由基本集合组成的笛卡尔乘积中的点，这些集合构成了搜索空间。每个集合可以是离散的或连续的浮点类型，通过二进制字符串的一种编码方式来支持，并具有指定的长度以涵盖所有不同元素。这样的坐标表示确保了编码是可逆的（因为它是单一映射）。对用户来说，实际重要的是解决方案的参数化现在显示为一个长的连续二进制字符串，这类似于生物学中的染色体。遗传算子可以定义，例如交叉操作，它在二进制字符串的随机选择位置处交换一对候选解中相同长度的邻接块，从而形成一个新的候选解对。然而，由Holland[80, 81]提出并进一步发展的遗传算法理论要求通过遗传适配实现计算理论。我们今天所知的现代使用仅仅是该理论的一个应用解读。例如，解决方案或程序并不限于仅仅是函数或参数的优化器[42]。

以同样的方式，进化编程（EP）的现代成功或许暗示了它是一种为参数优化开发的方法。为了说明这种观点如何形成，可以关注[60]中关于训练人工智能代理以近乎人类专家水平参与二维零和棋盘游戏的结果。这种应用中关键在于设计一个系统去训练游戏代理。在这个案例中，参数化的解决方案表示是一种大型前馈神经网络，该网络用于棋盘评估，并作为浅层极小极大搜索的功能以执行游戏动作。训练的成功似乎依赖于进化编程优化神经网络（通过特定的变异算子对其连接权重进行微小扰动）的效果。然而，由Fogel[56]引入并由其他研究者[5, 23]调查的方法最初被构想为一种更广泛的开发人工智能的方法。早期实验主要采用有限状态机（Finite State Machines）作为解决方案表示（例如即使是用于游戏策略的情况下[23]），这些实验的作用在于：
(i) 探索智能的发展理念，特别是以符号预测形式抽象的行为智能，可以通过演化来实现。
(ii) 展示智能行为是可以适应的，即演化变化可以直接作用于个体层面。

>  这段话涉及**进化编程（EP, Evolutionary Programming）**的发展历史、应用场景以及人们对它的理解。可以这样理解：
>
> ------
>
> ### 1. **现代 EP 成功的范畴**
>
> - 现代 EP 的成功，**可能主要归因于它被用于参数优化**，比如深度神经网络的参数搜索。
> - 例如，在[60]的研究中，AI被训练来玩一个双人零和棋类游戏，**没有预设知识，仅靠训练就达到接近人类专家的水平**。
>
> ### 2. **实际应用关注点**
>
> - 实际应用中，关键在于**如何设计系统来训练游戏智能体**。
> - 在这个例子里，**参数化的解决方案**就是用一个大型前馈神经网络来对棋盘局面打分，然后用浅层极小极大算法（minimax）来做决策。
> - 训练的成功，看起来**依赖于 EP 优化神经网络参数的能力**，比如用小扰动（mutation）来调整网络连接权重。
>
> ### 3. **EP 的本源目标**
>
> - 但实际上，**Fogel 等人最初提出 EP 是为了更广义的 AI 目标**，不仅仅是参数优化。
> - 早期实验多用**有限状态机（FSM）**来作为解决方案的表示，包括棋类策略。
>   - (i) 验证智能（尤其是行为智能）是否可以进化产生，哪怕是以符号预测的形式。
>   - (ii) 展示智能行为可以被适应进化，即进化变化可以直接作用于个体层面。
>
> ------
>
> ## **总结性理解**
>
> - **现代 EP** 在实际中常被理解和应用为**参数优化工具**（如优化神经网络权重）。
> - **但最初的 EP** 是作为一种**进化人工智能的方法**提出的，不只是简单的参数搜索，还包括对智能行为本身的进化和适应。
> - 早期 EP 主要用**有限状态机**来表示智能体，关注行为智能能否通过进化得到，而不仅仅是调参数。
> - 这段话提醒我们：**不要把 EP 只看作参数优化工具，它的本质是进化智能和行为的产生与适应**。



在这三种方法中，演化策略（ES）的发展动机更倾向于实际问题求解的应用。早期研究包括迭代过程及其相关分析 [17, 112, 115]。在实验参数优化的初始设定中，候选解通过实体调整并通过实际测量进行性能评估。这些随机启发式方法旨在引入设计参数的小幅且可变的调整，然后根据性能进行评估，其中可能会受到噪声污染。这些调整值来自某种概率分布，从而形成了随机过程，在实际的物理工程优化环境中，多模态且显然受到噪声影响的情况下，这些方法的表现超越了基于梯度的数值优化方法 [17]。高性能计算机的问世及其更高的可访问性随后使得开发速度得以提高。通过采用适当的抽象，将解决方案的设计参数化以及后续的适应度函数公式化，演化过程便可在计算机上进行模拟。

> 这段话的核心内容是讲**进化策略（ES, Evolution Strategies）**的发展动机与早期应用，以及它与其他优化方法的区别。可以这样理解：
>
> ------
>
> ### 1. **ES 的主要动机是解决实际问题**
>
> - 在三种主流进化计算方法（通常指遗传算法GA、进化策略ES、进化编程EP）中，**ES 的发展更侧重于实用问题的求解**，特别是工程参数优化。
>
> ### 2. **早期 ES 的实验流程**
>
> - 最初，ES 被用于
>
>   实验参数优化
>
>   ，即：
>
>   - 候选解（设计参数）会被**物理地调整**，
>   - 然后通过**实际测量**来评估性能。
>
> - 这样的过程往往受实验噪声影响，测量结果可能有误差（噪声污染）。
>
> ### 3. **ES 的特点**
>
> - ES 采用**随机启发式方法**，即每次对设计参数做一些**小的、可变的随机调整**。
>
> - 这些调整值来自某种概率分布（比如正态分布），因此整个过程是**随机的（stochastic）**。
>
> - 这种方法在
>
>   多峰（有多个最优解）且明显有噪声的实际工程优化问题
>
>   中，
>
>   往往优于基于梯度的数值优化方法
>
>   。因为：
>
>   - 梯度法在噪声大、多峰的环境下容易陷入局部最优，难以全局寻优。
>
> ### 4. **技术进步对 ES 的推动**
>
> - 随着**高性能计算机的普及**，ES 的发展速度加快了。
> - 当可以用计算机模拟这些实验时，就能更快地测试各种方案，推动了方法本身和参数抽象、适应度函数等理论的发展。
>
> ------
>
> ## **简明总结**
>
> - **进化策略（ES）\**的初衷是解决实际参数优化问题，尤其是\**实验噪声大、多峰的工程问题**。
> - 它通过对参数做**小幅度的随机调整**，并用实际测试来评估效果，用这种“试错+筛选”来不断改进方案。
> - 这种随机优化方法，在实际工程中**优于传统梯度法**，特别适合复杂、多噪声场景。
> - 随着计算能力提升，这类方法可以在计算机上高效模拟和发展。

尽管演化计算在现实世界中取得了成功，并且由于这一成就引发了将演化算法（EAs）视为针对具有独特结构的挑战性问题的一系列具体解决方案的诱惑，我们的动机与早期许多人 [40, 58, 66] 的研究观点一致，即突出这个领域在问题解决的其他方面能为实践者提供的支持，而不仅仅是作为一种直接应用于具体问题的搜索方法。本文的核心主题是一个特别强大的原则：基于相互作用的代理之间的共同适应（coadaptation）来引导搜索的方法。这一原则所支撑的协同进化计算（Coevolutionary Computation）概念并不新颖 [61]，但在过去20年的发展中，它带来了更好的理解并开启了新应用的可能性。

在协同进化自然应用于驱动决策代理学习的场景中，我们将展示协同进化算法（CEAs）的新理论洞察和分析工具。这些工具可以帮助实践者识别协同进化搜索受到病理性问题影响时的表现，以及如何缓解这些影响。在协同进化作为高级搜索框架的更广泛设想中，我们将演示如何将共同适应的原则作为一种高层次问题解决的框架来进行思考。
对于实际操作人员来说，这不仅仅是将一种元启发式方法扩展为演化算法（EAs）中的一个特定类别。相反，这涉及到系统化地模仿人类专家在算法调优和问题求解设计时所采用的一些高层次过程，这些过程可以被表示为协同进化（coevolutionary）程序。从通过适当的参数化构建求解器的空间开始，这不仅能够允许距离计算，还能够进行与基本求解器相关联的变换操作的设计。之后，协同进化可以作用于这个高层次的搜索空间。在这一基础上，构造问题测试案例空间以制定适当的适应度评估方案的挑战也得以解决。这种针对EA种群与测试案例种群之间协同进化的构建方法，成为解决组合优化方法（Portfolio Optimization）中的泛化能力相关已知挑战的基础。

在接下来的章节中，我们将更详细地讨论演化算法（EAs）的具体内容。第1.2节将专注于构成通用EA设计的关键要素：包括使用种群、解的表示以及变化和选择的演化算子。我们将描述并特别强调演化计算领域中常用的一些术语。此外，还将介绍一些EA的例子，特别是那些与后续章节中介绍的协同进化算法（CEAs）具有类似特征的算法。之后，第1.3节将引入EA的参数控制的概念，并描述一些能够优化与EA操作相关参数以改善其性能的先进方法。

### 1.2 演化算法的框架
演化算法（EAs）属于灵感来源于自然进化的一类基于种群的随机搜索算法。该领域采用了一种通用的抽象方法，用来将算法搜索与自然搜索进行关联，这种方法将两者都置于一个“生成-测试”的框架中。不论是计算性的还是自然的，这个过程都在一个状态空间上运行，状态空间的组成部分代表一个有限的候选解种群。我们提供了三种视角来帮助理解EAs的设计以及其设计方面如何与自然进化的重要特征相对应并受到影响。
初始化 变异 评估 选择 停止 是 否 图 1.1 通用进化算法的流程图

图 1.1 的流程图展示了一个非正式、系统化的视角，其中，通用进化算法（EA）与简化的新达尔文主义自然进化模型均由三个主要的、相互依赖的组成部分构成，这些部分在一个循环中相互作用。从初始化种群中的父候选解开始，候选解随后依次受到变异和选择两种进化算子的重复应用，直到循环终止。变异算子负责从已有的候选解中生成新的候选解。例如，从父候选解中生成一个子候选解，但其部分继承的解参数会受到小幅扰动改变其值，这类似于生物无性繁殖过程中的基因突变。选择算子通过评估过程获取候选解的适应度，并选择当前种群中的部分候选解以进入下一代种群。这两个组成部分在系统视角中被单独列出以便于说明，但在包含复杂选择过程的模型中，这二者是更加紧密交互的。它们可以反映基因型或表现型水平上的自然选择模型 [101]。例如，频率比例选择涉及根据候选解适应度值在种群总适应度中的比例来选择特定个体进行复制。这种选择方法被应用于经典遗传算法（GA），类似于生物中基因型水平选择压力作用于同一物种种群的生物学类比（例如染色体特定位置上的基因备选形式的频率） [81]。其他进化算法（EA）方法，例如进化策略（EP）家族中的策略，则使用局部竞争的模型，在表现型水平对种群的子集进行选择 [57, 62]。

算法 1.1 通用进化算法
输入：$Y$ 候选解的种群，$\mathrm{s}_{\mathrm{term}}$ 终止准则选择  
输出：$X$ 进化后的候选解种群  

1: $\textbf{程序 EA}$($Y, \mathrm{s}_{\mathrm{term}}$)  
2: $t := 0$ $\triangledown$ 初始化时间戳  
3: $\mathrm{b}_{\mathrm{term}} := \mathrm{true}$ $\triangledown$ 初始化循环条件  
4: $X := \mathrm{initialize}(Y)$ $\triangledown$ 在$X$中初始化父代种群  
5: $\textbf{当}$ $\mathrm{b}_{\mathrm{term}}$ $\textbf{为真时，执行如下操作}$  
6: $X := \mathrm{variation}(X)$ $\triangledown$ 在$X$上应用变异操作  
7: $\mathrm{evaluation}(X)$ $\triangledown$ 对$X$进行适应度评估  
8: $X := \mathrm{selection}(X)$ $\triangledown$ 在$X$上应用选择操作  
9: $t := t + 1$  
10: $\mathrm{b}_{\mathrm{term}} := \mathrm{termination}(X, t, \mathrm{s}_{\mathrm{term}})$ $\triangledown$ 检查终止条件  
11: $\textbf{结束循环}$  
12: $\textbf{返回}$ $X$  
13: $\textbf{结束程序} $ 

从算法的角度来看，这一通用框架强调了实施过程中的内在设计灵活性。这点可以通过算法1.1中一般性过程EA的数据结构设计加以说明。主要的结构化数据$X = \big(({\boldsymbol x}, f)_i : i = 1, 2, 3, \ldots, n\big)$包含了每个候选解的参数值 ${\boldsymbol x}$ 和适应度$f$的信息，参数值${\boldsymbol x}$共同描述了规模为$n$的种群构成。换句话说，$\big(({\boldsymbol x}, f)_i : i = 1, 2, 3, \ldots, n\big)$ 构成了种群$X$的整体配置。

两种主要的数据变换由两个过程表示：变异（$\mathrm{variation}$）和选择（$\mathrm{selection}$），这两个过程返回经过处理的数据，且明确体现它们在整个种群$X$上操作。经过操作后，$X$的具体实例变为种群配置集合$\{\boldsymbol X_1, \boldsymbol X_2, \boldsymbol X_3, \ldots\} = \boldsymbol {\mathcal X}$中的一个特定实例。

一个例外是初始化过程。它仅在程序开始时调用，也可以在EA之外调用，通过参数输入$Y$并传递某个值给$X \in \boldsymbol {\mathcal X}$。尽管变异和选择过程限制了输入和输出只能是类型为$\boldsymbol {\mathcal X}$的数据，其内部操作可以根据具体设计要求复杂到任何程度。

其他过程可以分为两个类别。第一类仅改变$X$中的特定数据。例如，评估过程负责更新每个候选解的适应度，该数据可以通过地址方式访问（如 $\boldsymbol X[i].f$）。事实上，评估过程甚至可以在选择过程中被调用。

第二类是那些操作局部变量以控制循环的过程。局部变量“时间戳”$t$上的基本算数操作跟踪迭代（或代数）计数。而二元操作“$t + 1$”采用中缀表示法进行书写。终止过程检查循环的终止条件。当条件成立时，它返回$\mathrm{false}$；否则返回$\mathrm{true}$。通过改变局部布尔标志$\mathrm{b}_{\mathrm{term}}$的值，循环便可以终止。注意，终止过程接收三个输入：$X$和$t$表示相关信息，而第三个输入$\mathrm{s}_{\mathrm{term}}$表示如何利用信息来评估循环的终止条件。
最终，我们可以将作用于种群配置空间${\mathcal X}$的抽象演化过程描述为离散时间动力系统 $F : \boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$ 。研究[127]将遗传算法(GA)数学化地构建为一个离散动力系统，并明确地进行演化算子的几何建模。另一研究[85]将基于种群个体数为2的演化算法（EA）应用于一维问题的搜索行为建模为一个离散时间动力系统，该系统生成期望种群状态值的轨迹。在此，我们仅详细介绍基本的理论框架，集中构建用于描述搜索行为的主要结构，将其表述为 $\boldsymbol{\mathcal{X}}$ 空间中的轨迹。

这种抽象的演化过程可以通过以下差分方程来表达：

$$
\boldsymbol{X}^{t+1} = \boldsymbol{\mathcal{F}} \big(\boldsymbol{X}^{t}\big), \quad t = 0, 1, 2, \ldots,
$$

$$
\boldsymbol{\mathcal{F}} = \boldsymbol{\mathcal{S}} \circ \boldsymbol{\mathcal{V}},
$$

其中，函数 $\boldsymbol{\mathcal{S}} : \boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$ 和 $\boldsymbol{\mathcal{V}} : \boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$ 分别表示选择算子和变异算子。从本质上讲，这个过程涉及种群 $\boldsymbol{X}$ 的组成成分的改变。通过这种方式，演化过程可以通过其在 $\boldsymbol{\mathcal{X}}$ 空间中的迭代轨迹 $\boldsymbol{X}^0, \boldsymbol{X}^1, \boldsymbol{X}^2, \ldots$ 来观察其搜索行为。这种行为可以通过描述轨迹的不同阶段来明确。例如，定义固定点 $\boldsymbol{X}^* 为\boldsymbol{X}^*= \boldsymbol{\mathcal{F}}\big(\boldsymbol{X}^*\big)$。如果轨迹落入某个 $\boldsymbol{X}^*$，则表明该搜索朝向某个局部最优进行。需要注意的是，在选择算子中隐含地融入了适应度评估。

针对个体候选物 $i = 1, 2, 3, \ldots, n$ ，其解参数由 $\boldsymbol{x}_i = \boldsymbol{X}[i]$ 表示，其中 $\boldsymbol{x} \in \boldsymbol{\mathcal{R}}$，$\boldsymbol{\mathcal{R}}$ 是解空间的适当子集（例如，在约束连续优化问题中 $\boldsymbol{\mathcal{R}} \in \mathbb{R}^D$）。这涉及计算目标函数 $f(\boldsymbol{x}_i)$，其中 $f : \boldsymbol{\mathcal{R}} \rightarrow \mathbb{R}_{\geq 0}$。由于选择算子作用于整个种群 $\boldsymbol{X}$，该算子内部包含两个过程。第一个过程 $\boldsymbol{\mathcal{S}}_{\text{fe}} : \boldsymbol{\mathcal{X}} \rightarrow \mathbb{R}^n$ 负责对所有 $n$ 个体进行适应度评估；第二个过程 $\boldsymbol{\mathcal{S}}_{\text{cs}} : \mathbb{R}^n \rightarrow \boldsymbol{\mathcal{X}}$ 使用这些适应度值指导下一代种群的候选选择。通过两个过程的复合 $\boldsymbol{\mathcal{S}}_{\text{cs}} \circ \boldsymbol{\mathcal{S}}_{\text{fe}} : \boldsymbol{\mathcal{X}} \rightarrow \mathbb{R}^n \rightarrow \boldsymbol{\mathcal{X}}$ 可以得到选择算子 $\boldsymbol{\mathcal{S}} = \boldsymbol{\mathcal{S}}_{\text{cs}} \circ \boldsymbol{\mathcal{S}}_{\text{fe}}$，其类型为 $\boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$。

然而，我们的主要展示重点在于揭示即使是这样的抽象模型如何能够呈现演化算法设计的重要方面。注意，我们之前的介绍指出演化过程从种群候选个体的初始化后开始，由变异算子执行。这是一种任意选择，也可以首先实施选择算子，然后进行变异算子的执行。两者之间在质上没有区别，其主要差异在种群的初始化方式。这一论点可以通过形式化表达，并借助仅具有 $\boldsymbol{\mathcal{X}} \rightarrow \boldsymbol{\mathcal{X}}$ 类型的函数的性质，以及函数复合的结合性来证明。种群在某个任意迭代步的状态是重复应用 $\boldsymbol{\mathcal{G}}$ 的结果，通过归纳法可以证明：

$$
\boldsymbol{X}^{m+1} = \boldsymbol{\mathcal{F}} \big( \boldsymbol{\mathcal{F}}^{m} (\boldsymbol{X}^0) \big) = \boldsymbol{\mathcal{F}} \circ \boldsymbol{\mathcal{F}}^{m} (\boldsymbol{X}^0),
$$
${\boldsymbol X}^{m + 1} = {\mathcal F }\big({\mathcal F }^{m} \big({\boldsymbol X}^{0}\big)\big) = {\mathcal F } \circ {\mathcal F }^{m} \big({\boldsymbol X}^{0}\big)$. 由于${\mathcal F } = {\mathcal S } \circ {\mathcal V}$，我们得到：
$$
{\mathcal F } \circ \cdots \circ {\mathcal F } \big({\boldsymbol X}^{0}\big) = {\mathcal S } \circ {\mathcal V} \circ \cdots \circ {\mathcal S } \circ {\mathcal V} \big({\boldsymbol X}^{0}\big)
$$

$$
= {\mathcal S } \circ {\mathcal V} \circ \cdots \circ {\mathcal S } \big({\mathcal V} \big({\boldsymbol X}^{0}\big)\big)
$$

$$
= {\mathcal S } \circ {\mathcal V} \circ {\mathcal S } \circ \cdots \circ {\mathcal V} \circ {\mathcal S } \big({\mathcal V} \big({\boldsymbol X}^{0}\big)\big) 
$$

$$
= {\mathcal S } \circ {\mathcal G} \circ \cdots \circ {\mathcal G} \big({\mathcal V} \big({\boldsymbol X}^{0}\big)\big),
$$

其中${\mathcal G} = {\mathcal V} \circ {\mathcal S }$。如果采用${\mathcal F }$作为演化过程的模型，那么就必须完全初始化种群（包括父代和子代候选解）以便选择操作能够进行。我们所采用的方法是将${\boldsymbol X}^{0}$部分初始化为父代候选解，因为${\mathcal V}$作用于父代以生成子代，从而完成种群初始化。

最后可以注意到，在文献[127]中针对抽象遗传算法（GA）所正式化的例子中，即使一个简单的种群搜索行为在函数优化中趋向于全局最优的描述也是微妙的。这是由于遗传算法映射${\mathcal F } = {\mathcal S } \circ {\mathcal V}$的构造造成的。一方面，除了与位于吸引域内部的全局最优相关联的那个稳定的固定点外，${\mathcal S }$有许多其他不稳定的固定点。另一方面，${\mathcal V}$的唯一固定点${\boldsymbol X}^{v}$对应于一个所有候选解均被平均表示的种群构型。该固定点的吸引域为${\boldsymbol {\mathcal X} \setminus {\boldsymbol X}^{v}}$。当将两个算子结合起来时，${\mathcal S }$的聚焦效应和${\mathcal V}$在${\boldsymbol {\mathcal X}}$中的散射效应，会使得遗传算法映射${\mathcal S } \circ {\mathcal V}$呈现出类似于“间断平衡”的搜索行为。具体表现为，当种群由于变异算子${\mathcal V}$的作用从一个平衡构型移向另一个不稳定的固定点时，搜索会经历一段过程。而最终，轨迹会掉入与全局最优对应的固定点，并在其附近循环。

> ## 1. **GA 的行为不是直来直去的**
>
> - 即使是最简单的GA，在寻优过程中，种群的行为也非常微妙和复杂，不是简单地“直接奔向”最优解。
>
> ## 2. **GA 的“映射”与“固定点”**
>
> - GA 的优化过程可以看作是一个由两个算子（S 与 V）组成的映射：
>   - **S**：有聚焦（收敛）作用，比如选择算子。
>   - **V**：有扩散（多样性）作用，比如变异算子。
>   - 二者组合形成一个“GA映射”。
> - 在这个映射下，有很多**不稳定的固定点**（fixed points），但只有一个与全局最优解有关的固定点是稳定的，且位于其吸引域的内部。
>
> ## 3. **唯一的特殊固定点**
>
> - V算子的唯一固定点是一个特殊的种群状态：所有候选解被完全平均地表示（即没有选择压力，大家平等）。
> - 这个点的吸引域是除了X^v以外的所有种群配置。
>
> ## 4. **搜索行为像“间断平衡”**
>
> - 由于S和V的交互，GA的搜索行为表现为**“间断平衡”（punctuated-equilibria-like）**：
>   - 种群会在一段时间内停留在某些不稳定的均衡状态（即局部最优附近），
>   - 然后因为变异（V的扩散作用）突然跳到另一个均衡状态。
>   - 这种来回跳跃，最终会让种群落到全局最优的固定点附近，并在其附近“循环”或震荡。
>
> ## 5. **整体理解**
>
> - GA不是线性收敛到最优，而是经历多个“停留—跳跃—再停留”的阶段，最后才稳定在全局最优附近。
>
> ------
>
> ## **一句话总结**
>
> > **遗传算法的搜索过程不是直线式前进，而是像间歇跳跃的爬山：种群会在多个不稳定的中间状态间游走，最终才会落到全局最优的区域并围绕它波动。**



**1.2.1 关于种群的使用**

一种区分典型演化算法（EAs）与其他启发式家族方法的特性（在考虑其经典形式而不包含增补或与其他启发式家族的混合时）是种群候选解的使用。**遗传算法（GA）的一个主要定义特征是交叉算子的使用**，根据其定义和构造需要一个种群的候选解。在演化算法中，使用一个单一的泛交配型种群，其中候选解为复制进行竞争是常见的，但这并非演化过程作用的唯一方式。

并行演化算法（Parallel EAs）也被提出，其由多个种群组成，进行一种更复杂的、松散耦合的过程，类似于自然界中相邻岛屿上的自然进化。在简单的并行演化算法设计中，每个种群分布在自己的“岛屿”上并大多独立演化，除了特定的且通常是短时间的种群间候选解交换。这种迁移过程可以周期性安排，也可以以其他更复杂的方式进行。
这些基于岛屿模型的进化算法(Island-based EAs)在并行和顺序计算环境中均可实现。在并行环境中，操作被分配到特定计算核心上的单个岛屿（种群），可以直接论证利用增加的计算资源在进化过程中的实际加速以获得解决方案。然而，在顺序环境中，每个岛屿内的进化过程必须依次在单一计算设备上运行，此时关于是否能在成功搜索上得到加速的论证会更加微妙且复杂。由于处理更多候选项的需求，会增加计算成本的开销。当这些并行进化算法在顺序环境中实现时，若比传统进化算法明显表现出更好的搜索性能，这可能意味着使用更大的候选项池具有某种内在特性。这一论点同样可以应用于进化算法中传统的单一随机交配种群（panmictic population）设置。特别是，可以提出这样的问题：进化算法与一种具有随机性及并行搜索的增强型爬山算法（例如，文献[114]中描述的随机光束搜索）之间是否存在显著差异？事实上，理解为何种群的使用在进化算法的成功中具有内在意义，关键在于进化搜索期间种群所具备的特定多样性。

一种非正式的方式可以展示这一问题：从简单的对立案例入手，即种群已经完全专注于某一个特定的候选项，其余种群中的候选项仅仅是这个候选项的复制品。最糟糕的情况是，该候选项对应一个局部最优解，且无法逃逸，因为当前进化算法设计的变异和选择算子协调地作用，导致只有该候选项的复制品能够在后续代中被保留下来。此时，进化算法被认为发生了“过早收敛”(Premature Convergence)。还可以注意到，其他种群配置结合特定进化算法设计和问题结构，可能也会导致此类搜索行为。例如，种群中的候选项虽然不同，但都对应于局部最优解吸引域的某一区域内的点。**由于问题结构的限制，交叉算子的效果被抵消，即任意两个相近候选项之间的交叉只会生成仍位于这个吸引域中的新候选项。突变也不足以跳出该吸引域，因为只有极少的概率会产生域外点，并且仅当该点具有更高的适应度值时才可能被选中。**事实上，随着种群规模的不断增大，进化优化器的性能可能会受到影响，尤其是在涉及特定问题结构的情况下。

尽管在特定进化算法配置和问题设置下，需要借助文献[31]中的技术性证明来论证，但这些理论结果也具有更广泛的意义。非正式地说，增加种群规模可能会加剧种群保持在某些局部最优解吸引域中的选择压力，这是因为这些吸引域通常伴随着较高的适应度值。可以通过变更变异算子来缓解这一问题，但需要特别注意，逃离局部最优后，变异算子仍需能够在种群找寻全局最优吸引域时发挥作用而不妨碍搜索。
因此，在演化算法（EAs）中使用种群来解决复杂的现实世界问题的内在效用 [134]，与在演化搜索的正确时间或阶段保持适当的多样性息息相关。种群和多样性使用的好处已经在该领域被证明 [16, 27, 38, 41, 68, 105, 111, 117, 126]，在任何关于演化算法的讨论中都需要将这些因素统筹考虑。根据当前对演化算法种群多样性的理论理解 [47]，我们列举了这方面的四个主要优势。

首先，演化算法是以全局探索为设计目标，其中种群用于探索搜索空间的不同区域。在某些情况下，问题结构结合演化算子可能引入额外的挑战，例如，对于具有强多峰适应度景观的问题（详见第1.4节），通过一个多样化的种群提供一种内在机制来帮助从局部最优中逃离，这一点尤为重要。

第二，一些演化算法主要设计为使用交叉类型的变异算子，而突变类型算子则在生成新的后代候选解时扮演次要角色。尤其是，当交叉操作作用于高度相似的父代候选解时，其效果类似于低强度和低频率的突变。在这种情况下，生成的后代会非常相似。因此，多样化的种群可能有助于交叉操作生成后代候选解，从而实现有效的全局搜索。

第三，某些现实世界问题的族群，例如以多目标优化（Multi-objective Optimization）形式表达的问题，要求解决方案同时处理多个甚至可能相互冲突的目标 [134]。在这些问题中，决策的相关性隐含其中，即代理（人类或人工智能）需要从求解器生成的一组解决方案中进行选择。在这种情况下，生成解决方案的种群是一种必要性。因此，演化算法必须设计为维护一个多样化的候选解决方案种群，以反映满足这些目标所需的权衡。

第四，在某些现实世界问题解决中，鲁棒性问题至关重要，其中特定问题的某些属性可能会随着时间变化，即这些问题不是静态的而是动态的。这可能是实验评估解决方案适应度时存在噪声，或者问题参数的变化所导致。在这种情况下，演化算法需要生成鲁棒的解决方案，而不是那些适应度仅与当前实验评估设置或问题公式相关联的最优解。如果可以生成一个多样化的种群，则更容易（或更快）实现这样的目标，该种群可以发现多个最优区域，或者能够跟踪由于适应度评估变化而造成的最优值移动。

#### 1.2.2 
#### 解决方案的表示
演化算法（EAs）通用设计框架的一个结果，以及它们随后在不同问题领域的广泛应用，是可供使用的解决方案表示形式具有多样性。对这些表示方法的任何讨论和阐述都与它们相关联的变异算子密切相关，我们将在下一部分详细说明。在本节中，我们介绍两种与EA结合使用的常见解决方案表示形式，并简要讨论某一特定表示形式如何应用于各种问题设置。然而，为了更好地理解解决方案表示形式与编码的附加使用如何影响EAs的搜索行为，我们首先介绍一种生物学上的对应关系及其关于表现型（phenotype）和基因型（genotype）的概念，以展开讨论。

不同于早期演化策略（ES）研究中的实验参数优化设置，这些研究通常直接在接近实际待优化对象的模型上开展工作【10】，大多数EA研究在这些问题设置中使用的是模拟演化优化。一个抽象化过程将已被执行，以对这些对象进行建模，这样可以验证它们的行为或输入-输出响应，从而使其可以被使用。参数与模型及其响应相关联，属于被考虑优化的模型响应的表现型。在这种情况下，所考虑的参数空间构成了表现型空间（phenotype space）。基因型的本质起源于计算机上的这些模拟演化过程。在这一背景下，模型需要以某种计算（表示）形式进行表达。通常会使用特定的数学对象，针对这些对象可以构建和应用变换算子。基因型指的是这些计算模型的具体实例，每一个对应于所考虑的候选解决方案。因此，基因型空间（genotype space）与搜索空间对应，而变异算子是能够在搜索过程中将种群成员从一个基因型变换到另一个基因型的变换算子【8, 9】。

显然，需在基因型与表现型之间建立一种映射或编码函数，而这一点通常由表示模型的构造所决定。然而，这种基因型与表现型的映射在使用EA解决问题时引发了各种问题。在大多数应用中，EA无法直接访问表现型空间，而是操作于表现型空间之下存在的基因型空间。可以参考文献【59】中的图解以获取直观视图。这种映射引发的复杂性不仅影响演化搜索性能，同时也使分析变得更加具有挑战性。这些问题所引发的挑战也许和问题本身的性质及用于解决问题的EA算法一样多，同时也和最初激励其构造的理念之间的差异密切相关。特别是，使用原始表示形式（即自然表示）的重视与提倡并不像人们初期可能意识到的那样直截了当。非正式地说，为了实现有效搜索而使用自然表示的本质可以被理解为使EA直接在表现型（参数）空间中操作。

举一个例子，在连续优化问题中，使用实值的演化优化器（例如ES与EP）解决已知数学构建的基准问题【75, 76】时，基因型空间与表现型空间间实际上存在一对一（双射）的映射。如果仅考虑简单的情况，即仅使用变异算子在基因型空间中将一个父代候选解变换为一个子代候选解，那么此类变异算子在基因型空间中所诱导的邻域结构（即可达邻域的点）会一致地被翻译到表现型空间。在基因型空间中观察到的由演化过程产生的轨迹，与在表现型空间中演化的轨迹是一致的。
在其他未使用自然表示的情况下，而是涉及某些编码方案（例如，在遗传算法（GA）的情况下），复杂情况则会出现，从而实际上基因型到表现型的映射是多对一的关系$[59]$。尽管如此，需要注意的重要一点是关于演化过程的可预测性，无论是从其搜索行为的分析还是控制角度来看。固有问题结构，例如凸性（例如单峰连续优化问题），可以为使用编码方案的演化算法（EA）呈现适用场景$[113]$。对于完全离散优化问题，寻求自然表示以及使用能够有效搜索的编码方案显然是极具挑战性的。除了这些问题的组合性质之外，还需处理表示问题。例如，经典的旅行商问题（TSP）涉及在给定的加权图上搜索总成本（例如总距离）最低的哈密顿环路。非正式而言，解可以定义为一次穿过图中每个顶点的路径或巡游，其中起点和终点是同一个顶点。为TSP问题指定字符串编码方案虽然很直接，但还需要额外一步来验证巡游的有效性。如果要为一个大型图家族设计能够固有地编码有效巡游的方案几乎是不可能的。通常情况下，修复操作符需与变异操作符结合设计，以定义有效巡游的邻域结构$[26]$。这与连续优化问题的情况不同，其中参数和搜索空间可能只是标准欧几里德向量空间。然而，人们仍然可以指定一种自然表示与编码方案所需的条件。相关问题特定知识的整合可以被视为通过指定距离度量来为空间制定合适的度量的一个实践过程，允许在表现型空间和基因型空间中一致地转换邻域结构$[26, 49, 50]$。

关于字符串编码的问题，理论上已有论证$[63]$表明，使用任何基数为$k = |A|$的字母表$A$指定编码方案（例如在$k$-元字符串表示中取基值$k \geq 2$）并没有内在优势。搜索空间是通过特定长度为$l$的$k$-元字符串表示形成的，用元组$(a_i \in A : 1 \leq i \leq l)$给出，包含定义搜索空间$A^l$中每个点（$k$-元字符串的唯一实例）邻域结构的变异操作符。定义候选生成概率的概率质量函数（“骰子”）可以在此搜索空间上进行公式化。至关重要的是，无论使用哪一个$k$值，只要使用$k$-元字符串表示，总是可以专门设计变异操作符以保留这些概率。
在建立了对解表示和编码作为一种接口的更全面理解后，我们可以观察到演化算法（EA）的搜索行为以及其底层操作过程接下来，我们将重点介绍那些在解决实际问题中常用的表示方法。我们特别关注后续章节中将会讨论的表示方法，以便本节也能起到简要介绍的作用。首先，我们讨论一种特定类型的实值表示，这种表示构成了一类广泛的连接主义系统。其中一个例子是人工神经网络（Artificial Neural Networks, ANNs），它们本身已经形成了人工智能方法论的一个主要分支。然而，很快就可以发现，演化过程不仅仅是传统训练方法的替代方案，而是一种能够解决传统方法某些弱点的方法。[132]。

人工神经网络由多种节点网络组成，每个节点都可以被看作一个神经处理单元（即神经元）。一个典型的神经元$y(\boldsymbol{x},\boldsymbol{w})$的输入是有限集合的实数$\{x_i\}$，存储在$\boldsymbol{x}$中，它们首先被线性组合。这些实数的加权和由存储在权重集合$\boldsymbol{w}$中的实值系数或参数控制。加权和$a$随后会被传递给一个非线性传输（激活）函数$h$，以输出一个实值$\{y\}$。具体表示为：
$$y(\boldsymbol{x}, \boldsymbol{w}) = h\big(a(\boldsymbol{x})\big), \ a(\boldsymbol{x}) = \sum_{i} w_{i} x_{i} + w_{0},$$
其中，术语$w_0$表示一个独立的偏置项。

为解决足够复杂的学习问题，通常使用一种前馈（Feedforward）架构的标准人工神经网络，其中神经元被组织在多个层中，层与层之间按照特定方式连接。特别地，该网络是一个特定的有向无环图。无环特性来源于以下约束：同一层的神经元之间没有连接，以及后续层的神经元不会反馈至较早层的神经元。然而，如果包括循环连接，则会形成循环神经网络（Recurrent Neural Networks, RNNs）。

我们将描述一个典型的前馈神经网络，这种网络包含一个单隐藏层和一个输出层，其结构通常按照文献中的描述，例如[18]。模型的输入为集合$\{x_i : i = 1, \ldots, I\}$，输出为集合$\{y_k : k = 1, \ldots, K\}$，其中隐藏层包含$J$个神经元。这种构建方式非常简单，只需要对索引做到细致管理即可。我们需要完成两次计算：一次是用于计算隐藏层神经元的输出，另一次是计算输出层神经元的输出。

某些图解可能会展示输入节点$\{x_i : i = 1, \ldots, I\}$，不过，这些节点只是将实数值传递给人工神经网络（它们充当恒等函数），并不进行任何处理。设第$j$个隐藏层神经元的输出为$z_j$，隐藏层$J$个神经元的输出（索引范围$j = 1, \ldots, J$）可以表示为：
$$z_j = h\big(a(\boldsymbol{x})\big) = h \left( \sum_{i=1}^{I} w_{ji}^{(1)} x_{i} + w_{j0}^{(1)} \right).$$

对于输出层中$k = 1, \ldots, K$的神经元，其表现如下：
**公式部分：**

$y_k = h\big(a(\boldsymbol{z})\big) = h \left( \sum_{j = 1}^{J} w_{kj}^{(2)} z_{j} + w_{k0}^{(2)} \right).$

**段落内容翻译：**

上标索引$(l)$被明确用于表示权重属于与第一层且唯一的隐藏层$(1)$以及输出层$(2)$相关联的神经元。需要特别注意，这种特定人工神经网络（ANN）的关键特性在于其复合结构，因为各层的输出会成为后续层的输入。在此情况下，我们获得了一种将 $\{x_i\}$ 映射到 $\{z_j\}$ 再映射到 $\{y_k\}$ 的函数的组合。然而，当代的人工神经网络（ANNs）如深度神经网络（DNNs）[1]则采用深层架构，具备多层结构以及多样的处理能力，例如卷积运算捕捉空间结构（如图像）和能够处理数据属性的序列依赖性（如时间序列和文本数据）。这些DNNs被广泛应用于不同领域的问题解决，例如在计算机视觉、语音识别、自然语言处理等领域拥有重要应用[70]。

两个神经网络能力的简单示例可通过回归和分类任务体现出来。在一个简单的回归任务中，目标是利用输入变量向量来逼近连续的因变量和目标变量之间的关系。而在二元分类任务中，则通过建立决策边界将由输入变量向量表示的观测样本归入两个离散类别或标签之一。这类前馈神经网络在问题解决中的强大之处在于，它们作为任何连续函数在紧致域（例如单位超立方体 $[0,1]^n$）上的任意精度逼近器的能力已得到充分论证，且其架构仅需满足少量限制条件（例如参见[37, 82, 104, 106]）。

当神经网络在宽度（固定数量的隐藏层并在其中包含任意数量的神经元）或深度（每个隐藏层固定数量的神经元但包含任意数量的层）上得到扩展时，针对此类架构制定理论保证会为研究提供动力，以解决有效训练方法的挑战。这形成了神经网络在问题解决中的框架的第二方面，即其机器学习能力。一种简单的说明是考虑监督学习的场景，即通过迭代过程，根据一系列带标签的训练样本来引导神经网络内部结构的改变。这种方式使得神经网络通过从原始数据中提取模式被认为具备解决问题所需的知识[70]。值得注意的是，这种通过训练实现的学习能力也可以通过适应来实现。

演化算法（EAs）被开发用于优化ANNs的参数和架构。针对ANNs的参数优化，可以直接使用基于实数型变异算子的EAs。然而，由于ANNs的架构呈现离散结构，因此可能需要某种形式的编码。鉴于设计这些DNNs的复杂性，EAs已经被开发出来用于自动构建这些DNNs，并对其架构和参数进行演化优化[136, 137]。
接下来介绍的一种解表示形式是树结构的形式。树是一种连通的无环图，其中任意两个节点之间仅通过一条边相连。树通常以顶部的单一节点作为根节点（root）呈现，该节点通过单一路径连接到其他节点子集。在演化计算领域，遗传编程（Genetic Programming，GP）是一类算法，其进化的计算机程序以树结构表示。进化计算机程序的概念可追溯至经典的遗传算法（Genetic Algorithms，GA）的研究工作[80]，随后被具体化并应用为GP[91]。GP使用的语法树表示法提供了直接表达计算机程序的方式，这些程序以形式语言中的文本表示，并包含语法结构。一个简单的GP树由连接的节点组成，这些节点用于表示一个原始集合（primitive set）。该原始集合是一个简单的程序，包括叶节点（leaf nodes）表示变量和常数，而内部节点（包括根节点）表示可执行的简单函数指令（例如二元关系）。结构设计的特点是，树中的当前节点指令的参数由其直接连接到的子节点表示。

一个简单的GP树示例是通过数学表达式 $min(x*y, 2*x+y)$ 计算两个数的最小值的程序。在此示例中，指令 $\mathrm{min}$ 由根节点表示。由于 $\mathrm{min}$ 的参数不是简单数字，而是由数学表达式 $x*y$ 和 $2*x+y$ 构成，这些表达式本身又形成子树。这种树表示的一个主要优点是其具有递归性质。注意，原始表达式 $min(x*y, 2*x+y)$ 在标准数学书写中通常使用中缀（加法和乘法运算符）与前缀（最小值运算符）的组合表示。而在LISP中常用的一种仅前缀符号表达（符号表达式，s-expression），则使GP的语法树结构更加清晰[95]。例如，可以写为 $(\mathrm{min} \ (* \ x \ x) \ (+ \ (* \ 2 \ x) \ y))$。相比之下，使用s-expression时，树结构浅的分支结构对读者而言更加清晰，例如右分支 $(+ \ (* \ 2 \ x) \ y)$ 也包含一个子树。

这种树结构可以进一步扩展为更高级的GP树，以表示更复杂的程序，类似于人类程序员所编写的程序。标准编程中通常会重用特定的指令序列，这些指令可以创建为模板，随后以组件或子程序的形式被使用。在更大的程序中可以通过不同的实例化形式使用这些子程序，以在参数中采用不同的输入值。其中一种更流行的扩展形式是自动定义函数（Automatically Defined Functions，ADF）[92]。其他形式的子程序表示也得到了发展，例如自动定义迭代（Automatically Defined Iterations）、自动定义循环（Automatically Defined Loops）、自动定义递归（Automatically Defined Recursions）等[93]。这些子程序在使用时形成高级GP树的分支，并被组织在一个特殊的根节点下。这些定义的子程序既可以执行任务，也可以生成结果。

需要注意的是，还有其他形式的GP使用不同类型的有向无环图，例如笛卡尔GP（Cartesian GP，CGP）[128]和基于度量的GP（Metric-Based GP，MBGP）[49, 50]。这些带有特定编码的解表示最初是为了数字电路（CGP）和布尔函数（MBGP）的进化而开发和应用的。鉴于GP树能够表示的计算机程序范围非常广泛，它被应用于不同领域的各种问题解决中并不令人惊讶。然而，GP树与人工神经网络（ANNs）中的图之间的主要区别是符号模型与连接主义模型的差别。例如，GP执行符号回归（symbolic regression），而进化ANNs则执行参数回归[91]。GP中的符号方法是通过演化过程构建一个通用函数及其系数，而不是像进化固定架构的ANNs那样寻找预定义函数的系数。同样，GP使用的树结构表示非常适合于符号分类（symbolic classification）任务[89]以及其他如决策制定任务，例如运筹学（Operations Research）中路由问题的策略制定[129]。
### 1.2.3 变异算子

在前一节中，我们讨论了在简化假设的基础上，解的参数化表示与生物染色体类比。它们构成了解决方案空间的坐标系基础，使得描述复杂且独特个体的信息可以以一种特定的方式进行结构化，从而彼此定位为解空间中的唯一点。之后，可以定义一种变异算子，该算子描述了这些点的邻域结构，并据此构建搜索空间。在本节中，我们将讨论变异算子的更实际方面，也就是将一个候选解转换为另一个候选解的机制。

由于任何变异算子的设计选择都与所选的解表示密切相关，我们将重点介绍一些针对实值和离散表示的常用例子，特别是我们之前提到的人工神经网络（ANNs）和基因程序树（GP trees）。为了进行概念性介绍，我们首先描述两种用于经典遗传算法（GA）的二进制字符串表示的变异算子形式，它们分别是**突变**和**重组（或交叉）算子** \[[40, 66]\]。

我们从简单突变算子的一个示例开始。设一个固定长度的二进制字符串，长度为6位，由序列 $(b_5,\ldots,b_0)$ 表示，其中 $b_i \in \{0,1\}$。注意，这里的地址索引 $i$ 是反向的，使得 $b_5$ 为最重要的位，而 $b_0$ 为最不重要的位。在此情况下，可以实现简单的**均匀突变**作为一种**位翻转突变算子**，其中每一个位 $b_i$ 的当前值有相同的概率被改变。在经典遗传算法中，突变被认为是一种次要变异算子，并且位翻转发生的概率应该非常低。

在这个例子中，对每个位 $b_i$ 从一个均匀分布中抽取一个值，例如 $r \sim U(0,1)$，然后如果 $r < p_m$ 则当前值被改变。这里，$p_m \in [0,1]$ 是指定突变概率的参数，因为位翻转发生的概率为 $\mathbb{P}(r < p_m)$。
交叉算子是经典遗传算法（GA）中的主要变异算子之一 $[40, 66]$。与突变算子类似，交叉算子有一个参数 $p_c \in [0,1]$ 来指定发生交叉的概率。通常情况下，$p_c$ 的值被设置为显著高于突变概率 $p_m$ 的值。在实际应用中，$p_c$ 通常至少比 $p_m$ 高一个数量级（例如 $p_c = 0.5, \ p_m = 0.01$），表明生成新的候选解的任务主要由交叉操作来完成。

通常，在交叉操作中，从种群中随机选择两个父代个体以进行特定的过程，从而生成两个子代个体。这一过程涉及在生成子代个体时，将父代个体中特定子序列（在遗传算法术语中称为“等位基因”）的值进行交换。在标准的 $k$ 点交叉中，随机选择 $k$ 个交叉点以确定哪些子序列需要交换。最简单的版本是 $k = 1$ 的情况，这被称为单点交叉，交叉点以均匀概率选择。我们用以下示例来说明单点交叉操作。

假设两个父代个体为 $(x_i^1)$ 和 $(x_i^2)$，两个子代个体为 $(y_i^1)$ 和 $(y_i^2)$，其中索引 $i = 5, \ldots, 0$，比特值来自集合 $\{0,1\}$。单点交叉操作在比特位置 $j$ 处的交叉点可以表示为 $\otimes_{\{j\}}^{(1)}$。以下我们使用前缀表示法来表述这一操作。为了减少索引的繁琐并提高交换过程的清晰度，我们去掉索引项 $i$，仅依赖自然顺序以元组表示法进行表述（在本例中为逆序）。例如当 $j = 3$ 时，$\otimes_{\{3\}}^{(1)}$ 将生成如下两个子代个体：

\[
\big\{(y_i^1), (y_i^2)\big\} = \otimes_{\{3\}}^{(1)} \big\{(x^1, x^1, x^1, x^1, x^1, x^1), (x^2, x^2, x^2, x^2, x^2, x^2)\big\} \\
= \big\{(x^1, x^1, x^1, x^2, x^2, x^2), (x^2, x^2, x^2, x^1, x^1, x^1)\big\}.
\]

一个具体的双点交叉操作实例为 $\otimes_{\{4,2\}}^{(2)}$，其交叉点在比特位置 $\{4,2\}$，将生成如下结果：

\[
\big\{(y_i^1), (y_i^2)\big\} = \otimes_{\{4,2\}}^{(2)} \big\{(x^1, x^1, x^1, x^1, x^1, x^1), (x^2, x^2, x^2, x^2, x^2, x^2)\big\} \\
= \big\{(x^1, x^1, x^2, x^2, x^1, x^1), (x^2, x^2, x^1, x^1, x^2, x^2)\big\}.
\]

此外，还有许多其他形式的交叉算子 $[40, 66]$。特别是一些变体专门设计用于离散结构问题的二进制编码表示，例如旅行商问题（TSP），这类问题会结合修复机制以确保生成有效候选。对于某些涉及高维连续函数优化的问题，当最优解必须是整数值时，直接应用于二进制字符串表示的标准交叉和突变算子可能无法满足要求。编码方式以及相关的变异算子可能会在新的搜索空间中引入局部最优，原因是编码改变了邻域结构，而原始解空间（基于实数表示）中可能不存在这种局部最优 $[43, 113]$。
在需要处理连续问题领域（例如人工神经网络的参数优化）时，有些进化算法（EAs）采用实值突变和重组算子。从历史上看，进化策略（ES）和进化规划（EP）是演化计算的两个主要分支，这两个分支强调个体（表型）层面的适应性。它们提供的突变算子通常从单个父候选解生成单个子候选解。这样的算子被建模为一种扰动过程。设${\boldsymbol x}, {\boldsymbol x}' \in {\mathbb{R}}^n$为父候选解和子候选解的解向量，包含$n$个实值设计参数。考虑一种由单峰多变量分布描述源的扰动，一个简单的使用各向同性扰动${\boldsymbol z}$的突变算子定义如下：

\[
{\boldsymbol x}' = {\boldsymbol x} + {\boldsymbol z}, \\
{\boldsymbol z} \sim \sigma {\boldsymbol N}({\mathbf{0}}, {\mathbf{I}}).
\]

此处，${\boldsymbol z}$是一个多变量随机向量，其值从球形高斯分布$\sigma {\boldsymbol N}({\mathbf{0}}, {\mathbf{I}})$中抽取并且根据标准差$\sigma$进行缩放。它具有标准正态随机向量的形式，每个分量均为独立同分布（iid）随机变量，其值从同一高斯分布中抽取：$z_i \sim N(0, \sigma)$，其中$i = 1, \ldots, n$ [17]。上述高斯突变算子的形式可以进一步表述为，针对设计参数索引为$i = 1, \ldots, n$的情况：

\[
x^{\prime}_i = x_i + \sigma N_i(0, 1).
\]

由于$z_i$是独立同分布的随机变量，对于每个$i$，可以直接从标准正态分布$N(0, 1)$中重新采样。考虑非球形分布，即那些具有椭圆常密度表面的分布。这种情况下，$z_i$是独立但不相同的随机变量。每个$z_i$仍来自高斯分布，但具有不同的$\sigma_i$，对应的表达式变为：

\[
x^{\prime}_i = x_i + \sigma_i N_i(0, 1).
\]

例如，通过增加$\sigma_i$可以产生更大的扰动，以更好地适应某些设计参数$x_i$。上述突变算子的更一般版本可以考虑随机变量具有相关性的多变量高斯分布${\boldsymbol N}({\mathbf{0}}, {\boldsymbol \varSigma})$，其中协方差矩阵${\boldsymbol \varSigma}$是非对角线的且正定。这样的模型会旋转描述多变量高斯分布的坐标系，从而使突变算子能够在解空间中引入更有方向性的扰动 [17]。

上文提供了一种更正式的描述，以明确一些早期突变算子的机制细节和设计方法，它们主要用于高维连续优化问题。如果问题仅是单维的，则这一要求会降低。特别是，我们目前介绍的突变算子需要用户设置的扰动模型（例如多变量高斯分布）。在进化策略（ES）和进化规划（EP）中使用的一种更复杂的突变算子实现了参数$\sigma_i$的自适应，从而分布的形状也能够在某种程度上进化。针对设计参数索引为$i = 1, \ldots, n$的情况，这种自适应突变算子可描述如下：

（此处继续描述对应的公式和方法）。 
$\sigma^{\prime}_i = \sigma_i \exp\big(\tau' N(0,1) + \tau N_i(0,1)\big), \\
x^{\prime}_i = x_i + \sigma^{\prime}_i N_i(0,1),$

其中，固定参数定义为：$\tau' = 1/\sqrt{2\sqrt{n}}$ 和 $\tau = 1/\sqrt{2n}$。这种自适应变异算子已经被应用于演化人工神经网络（ANNs）的研究 [28, 32, 33]。此外，基于扰动的变异算子还可以被扩展到其他领域。例如，可以通过使用具有重尾分布的分布函数（例如柯西分布）以及更广泛的莱维分布家族 [97, 133]，设计以提供更频繁的大步长变异为目标的算子。需要注意的是，自适应机制也可以被结合到这些基于重尾扰动的变异算子中。此外，还有一些非基于多变量随机分布模型的变异算子，例如差分演化（DE） [39, 120] 中的变异算子，它使用来自父代种群中随机选择的两个候选解的缩放差分向量作为来源。

标准差分演化（DE）的变异算子可以描述为：
$x^{\prime}_i = x_i + \upsilon (y_i - z_i),$
其中，$\upsilon \in [0,2]$。

在针对连续优化问题的演化算法（EAs）中，与变异算子相比，重组算子通常扮演次要角色，用于生成新的候选解。实值重组算子的设计原理类似于遗传算法（GA）中的交叉算子。在此情况下，重组算子作用于解的实值向量表示。这可以通过在固定坐标系后标记轴并将其与序列中特定位置关联来编码为实数序列。在这一场景下，有$\mathbf{x} \in \mathbb{R}^n$，编码为$(x_i \in \mathbb{R} : i = 1, \ldots, n)$。

可以设计两种类型的重组算子，它们从随机选择的父代候选解集合$\{\mathbf{y}^1, \ldots, \mathbf{y}^m\}$中生成子代候选解$\mathbf{x}$。第一种类型称为离散重组，对于每个设计参数$i = 1, \ldots, n$，机制涉及从父代捐献集合中复制相关分量，具体定义如下：
$x_i = y_i^j, \\ j \sim U\{1,\ldots,m\}$, 其中，$j$从离散均匀分布$U\{1,\ldots,m\}$中抽取，并且$\{1,\ldots,m\}$中的每个值被选择的概率相等。这种方法称为中间重组（Intermediate Recombination）。该机制简单地通过计算表示父代捐赠者集合的解向量的质心实现。对于每个设计参数$i = 1, \ldots, n$，可以表示为：
$$x_i = \frac{1}{m} \sum_{j = 1}^m y_i^j.$$

我们将以简要讨论遗传规划（GP）中使用的标准变异算子来结束本节。特别是，我们将重点关注GP树结构表示的重组和变异算子。GP交叉算子的机制类似于传统遗传算法（GA）中用于二进制字符串表示的交叉，但需要在算子设计中施加约束。这些约束用于解决进化GP树时遇到的两个常见问题。第一个问题是结构的快速增大，导致生成的树结构过于臃肿，但其行为却与更紧凑的结构相似，比如具有相似的适应度值。第二个更重要的问题与生成非法树结构相关。当问题域需要使用具有多种类型的原始函数集时，这一问题会出现。例如，这可以涉及从$\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$（例如算术操作，如加法$x + y = z$）到$\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{B}$（例如不等式关系，如$x \leq y \equiv b, \ b \in \{\mathrm{true}, \mathrm{false}\}$）的函数集合。解决非法树结构生成问题的一种方法是将数据类型作为原始集合中的元素描述的一部分进行引入。这种扩展称为强类型遗传规划（STGP），已被研究和应用 [109]。STGP已在领域中成功应用于进化计算机程序 [3, 4]。

一旦这些约束被识别出来，它们就可以被纳入GP变异算子的设计中，以生成合法树结构。一个简单的重组算子是标准子树交叉（Standard Subtree Crossover）[95]。该算子以两个父代候选解作为输入，并生成一个子代候选解。其工作机制首先随机选择两个父代GP树中的交叉点。交叉点对应于根于该点的子树接点。然后，交叉算子将第一个父代GP树中被识别出的子树替换为第二个父代GP树中的子树。

需要注意的是，随机选择交叉点的过程在实际应用中设计为有偏。例如，大多数GP树具有至少平均分支因子为2（例如源于二元运算符和关系的使用）。较大的子树关联的交叉点较少。例如，在深度为2的完全二叉GP树中，六个交叉点中四个会有叶节点（终端）根于其上进行关联。因此，均匀随机选择更有可能选中这些叶节点，而不是较大的子树，从而导致用于生成子代候选解的遗传物质交换范围较小。

其他更复杂的交叉算子通常涉及一个匹配过程，以确保交换的子树在结构上类似，例如，文献[94]中提出的尺寸公平交叉（Size-Fair Crossover）算子。
遗传编程（GP）的变异操作在设计时需要更加全面地考虑，确保对树结构的修改是合法且可被解析的。根据在GP树中选择参与变异过程的元素，可以首先从最简单的结构（即叶节点）开始，然后再处理更复杂的子树。如果选择的叶节点仅包含常量值，那么可以通过简单的扰动过程来修改这些值。如果选择的是内部节点，可以对该节点应用点变异操作。这种方法通过将节点中的元素替换为一个符合原始集合中$arity$约束（即参数数量）的元素来实现。例如，一个表示减法的节点可以通过点变异操作改变为加法节点。此外，还可以使用子树变异操作来生成新的子树结构。首先选择一个变异点，然后随机生成一个新的子树并将其附加到该变异点上。在这一操作中可以引入约束条件，例如规定生成的子树的最大深度[3, 4]。

### 1.2.4 选择操作器  
在演化算法（EA）中，选择操作器的主要任务是形成下一代的新种群。通常，这涉及从当前整个种群中选择候选解集合，这些候选解将在演化过程的下一代中充当父代。选择操作器利用候选解在评估后分配的适应度值完成这一任务。这与变异操作器不同，后者使用的是编码在候选解中的遗传信息。这一简单的描述掩盖了选择操作器的机制在转化种群配置时的全部复杂性。例如，为下一代选择的父代候选解的集合通常是一个多集合（或袋子），其元素来自当前种群。具有较高适应度值的个体候选解更可能被选中，并且出现的频率也通常高于其他候选解。因此，新的父代种群可能包含这些个体候选解的多个副本。然而，选择过程并不一定是精英主义的。在这种情况下，更复杂的机制可能偶尔选择某些适应度较低的候选解，以增加并保持正在演化的种群的多样性。

尽管如此，可以通过一个仅基于适应度值的简单过程来更深入地理解选择操作器。考虑一个用于解决全局最优优化问题的演化算法。作为一种基于种群的搜索方法，这表明成功搜索的阶段包括种群对最优解的首次发现以及随后向该解收敛的过程。为了确定成功演化搜索的进展是否与选择操作器相关的某些参数设置有关，可以在选择压力（或选择性压力）的背景下进行研究[7]。选择压力是选择操作器的一种属性，用于表征个体候选解的适应度值与其被复制形成新种群的概率之间的关系。
理论研究已经对选择压力对演化搜索的影响进行了探讨。早期的分析方法使用了诸如接管时间（takeover time）的概念，接管时间量化了种群收敛到最优解所需的时间 $[67]$。现代运行时间分析通过将演化算法（EAs）看作随机化算法，提供了一种严格的方法，用来量化EAs中种群向最优区域漂移的速度 $[47]$。这种分析方法已经被用于研究带有不同选择压力的选择算子对EAs运行时间性能的影响 $[30, 45]$。 

在应用和实证研究中，人们更宽松地使用选择压力的概念，认为选择压力可以通过调整参数设置或者设计相关算子来更改，以影响演化搜索的进行阶段。强选择压力可能会偏向于在搜索空间中高性能候选者定义的区域进行开发（exploitation）；弱选择压力则可能鼓励演化搜索去探索与低性能候选者相关的区域，这些区域潜在可能与新的更具前景的区域相差几个演化步骤。在这种背景下，人们通常会考虑各种为EAs设计的选择算子。在下文中，我们将介绍几种常见的选择算子。 

第一种是适配度比例（或轮盘赌）选择，它通常用于遗传算法（GAs）。我们考虑解空间 $\boldsymbol{S}$（例如 $\boldsymbol{S} \subseteq \mathbb{R}^n$）。这一特定算子使用一种简单的概率方法来决定当前种群中个体 $\boldsymbol{x}_i, \ i = 1,\ldots,s, \ \boldsymbol{x}_i \in \boldsymbol{S}$ 的复制率。其复制率基于个体适配度值 $f(\boldsymbol{x}_i)$ 相对于种群累计适配度 $\sum_i^s f(\boldsymbol{x}_i)$ 的比例。下一个世代种群中被选择复制的个体的概率为：

$$\mathbb{P}_i = \frac{f(\boldsymbol{x}_i)}{\sum_i^s f(\boldsymbol{x}_i)},$$

并且满足归一化条件：

$$\sum_i^s \mathbb{P}_i = 1。$$

这种适配度值归一化使得它们可以被解释为概率，并定义了一个离散概率分布，在集合 $\{\boldsymbol{x}_1, \ldots, \boldsymbol{x}_s\}$ 上可以抽取随机样本以形成下一个世代的父代种群。需要注意的是，适配度值必须是正实数。这种适配度比例选择的形式在适配度函数 $f: \boldsymbol{S} \rightarrow \mathbb{R}_{\geq 0}$ 的最大化问题中非常简单。然而，在其他问题中，例如最小化问题或适配度值为负数的问题，则需要对适配度函数进行重构或使用适当的尺度变换函数。后一种方法一般会利用候选者的原始适配度值与最差候选者的适配度值之间的差值作为新的分配适配度值 $[7]$。
接下来是锦标赛选择算子。其机制相对简单，需要两个正整数参数：锦标赛规模$q$以及下一代父代种群的规模$p$。该算子将从当前种群中随机抽样$p$次（带放回）。每次抽样中表现最好的个体会被复制，形成下一代的父代个体。文献[7]提供了该算子的正式组合描述，并推导了当前种群中规模为$s$的各个个体$i$被选择用于复制的概率$\mathbb{P}_i, \ i = 1,\ldots,s$。在这里，我们描述一种该算子的非正式实现方法。假设当前种群服从离散均匀分布，然后从该分布独立同分布(i.i.d)随机抽样$p$次。这会产生$p$组样本$(\boldsymbol{x}_k)^j, \ j = 1,\ldots,p$。每组样本$(\boldsymbol{x}_k)^j$是一个候选解的集合，我们考虑排列$(\boldsymbol{x}_i,\ldots,\boldsymbol{x}_q)$使其满足$f(\boldsymbol{x}_i) \leq \cdots \leq f(\boldsymbol{x}_q)$，即根据适应度值递增顺序进行排序。令$\boldsymbol{x}_{k,j}$表示从样本$(\boldsymbol{x}_k)^1,\ldots,(\boldsymbol{x}_k)^p$中取出的第$j$组有序列表中的第$k$个元素。在最大化问题中，下一代父代种群通过取$\boldsymbol{y}_j = \boldsymbol{x}_{q,j}$来获得。而在最小化问题中，则可以直接取$\boldsymbol{y}_j = \boldsymbol{x}_{1,j}$。

此外，还有几种基于排名的选择算子被设计出来[71]。一般来说，这些算子使用种群中候选个体的排名而非适应度值作为选择的主要依据。采用排名有两个好处：第一，对于无法得到有用的目标函数或任何代理函数以评估候选解质量的情况，使用排名可能是一种更优的选择。在这种情况下，可以通过种群中候选解的两两比较来获得排名。第二，使用排名能够避免构造离散概率分布时可能出现的归一化问题，例如负适应度值，或依赖于种群结构的其他归一化问题（如当大多数候选解具有类似的适应度值，或者种群存在适应度值差异显著的小分组时）。一种具体的版本是线性排名选择算子，它将概率以线性的方式分配给当前种群中根据适应度值递增排序的候选个体$i = 1,\ldots,s$。该概率为：

$$
\mathbb{P}_i = \frac{1}{s}\bigg(\alpha + (\beta - \alpha)\frac{i - 1}{s - 1}\bigg).
$$

该算子有两个参数，满足$1 \leq \beta \leq 2$以及$\alpha = 2 - \beta$。$\beta$和$\alpha$分别与当前种群中表现最佳和最差的个体的期望复制次数相关。其他基于排名的选择算子则使用几何分布或指数分布等函数来对概率进行缩放[71]。概率计算完成后，算子即可基于计算出的离散概率分布抽取随机样本。
我们接下来描述一种基于确定性机制的选择算子家族。特别是，$(\mu, \lambda)$ 和 $(\mu + \lambda)$ 选择算子通常用于演化编程（EP）和演化策略（ES）。在两种情形中，变异算子首先被应用于从 $\mu$ 个父代候选生成 $\lambda = k \mu, \ k \geq 1$ 个子代候选。也就是说，每个父代候选会产生 $k$ 个子代候选。在 $(\mu, \lambda)$ 选择中，$k$ 通常被设置为一个大于 1 的值，从而从生成的 $\lambda$ 个子代候选中选取最好的 $\mu$ 个，以形成下一代的父代种群。而在 $(\mu + \lambda)$ 选择中，符号“$+$”表示父代候选个体和子代候选个体的组合种群被作为选择操作的候选池。在这种选择中，从这个组合池中的 $\mu + \lambda$ 个个体中选取最好的 $\mu$ 个候选，以组成下一代的父代种群。

虽然还有其他选择算子，但我们将在本文的最后介绍一种特别用于演化编程的选择算子。此算子的机制介乎于之前描述的锦标赛选择和 $(\lambda + \lambda)$ 选择之间（即 $k = 1$，因此 $\mu = \lambda$）。之所以引用 $(\lambda + \lambda)$，是因为变异算子使用 $\lambda$ 个父代候选生成同数量 $\lambda$ 个子代候选。这些子代和父代共同构成提供选择操作所需的完整种群。研究 [7] 提供了关于该选择算子性质的技术论证，表明其本质为一种概率性的 $(\lambda + \lambda)$ 选择。我们在此基于一些简化假设作出非正式但直观的说明。

考虑一个最大化问题，组合种群 ${\boldsymbol x}_1, \ldots, {\boldsymbol x}_{2\lambda}$ 被自然排序为候选的适应值递增且互不相同的顺序。然而，此算子使用基于分配的锦标赛分数排序所获得的排名。这些分数是通过将候选 ${\boldsymbol x}_i$ 与组合种群中的其他候选进行成对比较计算得出的。如果使用整个种群，则排名保持自然排序；否则，使用较小样本计算锦标赛分数会扰乱原有的自然排序，进而实现锦标赛排名。

接下来，我们描述该算子的机制。对于每个候选 ${\boldsymbol x}_i, \ i = 1, \ldots, 2\lambda$，关联一个随机样本 $T_q^i = \{{\boldsymbol y}_j : j = 1, \ldots, q\}$，样本以离散均匀概率分布从组合种群中抽取。即 ${\boldsymbol y}_j \sim U\{{\boldsymbol x}_1, \ldots, {\boldsymbol x}_{2\lambda}\}$，且 ${\boldsymbol y}_1, \ldots, {\boldsymbol y}_q$ 是独立同分布的随机变量，每个变量从 $\{{\boldsymbol x}_1, \ldots, {\boldsymbol x}_{2\lambda}\}$ 中取值。然后，每个候选 ${\boldsymbol x}_i, \ i = 1, \ldots, 2\lambda$ 的锦标赛分数可以如下计算：

\[
g\big({\boldsymbol x}_i,T_q^i\big) = \sum_{j \in T_q^i} {\mathbf{1}}_{{\mathbb{R}}_{\geq 0}}\big(f({\boldsymbol y}_j) - f({\boldsymbol x}_i)\big),
\]

其中，

\[
{\mathbf{1}}_{{\mathbb{R}}_{\geq 0}}\big(f({\boldsymbol y}_j) - f({\boldsymbol x}_i)\big) = 
\begin{cases} 
1 & \ \mathrm{if} \ f({\boldsymbol x}_i) \geq f({\boldsymbol y}_j), \\
0 & \ \mathrm{otherwise}.
\end{cases}
\]

请注意，每个候选 ${\boldsymbol x}_i$ 的锦标赛分数可以被解释为该候选在每场双人游戏中赢得的胜利次数，其中对手来自锦标赛样本 ${\boldsymbol y}_j \in T_q^i$。指示函数 ${\mathbf{1}}_{{\mathbb{R}}_{\geq 0}}$ 本质上实现了这种游戏，并为第一个玩家 ${\boldsymbol x}_i$ 输出结果。游戏涉及两位玩家适应值的成对比较，其中当 $f({\boldsymbol x}_i) \geq f({\boldsymbol y}_j)$ 表示 ${\boldsymbol x}_i$ 获胜并得分为 1；否则 ${\boldsymbol x}_i$ 失败并得分为 0。

随后，锦标赛选择通过选取锦标赛分数 $g\big({\boldsymbol x}_i, T_q^i\big)$ 最高的 $\lambda$ 个候选完成。
$g\big({\boldsymbol x}_i,T_q^i\big)$。

### 1.3 演化算法中的参数控制  

在第1.2节开头，我们详细描述了如何通过基于种群的随机搜索框架来解决问题的演化算法（EAs）。随后，在第1.2.1到1.2.4的各节中，我们介绍了实施演化算法所需的主要组成部分：种群、解的表示方式，以及变异与选择两种演化运算符。我们可以使用标准的设置，例如遗传算法（GAs）、演化规划（EP）和演化策略（ES）的经典形式，也可以使用优化后的改进形式，这些形式旨在一般性提升算法性能或针对特定问题结构进行定制（例如基于符号演化方法的基因编程（GP）可用于进化程序）。

需要注意的是，演化算法必须初始化一系列参数才能进行运算。这些参数与演化算法的主要组成部分相关（即算法1.1），包括种群大小，以及影响搜索性能的变异强度和选择压力的参数。这意味着在演化算法中，对参数的定制空间远远大于预先决定每个组成部分、具体设置、表示设计以及运算符的使用方式。

我们首先根据文献[54]提出的分类，在演化算法的上下文中区分与EA运算相关的参数可变性主要涉及两方面的操作。这种分类还可以拓展到更广的元启发式方法上下文，例如文献[83]提出的分类方法。

首先，**参数控制**指的是在演化算法运行期间对这些参数进行有针对性的调整。这一理论认为，在演化算法搜索过程的不同阶段，对应不同的参数值会更有效地提升搜索效率。

其次，**参数调整**指的是在演化算法执行之前通过静态方式设置这些参数。通常，演化算法相对于目标问题的性能与初始参数值密切相关。这种关系要求在EA设置过程中进行初步尝试，而不是随意初始化参数。

在文献[54]中，将演化算法中的参数控制方法大致分为三类。**确定性方法**通常使用某种形式的固定计划来改变参数。另外两种方法是**适应性方法**和**自适应方法**，它们通过基于搜索过程的反馈机制更改参数。自适应方法可以视为上述两种方法的进一步完善。自适应方法将演化算法的参数以适合的形式表示，并将参数的调整机制集成到演化过程之中。

需要注意，参数控制的这种分类在文献[46]中得到了进一步细化和扩展，其中划分出了五个类别。
这些两个类别的主要区别在于参数允许发生变化的时间。在参数调整（Parameter Tuning）中，这一过程以离线方式完成，而在参数控制（Parameter Control）中，参数的变化在演化算法（EAs）的执行过程中在线进行。尽管如此，它们在实现的总体设计上以及需要解决的挑战上存在共性。在本节的其余部分，我们将通过分别的子节进一步讨论如何通过种群（Population）、变异（Variation）和选择操作符（Selection Operators）将参数调整和控制应用于演化算法。我们的讨论总结并反思了先前在文献[84]中进行的研究，同时包含了一些在新研究中详细描述的发展，例如文献[46]。

### 1.3.1 种群规模上的参数控制

针对特定问题找到合适种群规模的主要问题在于理解种群规模对成功的EA搜索的影响，这为开发种群规模控制的程序提供了信息支持。一些早期的理论研究采用了“构建块模型”（Building Block Model）[69]，该模型基于若干简化假设。在离散优化的背景下，问题结构的性质通常被假设为可以加性分解成独立的分区。在每个分区中，存在不同的子解或构型，其中一种是优于其他的，并且至关重要地属于全局最优解的一部分。分析的重点在于遗传算法（GA）如何将所有构建块组装成正确的解决方案。一些研究将此过程形式化为一个马氏链（Markov Chain）[100]，特别是描述为一个一维随机游走（One-dimensional Random Walk）[103]。通过研究这样的模型，可以解释种群规模对成功搜索的可能性或失败风险的影响。

如同演化计算理论发展的历史和现代趋势一样，理论研究通常由广泛的、系统性的实验研究支持并补充。在这些实验研究中，可以放宽理论分析的强假设，比如问题结构或EA设计上的定义要求。关于种群规模参数调整和控制的文献中识别出了三个主要问题[84]。第一点是消除设置种群规模的需求，大多数研究方法探讨的控制机制是通过个体的生命周期模拟，初始化足够大的种群规模后，个体从种群中被移除[2, 35]。第二点涉及近似搜索所需的种群规模，许多机制集中于以某种控制方式增加种群规模，例如通过贪婪算法[118]或随机方法[72, 73]来翻倍增长。最后，各种研究探讨了在演化过程中使用可变种群规模的有效性，这些机制包括确定性控制[90]、自适应控制[116]以及自我适应控制[122]。
### 1.3.2 变异算子的参数控制  

如文献 [84] 所述，与演化算法（EAs）中其他组成部分相比，针对变异算子相关参数的调整和控制已经得到了广泛研究。这并不令人惊讶，因为变异算子的主要作用是生成新的候选解供评估，这些候选解随后由选择算子决定是否进入下一代种群以进行复制。在这种情况下，相关研究的动机主要集中于解决两个主要问题。  

第一个问题涉及在搜索过程中实现全球探索与局部开发之间的有效平衡，这是必需的。第二个相关问题则在于变异算子的有效性，例如，确保演化算法具有适当的步长大小以更好地搜索解空间 [29]。我们接下来的讨论将重点介绍两种主要设计机制，通过这些机制可以在演化算法的变异算子上实施参数控制。  

现代演化算法的运行时间分析使得可以深入研究静态参数设定（如变异率） [78]以及那些涉及动态参数设定的变异算子 [46]。尽管有必要使用简化的演化算法实现来匹配精心设计的基准问题，以确保数学分析的可操作性，理论研究在使用参数调整和控制变异算子上报告了积极成果。这些研究进一步提供了关于参数调整和控制为何有效的洞见。例如，文献 [51] 的早期研究展示了一种确定性的方法，该方法使用简单的调度方案在经典 $(1+1)$EA 离散优化问题的每次迭代中将变异率加倍，比具有固定变异率的同类 EA 更适合解决具有特定结构的问题。  

非正式地，这类问题存在一个全局最优解，该解被作为陷阱的局部最优解包围，因为这些局部最优解能够被容易地搜索。一旦达到局部最优，必须通过直接变异进行较大跳跃才能到达全局最优。在这种情况下，如果允许 $(1+1)$EA 增加其比特翻转算子的变异率，它更有可能达到全局最优。然而，对于具有不同特性的其他问题，使用固定变异率的选择可能更好。这些严格但可解释的研究结果也反映在实证研究中，这些研究调查了其他更复杂的变异算子参数控制机制。  

一种方法涉及随着演化算法过程中的某些可测状态变化而改变变异算子的参数设定的机制。文献 [46] 将这种机制称为状态依赖的参数控制机制。其中之一被称为 "多样性维护技术"。早期研究 [119] 使用了这样的机制：该机制根据某种特定测量指标（表明种群的收敛水平）来改变交叉和变异率。这个指标是种群中最佳候选解与种群平均适应值之间的差值 $f_{\mathrm{max}} - f_{\mathrm{avg}}$。  

一个简单的比例函数基于变异算子参数与收敛水平之间的逆关系，被操作用于改变并设定交叉和变异率。然而，这种机制还包括额外的检查，在种群收敛到低多样性的配置（例如由低 $f_{\mathrm{max}} - f_{\mathrm{avg}}$ 值表示）时，对低适应值的候选解应用更高的交叉和变异率。
我们在前面描述的机制需要用户设计调度、函数和其他操作来调整参数，其效果通常依赖于问题结构的先验知识。另一种替代方法是使用采用自适应控制方法的机制。这种方法将变化算子中的参数与种群中的候选解关联，其参数的改变通常通过某种扰动过程实现，但只有当关联的候选解在下一代中被选择进行复制时，才会进行相应的改变。例如，研究[135]引入了这种自适应控制方法用于差分进化（DE）。在这种情况下，DE变化算子中的交叉率和变异因子的改变是通过扰动实现的。例如，使用基于柯西分布的扰动来改变变异因子。需要注意的是，由于变化算子中的参数变化机制和解表示中的参数变化机制不同，这被视为一种自适应控制方法。当演化过程直接用于改变这两组参数时，则称为使用自适应参数控制机制。我们在Sect. 1.2.3中介绍了一种特定的自适应参数控制机制，它通过对解向量表示的每个分量独立地应用对称单变量概率分布的独立扰动，针对实值变异算子实现自适应控制。

我们将讨论的最后一种方法采用了更复杂的机制，其中变化算子的变化不仅发生在参数层级，还涉及其符号化的操作描述。这些机制设计的主要操作问题在于如何在演化过程中为特定变化算子分配有限且固定的计算资源，以最大化生成适应度值更高的后代候选解，从而提升进化算法（EA）的优势。这类机制的设计和实现有两种主要方法。第一种方法基于机器学习的多臂赌博问题框架，形式化了这一分配过程。第二种方法基于元启发式算法，提出了超启发式的概念。不仅可以从现有的算子集合中选择，还可以通过生成器从基本版本生成更复杂的算子。

早期研究[107]详细回顾并进行了关于这种机制在EA中应用于变化算子的经验研究。研究重点是离散优化问题，特别是经典的布尔可满足性问题（通常缩写为SAT），其目标是寻找适当的变量赋值使命题逻辑表达式获得满足（即表达式的值为$\mathrm{true}$）。解可以表示为标准的合取范式（CNF），这种范式由子句的合取构成，其中子句本身是文字或变量（即这些变量可以从布尔集$ \mathbb{B} = \{\mathrm{true},\mathrm{false}\} $中赋值）的析取。例如，2-SAT问题将CNF中的命题表达式限制为每个子句仅包含两个变量，且要求其中一个变量必须为$\mathrm{true}$。一个候选解是布尔值的组合，这些值被赋予变量以满足给定的命题表达式。与精确方法不同，EA作为一种近似方法，利用某种代理函数（例如最小化错误子句数$\mathrm{false}$）来指导对解的进化搜索。
在文献[107]中，一种复杂的操作符管理系统被引入并融入到遗传算法（EA）中，该系统能够选择和生成交叉操作符。原则上，这需要构建交叉操作符的空间。这一构建过程是在识别四个基本特征（每个特征包含若干可选动作），这些动作可以对表示可能解决方案的父候选个体（使用合取范式，CNF表示）进行修改后得以实现。通过为这四个特征中的每一项选择一个动作，可以生成一个交叉操作符。实际上，可以在线搜索交叉操作符的空间，此后，该机制将选出的最适合当前演化搜索阶段的操作符传递并使用。该操作符评价涉及三个衡量指标，分别与种群多样性、解决方案质量和执行时间相关。并不是所有关于变异操作符的自适应操作选择或超启发式参数控制方法都像文献[107]中开发的那样复杂。例如，由于相关技术挑战，其中一种为这种参数控制的少数理论研究之一的文献[48]研究了一种简单的位翻转变异操作符，该操作符能够通过单一参数来调整自身的变异强度。通常，会构建一个包含 $k$ 个参数值的组合或集合，用于选择一个适用于变异操作符的参数值。选择这些参数值的基础方法涉及概率匹配[46, 107]。具体来说，每个 $i = 1, \ldots, k$ 的参数值都附带一个置信值 $c_i$，该置信值表示在时间步长 $t$ 时参数值在当前遗传算法搜索阶段中的适用性。选择第 $i$ 个参数的概率 $\mathbb{P}_i$ 根据其关联的置信值 $c_i$ 按以下方式分配：

\[
\mathbb{P}_i(t) = \mathbb{P}_{\mathrm{min}} + (1 - k\mathbb{P}_{\mathrm{min}})\frac{c_i(t)}{\sum_{j = 1}^k c_j(t)},
\]

置信值更新规则如下：

\[
c_i(t + 1) = (1 - \alpha) c_i(t) + \alpha r(t).
\]

置信值会根据变异操作符在应用第 $i$ 个参数值设置后对遗传算法产生的归一化奖励或增益 $r(t)$ 进行权重更新。超参数 $\alpha \in (0, 1)$ 用于控制置信值的适应速率。需要注意的是，每个第 $i$ 个参数值至少有一个最低概率 $\mathbb{P}_{\mathrm{min}}$ 被选择。
对概率匹配还有其它更为复杂的方法，这些方法在参数值的选择上采用了更复杂的公式。在**自适应追求（adaptive pursuit）算法**中，更新规则在增加所选参数值的置信值的同时，将非选择参数值的置信值降低，这些参数值是在演化算法（EA）的搜索迭代中未被选中的。在**上界置信算法（upper confidence bound algorithm）**中，参数值的选择基于一个加权和的最大化，这个加权和包括两个部分。第一部分涉及与参数值相关的固定分布上的期望奖励，它模拟了对使适应度增益最大的参数值的利用搜索。第二部分涉及一个函数，其输出与某个参数值过去被应用的次数成反比，但与演化过程中的迭代次数的对数成正比。这部分模拟探索性搜索机制，作用是平衡并选择在EA早期阶段较少应用的参数值【46】。

### 1.3.3 选择操作符的参数控制

选择操作符的参数控制机制旨在通过改变选择压力的方式来调整操作符。例如，它可以对操作符的参数设置进行特定调整。与EA中的其他组成部分一样，一种基本方法是**确定性参数控制（deterministic parameter control）**，它由用户设定，针对选择压力进行预定的改变。一个被研究并应用的机制基于一种随机优化器——**模拟退火（Simulated Annealing，SA）**所采用的方法。原创研究【88】深入探索了SA解决旅行商问题（TSP）的方法与物理系统中的退火过程的深层联系。简而言之，后者使用统计描述来刻画多体热力学物理系统。在物理系统的粒子集合中，与特定的状态配置$i$相关的概率由**玻尔兹曼分布（Boltzmann distribution）**描述。这一概率$P_i$与$e^{-\frac{E_i}{kT}}$成正比，其中$E_i$是状态配置$i$的能量值，$k$是玻尔兹曼常数，$T$是系统的温度。通过冷却时间表获得热力学系统基态的物理退火过程被用来设计随机优化的搜索过程。

此外，生成并测试的搜索过程涉及**概率接受（probabilistic acceptance）**。在最小化设置中，生成的候选解会被接受，如果它的适应度差异满足$\Delta f \leq 0$。否则，对于质量较低的候选解，其被接受的概率与$e^{-\frac{\Delta f}{kT}}$成正比。在文献【44】中，通过研究设计了一种**玻尔兹曼选择操作符（Boltzmann selection operator）**，它对传统的适应度比例选择操作符进行修改。这个修改涉及对种群中候选解的原始适应度值进行一次标度指数变换。这种变换描述的函数形式为玻尔兹曼分布。种群中$s$个候选解的选择概率对于解$i = 1,\ldots,s$的计算如下：
$P_i = \frac{\exp\big(f({\boldsymbol x}_i)/T\big)}{\sum_i^s \exp\big(f({\boldsymbol x}_i)/T\big)}$表示最大化问题的适应度分布。在最小化问题中，使用$-\exp\big(f({\boldsymbol x}_i)/T\big)$的变换。需要注意的是，如果使用恒等函数，Boltzmann选择操作会简化为适应度比例选择。因此，这里存在一个参数$T$，它能够控制该选择算子的选择压力。选择压力表现为$T$参数设置之间的两个极端。在较低参数值时，变换会放大原始适应度值的差异，从而增加高适应度候选被复制的机会。而在较高参数值时，变换会减少原始适应度值的差异，从而更加均等地分配复制机会。因此，文献[44]中设计了一种线性降温调度方案，以在演化算法(EA)的初始阶段促进更具探索性的搜索，然后随着演化搜索的进行逐渐切换到更具开发性的搜索阶段。文献[108]的研究采用了一种自适应的、状态依赖参数控制方法，应用于锦标赛选择操作。特别地，采用了一种维护多样性的机制，通过控制锦标赛样本的大小来调整不同阶段演化搜索中的选择压力。为此，引入了一种特定的多样性度量—健康种群多样性(Healthy Population Diversity, HPD)。然后，根据HPD值的大小来调整锦标赛规模，使其与HPD值成比例。HPD度量采用个体适应度值加权的欧几里得距离，这一距离是相对于种群平均值计算的。在文献[55]中，采用了一种自适应的方法，用于锦标赛选择操作的选择压力变化。每个个体被赋予一个额外的参数，该参数随着演化过程通过通常的自适应变化进行调整。锦标赛规模的参数设置根据这些由演化的个体贡献的值集成后进行变更。

### **1.4 总结性评论与进一步阅读的建议**
在我们对演化算法(EAs)主要方面的介绍与讨论中，我们强调了这一广泛的基于种群的、随机的、迭代搜索方法族作为通用问题求解器的重要作用。特别地，EAs可以通过“生成-测试”框架来理解，其作为一个计算系统由三大主要组件构成。丰富的实验研究与严格的理论研究已被用于开发这些组件操作的不同机制，以及探讨参数设置对EAs性能的影响。因此，一个EA可以被适当地设计为拥有匹配的组件，以更好地应对问题的结构和特性。可以参考现有文献中展示其在解决相似问题类别方面有效性的EAs家族，同时基于文献中的建议或自身的初步研究，进行修改可能会带来性能提升。
进化算法（EA）解决问题的开发过程看似简单，却掩盖了其搜索行为的内在复杂性。可以理解，要使EA进一步被接受为主要的启发式方法之一以及精确算法的主要替代方案，其进化搜索过程的行为需要被深入理解。然而，在实际EA的组成部分中使用的机制设计的复杂性使得这一任务极具挑战性。比如，适应度景观（fitness landscape）的概念，一个常见的工具用于理解和分析EA解决的优化问题，就显示出了这方面的困难。适应度景观形式化定义为三元组$L = (S, f, d)$，其中包括搜索空间$S$、适应度函数$f: S \rightarrow \mathbb{R}$，以及距离度量$d: S \times S \rightarrow \mathbb{R}_{\geq 0} \cup \{+\infty\}$。

对于连续优化问题，适应度景观描述相对直观，主要通过适应度函数来描述（例如，对于一个无约束优化问题为$f: \mathbb{R}^n \rightarrow \mathbb{R}$）。然而，即便对于更简单的单目标优化问题，也可以构造具有各种问题特性的函数[76]，这些函数集合被用于作为评估EA性能的基准集[79]。而离散优化问题，或涉及解决方案编码为连续域的场景，则可能明显更具挑战性。关于这些方面可以参考文献[43]进行更详细的讨论，我们在此仅简要介绍。

非正式地讲，完整的三元组$(S, f, d)$是必要的，因为离散搜索空间$S$会因内部点$s$之间拓扑关系的不同而有所变化。可以通过将搜索空间$S$表示为一个图$G = (V, E)$来获得更好的理解，其中顶点集合$V$代表所有候选解，边集合$E \subseteq V \times V$表示通过变异算子对候选解进行变换的结果。因此，点$s \in S$的拓扑关系由其邻域结构决定，而邻域结构取决于变异算子的操作。例如，二进制字符串编码表示及一位突变将会在搜索空间中引入超立方体结构，而使用二进制字符串的所有位的多位突变会在搜索空间中引入完全图结构。在这个背景下，由于邻域结构的变化当使用不同的解决方案表示和编码时，问题的结构可能会发生变化（例如，引入新的局部最优解）[43]。

因此，通过严格分析以深入理解实际EA的搜索行为是非常具有挑战性的。这也适用于理论研究，其中已付出了大量努力，以构建实际EA的更抽象版本以及具有详细问题结构的基准函数。例如，可以参考最新的文献[47]，其中对关于EA在离散优化问题上的现代运行时间分析的20年研究进行了全面概述和总结，从而理解所涉及的技术挑战。在这些理论研究中，EA被建模为随机算法，其运行时间分析需要经过三个步骤[98]。首先，应确定一个合适的距离度量$X_t$，用于表示EA在第$t$次迭代或时间步的进展。接下来，建模并分析该度量的一步变化性质，即随机变量$X_t - X_{t + 1}$在任何给定$X_t$值时的行为。然后利用这些知识来表征EA的运行时间$T$，即EA解决问题所需的迭代次数。

即便对于行为明确的简单EA解决的求解问题，其中的挑战也可能很大。例如，假设该过程可以约束为马尔科夫链形式$(X_t \in S : t \in \mathbb{N}_0)$，其中$X_t$取值来自集合$S = \{0\} \cup [1, \infty)$，且$\mathbb{N}_0 = \{0\} \cup \mathbb{N}$。即使在这样的构造中，基于偏移$\mathbb{E}[X_t - X_{t + 1} \ | \ X_t = s]$对所有$s \in S$的知识，要推导关于期望首次命中时间$\mathbb{E}[T]$的论断（例如，给定随机变量$T$，EA解决优化问题并达到适应度度量值$X_t = 0$的最早时间$t \geq 0$）也可能非常复杂[99]。
我们将以一段关于现代进化优化器与经典数值优化器之间概念差异和相似性的讨论来结束本章。回到单目标优化问题，虽然这些问题可能较为简单，但现代实际应用中的进化算法(Evolutionary Algorithms, 简称EAs)的搜索过程仍然表现出显著的复杂性。考虑如下问题设定：目标是无约束优化函数$f : \mathbb{R}^n \rightarrow \mathbb{R}$，其中$f$是一个凸函数并且具有二阶可微性。具体而言，我们关注凸二次优化问题的家族（例如，详见参考文献[21]第九章）。许多此类二次优化问题被广泛用于标准基准测试问题[76]，例如简单的球体问题（simple sphere problem），其形式化定义为$f(\boldsymbol{x}) = \| \boldsymbol{x} \|^2$，其全局最优解位于原点，即$\boldsymbol{x}_{\mathrm{opt}} = \mathbf{0}$。

对于这一问题，可以采用梯度下降法[21]来解决，因为可以求导得到负梯度。在简单球体问题中，如果忽略使用精确线搜索所需的计算代价，那么可以观察到该方法沿着从当前点向原点的方向下降。然而，作为一种无导数的搜索方法，EAs将问题视为黑盒优化（Blackbox Optimization），即对目标函数的了解仅限于调用或查询以评估候选解的适应度[6]，并且不会尝试对问题结构进行建模，因此表现出不同的搜索行为。虽然球体问题中的凸结构确保了精英式(1+1)EA能够沿着适应度景观下降（即生成的子候选解$\boldsymbol{x}'$仅当$f(\boldsymbol{x}') < f(\boldsymbol{x})$时被接受），EA的搜索路径可能表现为一种类似“之字形”的模式，而非直接从初始点到原点的直线传递。然而，一些现代的群体规模大于1的EAs的搜索行为可能在质上更接近于梯度下降法所表现的方式。通常，这涉及通过整合关于问题结构的信息来引导整个群体的进化搜索过程。

回想一下诸如演化策略(Evolution Strategies, ES)和演化规划(Evolutionary Programming, EP)等EAs，它们采用基于实值扰动的变异操作器直接从父候选解生成子候选解。其中一些，例如协方差矩阵自适应演化策略(Covariance Matrix Adaptation Evolution Strategy, CMA-ES)，通过定义在搜索空间$\mathbb{R}^n$上的多变量高斯分布来直接生成子候选解[74]。CMA-ES设计了一种复杂的机制，通过从搜索过程中进化路径中提取的信息来更新协方差矩阵$\boldsymbol{\Sigma}$。进化路径中的每次迭代是$\mathbb{R}^n$中的一个点，并由当前代种群中表现最佳的$\mu$个候选解权重均值描述。因此，每代中的子候选解仅仅是从以种群均值为中心的已适应多变量高斯分布中抽样得到的样本。
尽管CMA-ES（协方差矩阵适应进化策略）在演化搜索过程的构建上具有更机械化的特点，它与使用梯度估计的方法在概念上建立了联系。这种联系因自然进化策略（NES）的发展而更加紧密 [130]。CMA-ES 的主要机械化工作原理是通过不断变化的种群，从问题的适应度景观中提取信息。在演化过程中，那些具有更高适应度值的个体受到偏好，并影响种群的变化，这一原理在NES中被形式化 [102]。

原则上，这需要将原始的最小化问题重新表述为一个期望的最小化问题：
$$\min_{\theta} J(\theta) = {\mathbb{E}}_{\theta}[f({\boldsymbol x})]$$
其中优化是针对参数化搜索分布空间的，例如通常是具有参数$\theta$的多变量高斯分布。种群在适应度景观上的搜索行为由一个底层过程驱动，该过程实际上是在多变量高斯分布的参数空间中进行搜索。后者需要使用搜索梯度来指导多变量高斯分布的更新。与CMA-ES中机械化利用由演化种群采样得到的期望适应度梯度不同，可以正式构建多变量高斯分布的参数空间，并在此定义一个优化过程。在这个参数空间上的优化是通过使用自然梯度实现的，自然梯度可以推导出最陡的搜索方向。

这一概念在图2 [130] 中示意性地演示了采样适应度梯度与自然梯度之间的差异。在结束本章之前，我们重新审视了先前对图灵的工作——图灵机和非组织化机器的介绍，这些是演化计算和神经计算的通用先驱。在它们提出之后的多年，一系列理论研究（例如 [24, 52, 53]）结合了所有这些计算概念及相关方法，对演化计算范式进行了深入研究。尤其是，作为研究进化算法（EA）的正式计算模型，引入了进化图灵机。这允许例如通过回答一个总体问题——即演化算法是否能够比传统算法（这些算法通过数字机器操作，可以表示为图灵机）表现得更好——来建立演化算法的表达能力。停机问题为这一研究提供了一个正式的背景。

停机问题涉及确定给定描述的计算机程序（算法）在特定输入下是将无限继续运行还是终止。已经证明，由图灵机表示的算法无法解决通用图灵机的停机问题（通用图灵机能够计算任何可计算的序列，即在此意义上它可以表示任何图灵机） [123]。换句话说，没有算法可以解决这一停机问题，这就表达或表征了图灵机作为算法类的可计算性极限。
在文献[52]中，演化图灵机(Evolutionary Turing Machine)被定义为一系列可能无限的图灵机 $T(t)$，它们作用于解的种群 $x(t)$，其中 $t=0, 1, 2, \ldots$。图灵的框架被用于研究演化算法(EAs，作为演化图灵机的表现形式)的表达能力。其中一些理论结果表明，与经典算法相比（经典算法通过定义总是终止并生成所需解），演化算法具有更高的表达能力，这是由于演化算法具备非算法化的搜索行为。可以证明演化算法能够演化出收敛于最优解（在有限距离内）的解决方案，并且这一过程是渐近的。此外，还可以提出其他可证明的论点。

在文献[53]中，通过将演化算法表示为有限状态自动机(Finite State Automata, FSA)，可以生成具有FSA表示的解，而这些解的表达能力可能超出其所属类别（即超过FSA计算能力的范围）。未来，这类理论洞察对于设计实际问题解决的演化算法至关重要。与其开发可能难以超越某些表达能力限制的复杂演化算法，现在研究的重点逐步转向将演化算法的原理作为元算法(metaalgorithms)来应用，例如在投资组合优化中演化演化算法。

这段文字还引用了大量相关研究与参考文献，研究主题涵盖演化计算中的历史、理论和实际应用，如自适应粒子群优化、演化图灵机框架、以及有限状态自动机的表达能力。在实际应用中，这些理论为构建更高效的演化算法提供了重要的设计指南。
